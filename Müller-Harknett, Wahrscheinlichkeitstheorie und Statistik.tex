\documentclass[a4paper,openany]{book}
\title{Wahrscheinlichkeitstheorie und \\ Mathematische Statistik}
\author{Müller-Harknett, Ursula Ute, Dr. rer. nat.}
\date{}
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc}
\usepackage[left=1in,right=1in]{geometry}
\usepackage{amsmath,amssymb,graphicx,tikz,pgfplots,cancel,mathrsfs,upgreek,amsthm,hyperref,fancyhdr,lmodern}
\pgfplotsset{compat=1.18}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{
    every tick/.style={black,}
  }
\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{#1}{#1}}
\fancyhead[R]{\thepage}
\fancyhead[L]{\chaptername\ \thechapter \ - \leftmark}
\fancyfoot{}
\hypersetup{
  colorlinks = true,
  linkcolor = blue,
  pdftitle = {Müller-Harknett, Wahrscheinlichkeitstheorie und Statistik}
}
\usepackage[Lenny]{fncychap}
\usepackage[most]{tcolorbox}
\newtcbtheorem{theo}{Theorem}{%
        theorem name,%
        colback=red!5,%
        colframe=red!35!black,%
        fonttitle=\bfseries,title after break={Theorem  -- \raggedleft Continued}%
 }{theo}
\newtcbtheorem{kor}{Korollar}{%
        theorem name,%
        colback=red!5,%
        colframe=red!35!black,%
        fonttitle=\bfseries,title after break={Korollar  -- \raggedleft Continued}%
 }{kor}
\newtcbtheorem{lem}{Lemma}{%
        theorem name,%
        colback=red!5,%
        colframe=red!35!black,%
        fonttitle=\bfseries,title after break={Lemma  -- \raggedleft Continued}%
 }{lem}
\newtcbtheorem{defi}{Definition}{%
        theorem name,%
        colback=blue!5,%
        colframe=blue!35!black,%
        fonttitle=\bfseries,title after break={Definition  -- \raggedleft Continued}%
 }{defi}
\newtheoremstyle{mytheoremstyle}
 {1em} {1em} {} {} {\bfseries} {} {\newline} {}
\newtheoremstyle{mytheoremstyle2}
 {1em} {1em} {} {} {\itshape} {.} {\newline} {}
\theoremstyle{mytheoremstyle}
\newtheorem*{bei}{Beispiel}
\newtheorem*{bem}{Bemerkung}
\theoremstyle{mytheoremstyle2}
\newtheorem*{cbew}{Beweis}
\setcounter{tocdepth}{2}

 \usepackage{ifthen}
\newboolean{showbew}
\setboolean{showbew}{true}%
%
% TO SHOW THE PROOFS SET THE BOOLEAN TO TRUE, FALSE OTHERWISE
%
%
%
\newenvironment{bew}[1][]{%
  \ifthenelse{\boolean{showbew}}{%
    \begin{cbew}[#1]%
  }{%
    \expandafter\comment%
  }%
}{%
  \ifthenelse{\boolean{showbew}}{%
    \end{cbew}%
  }{%
    \expandafter\endcomment%
  }%
}
\begin{document}
\maketitle
\tableofcontents
\chapter{Einige Grundlagen}
\section{Diskrete Verteilungen}
Gegeben $(\Omega ,A,P), \Omega$ höchstens abzählbar\\
$P$ bestimmt durch $p_w:=P(\left\{w\right\})$, $w \in \Omega$, $p_w \geq 0$, $\sum\limits_{w\in \Omega }p_w=1$ \\
\subsection{Bernoulli-Verteilung} B$(n,p)$, Bin$(n,p)$  \\
 \underline{Bsp. Münzwurf} mit $p \in (0,1)$, '$1$' Kopf, '$0$' Zahl\\
$(\Omega ,\mathcal{A},P)=\left(\left\{0,1\right\},\mathfrak{P}(\left\{0,1\right\}),P\right)$ mit $P(\{1\})=p, P(\{0\})=1-p$, also $P(\{w\})=p^w(1-p)^{1-w}$, $w=0,1$  \\\\
    \underline{n-facher Münzwurf} (unab. Wiederholungen) \\
$(\Omega ,A,P)=\left(\left\{0,1\right\}^n,\mathfrak{P}(\Omega )P\right)$, $P(\{w\})=\prod\limits_{j=1}^{n}{p^{w_j}(1-p)^{1-w_j}}$ \\ 
Betrachte Zufallsvariable $X=\#\left\{\text{Münze zeigt Kopf}\right\}=\sum\limits_{j=1}^{n}{w_j}$, d.h.
$(\Omega ,A,P)\overset{X}\to (\Omega',A')=\left(\left\{0,1,...,n\right\},\mathfrak{P}(\Omega')\right)$  \\
\underline{Gesucht}: Bildmaß von $X$ \\
Betrachte erzeugende Funktion ('probability generating function') für diskrete \\
Verteilungen (konv. $\forall z \in \mathbb{C},|z| \leq 1$) \\
Allgemein \[
  Ez^X=\sum_{k=0}^{\infty}{z^kP(X=k)}=\varphi_X (z),P(X=k)=\frac{\varphi ^{(k)}(0)}{k!}
\]
Hier 
\begin{align*}
  \varphi _X(z)&=E \left(z^{\sum_{j=1}^{n}{w_j}}\right)=E \prod_{j=1}^{n}{z^{w_j}}\overset{\text{unab.}}=\prod_{j=1}^{n}{Ez^{w_j}}\\
               &=\left(z^0(1-p)+z^1p\right)^n=\left(zp+1-p\right)^n \overset{\text{binom.}}{\underset{\text{Formel}}{=}}\sum_{k=0}^{n}{\binom{n}{k}(zp)^k(1-p)^{n-k}}\\
               &=\sum_{k=0}^{n}{z^k \underline{\binom{n}{k}p^k(1-p)^{n-k}}}=Ez^X=\sum_{k=0}^{n}{z^k \underline{P(X=k)}}\\
               &\Rightarrow P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}\text{ für } k = 0,1,...,n \text{\  \underline{Binomialverteilung}
}\end{align*}
\subsection{Negative Binomialverteilung}
 ('Pascal Verteilung') NB$(r,p)$ \\
Betrachte Anzahl Münzwürfe bis genau $r$-mal Kopf beobachtet wurde \\
Sei $(Z_m)_m$ Folge von i.i.d. (u.i.v.), binärer ($0/1$) Zufallsvariable mit 
\[
  P(Z_m=1)=p \in (0,1), \quad Z:=\min \left\{n \in  \mathbb{N}:\sum_{j=1}^{n}{Z_j}=r\right\}
\]
Verteilung von $Z$? \\
Mit \[
  \left\{Z=n\right\}=\left\{Z_n=1\right\}\cap \left\{\sum_{j=1}^{n-1}{Z_j}=r-1\right\}
\]
folgt
\begin{align*}
  P(Z=n)&=\underbrace{P(Z_n=1)}_{p \text{}}\cdot P\bigg(\underbrace{\sum_{j=1}^{n-1}{Z_j}=r-1}_{\sim \text{Bin}(n-1,p) \text{}}\bigg)\\
        &= p \cdot \binom{n-1}{r-1}p^{r-1}(1-p)^{n-1-(r-1)}\\
        &=\binom{n-1}{r-1}p^r(1-p)^{n-r}\text{ \ NB$(r,p)$-Dichte}
\end{align*}
\subsection{Hypergeometrische Verteilung} Hyp$(N,M,n)$ \\
Betrachte z.B. ja/nein Umfrage, \#'ja', \#'defekte Teile' \\
Urne mit $N$ Kugeln, davon $M$ rote, $N-M$ weiße Kugeln \\
Ziehe $n<N$ Kugeln (Stichprobe ohne Zurücklegen) \\
$X:=$ Anzahl rote Kugeln in Stichprobe
\[
  \Rightarrow P(X=l)=\frac{\binom{M}{l}\cdot \binom{N-M}{n-l}}{\binom{N}{n}} \quad \text{hypergeom. Dichte}
\]
\subsection{Multinomialverteilung}
$n$ Kugeln verteilen sich zufällig (unabhängig) auf $m$ Fächer $F_1,...,F_m$  
\begin{align*}
  &P('F_j')=p_j \in (0,1), \quad \sum_{j=1}^{m}{p_j}=1,\quad \Omega =\left\{1,...,m\right\}^n\\
  &P(\left\{w\right\})=P(\left\{w_1,...,w_n\right\})=P(\underbrace{X_1(w)}_{w_1 \text{}},...,\underbrace{X_n(w)}_{w_n \text{}})
\end{align*}
$X_1,X_2,...,X_n $ iid, $P(X_k=j)=p_j$\\ 
$Y_j:=\sum\limits_{k=1}^{n}{1_{\left\{j\right\}}(X_k)}\;$ \#\{Kugeln in $F_j$\}, $j=1,...m$. Dann gilt 
\[
  P(Y_1=l_1,...,Y_m=l_m)=
  \begin{cases}
    \frac{n!}{l_1! \cdot ...\cdot l_m!}\prod\limits_{j=1}^{m}{p_j^{l_j}} & \text{ falls }\sum_{j=1}^{m}{l_j}=n\\
    0 & \text{ sonst}
  \end{cases}
\]
Spezialfall $m=2$ Binomialverteilung \\\\
\subsection{Poisson-Verteilung} Pois($\lambda $), P($\lambda $)\\
Betrachte Bin$(n,p)$, $n$ groß, $p$ klein \\
z.B. $n$ Unfälle/Jahr in Deutschland \\
$p_n$ Unfallwahrscheinlichkeit (seltenes Ereignis) \\
Angenommen $p_n\approx \frac{\lambda }{n}$, $\lambda $ 'Intensität', also $\lambda \approx np_n$ $\;(E(Bin(n,p)))$ für 
$n \to \infty, p_n \to 0$ \\
Dies liefert die Poisson-Verteilung mit Parameter $\lambda >0$.
\[
  P(\left\{k\right\})=e^{-\lambda }\frac{\lambda ^k}{k!}, \quad k \in \mathbb{N}_0
\]
'Verteilung der seltenen Ereignisse'
\begin{theo}{1.1}{}
  Betrachte $(X_n)_n$ Folge von Zufallsvariablen, $X_n \sim \text{Bin}(n,p_n)$, $np_n \overset{n\to\infty}\to \lambda >0$.\\
  Dann gilt $X_n \overset{D}\to X\sim \text{Pois}(\lambda ) \quad(n\to\infty)$   
\end{theo}
\begin{bew}[]
  Betrachte $F_n(x)=P(X_n \leq x)$ Verteilungsfunktion mit Sprüngen bei $x \in \mathbb{N}_0$.
  \begin{align*}
    P(X_n=k)&=\binom{n}{k}p_n^k(1-p_n)^{n-k}=\frac{n!}{k!(n-k)!}p_n^k(1-p_n)^{n-k}\\
            &=\frac{1}{k!} \frac{n(n-1)...(n-k+1)}{\underbrace{n \cdot n \cdot ...\cdot n}_{n^k \text{}}}n^kp_n^k(1-p_n)^{n-k}\\
            &=\underbrace{\frac{(np_n)^k}{k!}}_{\to\frac{\lambda ^k}{k!} \text{}}\underbrace{(1-p_n)^n}_{=\left(1-\frac{np_n}{n}\right)^n }\underbrace{(1-p_n)^{-k}\cdot 1 \cdot \left(1-\frac{1}{n}\right)\cdot ... \cdot \left(1-\frac{k-1}{n}\right)}_{\to1 \cdot 1 \cdot 1 \cdot ... \cdot 1 \text{}}\\
            &\overset{n\to\infty\text{}}\longrightarrow \frac{\lambda ^k}{k!}e^{-\lambda }\qed
  \end{align*}
\end{bew}
\section{Absolutstetige Verteilungen}
W-Maße auf $(\mathbb{R}^d,\mathcal{B}(\mathbb{R})^d)$ mit Dichte bzgl. Lebesgue-Maß. \\
\subsection{Normalverteilung} $N(\mu ,\sigma ^2)$, Erwartungswert $\mu \in \mathbb{R}$, Varianz $\sigma ^2>0$ 
\[
  f(x)=\frac{1}{\sqrt{2 \pi }\sigma }\exp \left(-\frac{1}{2 \sigma ^2}(x-\mu )^2\right)\quad x \in \mathbb{R}
\]
\underline{Bivariante} Normalverteilung $(X_1,X_2)\sim N_2 \left(\begin{pmatrix}\mu _1\\\mu _2\end{pmatrix},\begin{pmatrix}
    \sigma _1^2&\sigma _{12}\\\sigma _{12}&\sigma _2^2
\end{pmatrix}\right)$, $\rho =Corr(X_1,X_2)$
\[
  f(x_1,x_2)=\frac{1}{2 \pi \sqrt{\sigma _1^2 \sigma _2^2-\rho^2}}\exp \left(-\frac{1}{2(1-\rho^2)}\left(\left(\frac{X_1-\mu _1}{\sigma _1}\right)^2-2 \rho \left(\frac{x_1-\mu _1}{\sigma _1}\right)\left(\frac{x_2-\mu _2}{\sigma _2}\right)+\left(\frac{x_2-\mu _2}{\sigma _2}\right)^2 \right)\right) 
\]
mit $\rho=Corr(X_1,X_2)=\frac{Cov(X_1,X_2)}{\sigma _1 \sigma _2}$. \\
Beachte: $\rho=0 \Rightarrow X_1,X_2$ unabhängig (Produkt eindimensionaler Dichten)
\begin{lem}{k-variante Normalverteilung}{}
  Sei $Z\sim N_n(0,I_n)$ $n$-dim. normalverteilt, $A \in \mathbb{R}^{k \times n}$, $\mu \in \mathbb{R}^k$.\\
  Dann ist 
  \begin{align*}
    X:=AZ+\mu
  \end{align*}
   $k$-dim. normalverteilt, $X\sim N_k(\mu ,\Sigma)$ mit 
   \begin{align*}
    EX=\mu 
   \end{align*} und Kovarianzmatrix 
   \begin{align*}
    CovX=E((X-\mu )(X-\mu )^T)=E((AZ)(AZ)^T)=AE(ZZ^T)A^T=AA^T=:\Sigma
   \end{align*}\\
  Ist $\Sigma$ invertierbar, dann hat $X$ die Dichte 
  \begin{align*}
    f(x)=\frac{1}{(2 \pi )^{\frac{n}{2}}\sqrt{\det\Sigma}}\exp\left(-\frac{1}{2}(x-\mu )^T\Sigma ^{-1}(x-\mu )\right)
  \end{align*}    
\end{lem}

\subsection{Chi-Quadrat-Verteilung} $\chi _d^2$ \\
Betrachte $X_1,X_2,...,X_d$ unabhängige Zufallsvariablen, $X_i\sim N(0,1)$, $Y:=\sum\limits_{j=1}^{d}{X_j^2}\geq 0$\\
Verteilung von $Y$?\\
\underline{$d=1$}: $Y=X^2\;(=X_j^2)$
\begin{align*}
  F_Y(y)&=P(Y \leq y)=P(X^2 \leq y)=P(-\sqrt{y}\leq X \leq \sqrt{y})\\
        &=\frac{1}{\sqrt{2 \pi }}\int_{-\sqrt{y}}^{\sqrt{y}}{e^{-\frac{x^2}{2}}dx}=2 \frac{1}{\sqrt{2 \pi }}\int_{0}^{\sqrt{y}}{e^{-\frac{x^2}{2}}dx} 
\end{align*}
Substitution mit $t=x^2,x=\sqrt{t},dx/dt=\frac{1}{2}\cdot t^{-\frac{1}{2}}$ führt auf
\begin{align*}
  &=\cancel{2} \frac{1}{\sqrt{2 \pi }}\int_{0}^{y}{e^{-\frac{t}{2}}}\cdot \cancel{\frac{1}{2}}\cdot t^{-\frac{1}{2}}dt=\frac{1}{\sqrt{2 \pi }}\int_{0}^{y}{\frac{e^{-\frac{t}{2}}}{\sqrt{t}}dt}\\
  &\Rightarrow f_Y(t)=\frac{1}{\sqrt{2 \pi }}\frac{e^{-\frac{t}{2}}}{\sqrt{t}}1_{(0,\infty )}(t)\quad \text{$\chi ^2$-Dichte mit 1 Freiheitsgrad}
\end{align*}
\underline{Allgemein} $d=\nu \in \mathbb{N}:\chi ^2$-Verteilung mit $\nu $ Freiheitsgeraden
\[
  f(x)=2^{-\frac{\nu }{2}}\frac{1}{\Gamma (\frac{\nu }{2})}x^{\frac{\nu }{2}-1}e^{-\frac{x}{2}}1_{(0,\infty)}
\]
$\Gamma(.)$ ist die \underline{Gamma-Funktion}
\[
  \Gamma(z)=\int_{0}^{\infty }{x^{z-1}e^{-x}dx} \text{ für } z>0
\]
Es gilt:
\begin{itemize}
  \item $\Gamma(z+1)=z\Gamma(z)$
  \item $\Gamma(n+1)=n\Gamma(n)=n!$ $\forall n \in \mathbb{N}_0$  
  \item $\Gamma(\frac{1}{2})=\sqrt{\pi }$ 
\end{itemize}
z.B. $\Gamma(4)=3 \cdot 2 \cdot \Gamma(1)=6 \int_{0}^{\infty}{e^{-x}dx}=6 \cdot 1$ oder 
$\Gamma(1.5)=\frac{1}{2}\cdot \Gamma(\frac{1}{2})=\frac{\sqrt{\pi }}{2}$ 
\begin{center}
\begin{tikzpicture}
\begin{axis}[
xmin=0,
ymin=0,
xmax = 5,
ymax = 24,
samples = 500,
legend pos=outer north east,
axis lines = box,
xlabel = $x$,
ylabel = $\Gamma (x)$,
ylabel style = {rotate =-90},
variable = x,
trig format plots = rad,
]
\addplot[black] {sqrt(2*pi)*e^(-x)*sqrt(1/x)*(x+1/(12*x-1/(10*x)))^x}; 
\end{axis}
\end{tikzpicture}
\end{center}
\subsection{Gamma-Verteilung} $\Gamma(\lambda ,r),\lambda ,r \in \mathbb{R}_+$ 
\[
  f(x)=\frac{\lambda ^r}{\Gamma(r)}x^{r-1}e^{-\lambda x}1_{[0,\infty )}(x)
\]
\underline{Spezialfälle}:
\begin{itemize}
  \item $r=\frac{\nu }{2}$, $\nu \in \mathbb{N}$, $\lambda =\frac{1}{2}$:  
\[
  f(x)= \left(\frac{1}{2}\right)^{\frac{\nu }{2}}\frac{1}{\Gamma(\frac{\nu }{2})}x^{\frac{\nu }{2}-1}e^{-\frac{1}{2} x}1_{[0,\infty )}(x)\quad \underline{\chi ^2-\text{Dichte}}
\]
 \item $r=1$: $f(x)=\lambda e^{-\lambda x}$, $x \geq 0$ \underline{Exponential}-Dichte.
\end{itemize}
\underline{Herleitung der Charakteristische Funktion} der $\Gamma(\lambda ,r)$-Verteilung für $r \in  \mathbb{N}$:\\
Betrachte $W\sim \Gamma(\lambda ,r)$\\
\begin{align*}
  \varphi _W(t)=E(e^{itW})&=\frac{\lambda ^r}{\Gamma(r)}\int_{0}^{\infty }{e^{itx}x^{r-1}e^{-\lambda x}dx}\\
                          &=\frac{\lambda ^r}{\Gamma(r)}\int_{0}^{\infty }{x^{r-1}e^{x(it-\lambda )}dx}\\
                          &=\frac{\lambda ^r}{\Gamma(r)}i^{-(r-1)}\frac{d^{r-1}}{dt^{r-1}}\int_{0}^{\infty }{\underbrace{e^{(it-\lambda )x}}_{e^{-(\lambda -it)x} \text{}}dx}\cdot \frac{\lambda -it}{\lambda -it}\\
                          &=\frac{\lambda ^r}{\Gamma(r)}i^{-(r-1)}\frac{d^{r-1}}{dt^{r-1}}\cdot 1 \cdot \frac{1}{\lambda -it}\\
                          &\text{mit }\frac{d}{dt}(\lambda -it)^{-1}=(-1)(\lambda -it)^{-2}(-i)=i(\lambda -it)^{-2}\\
                          &\text{und }\frac{d^{r-1}}{dt^{r-1}}(\lambda -it)^{-1}=i^{r-1}(\lambda -it)^{-r}\underbrace{(r-1)!}_{\Gamma(r) \text{}}\\
                          &=\frac{\lambda ^r}{\Gamma(r)}i^{-(r-1)}i^{r-1}(\lambda -it)^{-r}\Gamma(r)\\
                          &=\underline{\lambda ^r(\lambda -it)^{-r}}
\end{align*} 
Angenommen $W\sim \Gamma(\lambda ,r)$, $V\sim \Gamma(\lambda ,s)$ sind unab. dann gilt 
\begin{align*}
  \varphi _{W+V}(t)&=\varphi _W(t)\varphi _V(t)=\lambda ^r(\lambda -it)^{-r}\lambda ^s(\lambda -it)^{-s}\\
                   &=\lambda ^{r+s}(\lambda -it)^{-(r+s)}\quad \Gamma(\lambda ,r+s)-\text{Verteilung}
\end{align*}
$\Rightarrow$ Für unabhängig Zufallsvariablen $Z_1,...,Z_d\sim N(0,1)$ gilt $\sum_{j=1}^{d}{Z_j^2}\sim \chi ^2(d)$ $(Z_i^2\sim\Gamma(\frac{1}{2},\frac{1}{2}))$
\section{Transformationssatz und Deltamethode}
\underline{Transformationssatz für Lebesgue-Dichten}\\
Sei $P$ $W$-Maß auf $(\mathbb{R}^d,\mathcal{B}(\mathbb{R}^d))$ \\ 
\underline{Vorbemerkung}: \underline{$d=1$}\\
Betrachte $X$, $Y=h(X)$ bijektiv mit $h ^{-1}$ differenzierbar, $Y$ abs. stetig \\
1. Fall: $h$ streng monoton wachsend 
    \begin{align*}
      f_Y(y)=\frac{d}{dy}F_Y(y)&=\frac{d}{dy}P(h(X)\leq y)\\
                               &\overset{\text{mon.}}{\underset{\text{wachs.}}{=}}\frac{d}{dy} P(X \leq h ^{-1}(y))\\
                               &=\frac{d}{dy}F_X(h ^{-1}(y))=f_X(h ^{-1}(y))\frac{d}{dy}h ^{-1}(y)\\
                               &=\frac{1}{\underbrace{h'}_{>0 \text{}}(h ^{-1}(y))}f_X(h ^{-1}(y))
    \end{align*}
2. Fall: $h$ streng monoton fallend
    \begin{align*}
      f_Y(y)=\frac{d}{dy}P(h(x)\leq y)\overset{\text{mon.}}{\underset{\text{fall.}}{=}}\frac{d}{dy}P(X\geq h ^{-1}(y))&=\frac{d}{dy}(1-F_X(h ^{-1}(y)))\\
                                               &=-\frac{1}{\underbrace{h'}_{<0 \text{}}(h ^{-1}(y))}f_X(h ^{-1}(y))
    \end{align*}
    \underline{Insgesamt}:
    \[
      f_Y(y)=\left|\frac{1}{h'(h ^{-1}(y))}\right|f_X(h ^{-1}(y))
    \]
\underline{Merkregel}: 
\begin{align*}
  f_Y(y)=\left|\frac{dx}{dy}\right|f_X(y) \quad(x=h ^{-1}(y))
\end{align*}
\begin{bei}[]
 $X\sim$ Expo$(\frac{1}{10})$, $Y=\ln\left(X\right)=h(X)$, $X=e^Y=h ^{-1}(Y)$ 
\begin{align*}
  f_Y(y)&=\left|\frac{dx}{dy}\right|\frac{1}{10}e^{-x \cdot \frac{1}{10}}1_{[0,\infty )}(x)\\
        &=\left|\frac{de^y}{dy}\right|\frac{1}{10}e^{-\frac{e^y}{10}}\underbrace{1_{[0,\infty )}(e^y)}_{=1}\\
        &=\frac{e^y}{10}e^{-\frac{e^y}{10}}\quad\forall y \in \mathbb{R}
\end{align*} 
\end{bei}
\begin{lem}{1.1 Transformationssatz für mehr-dimensionale Zufallsvariablen}{}
Betrachte $(\mathbb{R}^d,\mathcal{B}(\mathbb{R}^d)$, $f$ Lebesgue-Dichte. \\
Angenommen $P(I)=1$ für $I \subseteq \mathbb{R}^d$ offen, $T:I\to \mathbb{R}^d$ stetig differenzierbar injektiv, mit $T ^{-1}$ stetig differenzierbar auf $T(I)$. \\
Das Bildmaß von $P$ unter $T$ besitzt dann die Lebesgue-Dichte $f_T(y)$
 \begin{align*}
   f_T(y)=
  \begin{cases}
    f(T ^{-1}(y))\cdot |\det(\partial T ^{-1}(y))|&\forall y \in  T(I)\\
    0&\forall\;y \in \mathbb{R}^d \backslash T(I)
  \end{cases}
 \end{align*}
 mit Jacobi Matrix
 \begin{align*}
  \partial T ^{-1}(y)=
  \begin{pmatrix}
    \frac{\partial (T ^{-1})_1(y)}{\partial y_1}&...&\frac{\partial(T ^{-1})_1(y)}{\partial y_d}\\\vdots&&\vdots\\\frac{\partial (T ^{-1})_d(y)}{\partial y_1}&...&\frac{\partial(T ^{-1})_d(y)}{\partial y_d}
  \end{pmatrix}
 \end{align*}
\end{lem}
\begin{bew}[]
  Mit dem Transformationssatz aus der Analysis folgt
  \begin{align*}
    P_T(B)&=E (1_{B}(T))\\
          &=\int_{I}^{}{1_{B}T(x)dP(x)}\\
          &=\int_{}^{}{1_{I}(x)1_{B}T(x)f(x)dx}\\
    \overset{\text{Trafo.}}{\underset{x=T ^{-1}(y)}{=}}&\int_{}^{}{1_I(T ^{-1}(y))1_B(y)f(T ^{-1}(y))|\det(\partial T ^{-1}(y))|dy}\\
          &=\int_{B}^{}{\underbrace{1_{T(I)}(y)f(T ^{-1}(y))|\det(\partial T ^{-1}(y))}_{\text{Dichte}}}|dy
  \end{align*}
\end{bew}
\noindent\underline{Einfache Version/ Merkregel} für $d=2$\\
$(X,Y)$ mit Dichte $f_{X,Y}$, $U=g(X,Y)$, $V=h(X,Y)$, $(x,y)\mapsto (g(x,y),h(x,y))$ 
\begin{align*}
  f_{U,V}(u,v)\partial u\partial v=f_{X,Y}(x,y)\partial x\partial y\quad  \frac{\partial x\partial y}{\partial u\partial v}=|\det(\text{Jacobi})|
\end{align*}
 bzw. 
 \begin{align*}
    f_{U,V}(u,v)=f_{X,Y}(x,y)\cdot \left|\det \begin{pmatrix}
  \frac{\partial x}{\partial u}&\frac{\partial x}{\partial v}\\\frac{\partial y}{\partial u}&\frac{\partial y}{\partial v}
\end{pmatrix}\right|
 \end{align*}
\begin{bei}[]
  \begin{align*}
    f_{X,Y}(x,y)=\frac{1}{2}(\lambda ^2e^{-\lambda (x+y)}+\mu ^2e^{-\mu (x+y)})1_{(0,\infty )}(x)\cdot 1_{(0,\infty )}(y)
  \end{align*} 
  \begin{align*}
    T=X+Y, \quad W=\frac{X}{X+Y}\Rightarrow W=\frac{X}{T}\Leftrightarrow \underline{X=TW}\\
    \underline{Y}=T-X=T-TW=\underline{T(1-W)}
  \end{align*}
  \begin{align*}
    \frac{\partial x\partial y}{\partial t\partial w}&=
    \left|\det \begin{pmatrix}
      \frac{\partial x}{\partial t}&\frac{\partial x}{\partial w}\\\frac{\partial y}{\partial t}&\frac{\partial y}{\partial w}
    \end{pmatrix}\right|=\left|\det \begin{pmatrix}
        w&t\\1-w&-t
      \end{pmatrix}\right|\\
                                                     &=|-wt-t(1-w)|=|-w-t+w|=|-t|=t
  \end{align*}
  \begin{align*}
    f_{T,W}(t,w)&=t \cdot  f_{X,Y}(tw,t(1-w))\\
                &= t \cdot \frac{1}{2}(\lambda ^2e^{-\lambda (\cancel{tw}+t-\cancel{tw})}+\mu ^2e^{-\mu t})1_{(0,\infty )}(tw)1_{(0,\infty)}(t(1-w))
  \end{align*}
  mit $1 _{(0,\infty )}(tw)=1$ für $t>0,w>0$ und $1 _{(0,\infty )}(t(1-w))=1$ für $t>0$, $1-w>0 \Leftrightarrow w<1$
  \begin{align*}
    \Rightarrow f_{T,W}(t,w)&=\underbrace{t \cdot \frac{1}{2}(\lambda ^2e^{-\lambda t}+\mu ^2e^{-\mu t})1_{(0,\infty )}(t)}_{f_T(t)}\underbrace{1_{(0,1)}(w)}_{f_W(w)\sim U(0,1)}
  \end{align*}
  Man sieht das $T,W$ unabhängig sind 
\end{bei}
\begin{theo}{1.2 Delta-Methode}{}
  Sei $(Z_n)_n$ Folge von Zufallsvariablen mit $\sqrt{n}(Z_n-\theta)\overset{\text{D}}\to Z$, $Z$ Zufallsvariable mit Varianz $\sigma ^2 \in (0,\infty )$, $g:\mathbb{R}\to \mathbb{R}$ eine in $\theta$ differenzierbare Funktion mit $g'(\theta)\neq 0$. \\
  Dann gilt 
  \begin{align*}
    \sqrt{n}(g(Z_n)-g(\theta))\overset{\text{D}}\to g'(\theta)Z
  \end{align*}
  Ist $Z\sim N(0,\sigma ^2)$, dann gilt $g'(\theta)\cdot Z\sim N(0,\sigma ^2 g'(\theta)^2)$ 
\end{theo}
\noindent\underline{Einschub/Notation}:\\
Seien $\left\{a_n\right\},\left\{b_n\right\}$ Folgen mit $a_n \in \mathbb{R}$, $b_n \in \mathbb{R}_+$ \\
(a) $a_n=O(b_n)$ falls $\lim\limits_{n\to \infty }\frac{a_n}{b_n}<\infty $  \\
(b) $a_n=o(b_n)$ falls $\lim\limits_{n\to \infty }\frac{a_n}{b_n}=0 $ \\
Seien $\left\{X_n\right\},\left\{Y_n\right\}$ Folgen von Zufallsvariablen \\
(a) $X_n=o_P(Y_n)$ falls $\frac{X_n}{Y_n}\overset{\text{P}}\to 0$, d.h. $\frac{X_n}{Y_n}=o_P(1)$ \\
(b) $X_n=O_P(Y_n)$ falls $X_n=o_P(Y_n)$ oder falls gilt:
\begin{align*}
  \forall \varepsilon >0 \exists n_0 \in \mathbb{N}:\exists L,R \in \mathbb{R}:P \left(L \leq \frac{X_n}{Y_n}\leq R\right) >1-\varepsilon \quad \forall n>n_0
\end{align*}
  (die Folge $\frac{X_n}{Y_n}$ ist 'straff')
\begin{bew}[]
  $\sqrt{n}(Z_n-\theta)$ konvergiert in Verteilung per Voraussetzung, 
  \begin{align*}
    \Rightarrow \sqrt{n}(Z_n-\theta)=O_P(1),\quad Z_n-\theta=\frac{1}{\sqrt{n}}O_P(1)=o_P(1)
    \Rightarrow Z_n \overset{\text{P}}\to \theta
  \end{align*}
  Setze $R(h):=g(\theta+h)-g(\theta)-g'(\theta)h$ ($\leadsto h\triangleq Z_n-\theta $)\\
  Dann gilt  
  \begin{align*}
    \frac{R(h)}{|h|}=\frac{g(\theta+h)-f(\theta)}{|h|}-g'(\theta)\frac{h}{|h|}=o(1)%\quad h \to 0
  \end{align*}
  nach Voraussetzung (betr. $h \gtrless 0$), d.h. 
  \begin{align*}
    R(h)=o(|h|)=|h|\cdot o(1)
  \end{align*}
  Ersetze $h$ durch die Zufallsvariable $Z_n-\theta$ (ok nach dem nächsten Lemma) 
  \begin{align*}
    R(Z_n-\theta)=g(Z_n)-g(\theta)-g'(\theta)(Z_n-\theta)=o_P(|Z_n-\theta|)
  \end{align*}
  Damit folgt  
  \begin{align*}
\sqrt{n}(g(Z_n)-g(\theta))&=\sqrt{n}(g'(\theta)(Z_n-\theta)+o_P(|Z_n-\theta|)\\
    &=\underbrace{g'(\theta)}_{\overset{\text{P}}\to g'(\theta)} \underbrace{\sqrt{n}(Z_n-\theta)}_{\overset{\text{D}}\to Z}+\underbrace{\underbrace{\sqrt{n}|Z_n-\theta|}_{O_p(1)}\cdot o_P(1)}_{o_P(1)\overset{\text{P}}\to 0}
  \end{align*}
  Also nach Slutsky ingesamt $\overset{\text{P}}\to g'(\theta)Z$ $\qed$  
\end{bew}
\begin{lem}{1.3}{}
  Betrachte $R:\mathbb{R}\to \mathbb{R}$ mit $R(0)=0$, Zufallsvariablen $X_n \overset{\text{P}}\to 0$ \\
  Dann gilt für $p>0$\\
  \begin{align*}
    R(h)=o(|h|^p)\quad(h\to 0 )\Rightarrow R(X_n)=o_P(|X_n|^p)
  \end{align*} 
\end{lem}
\begin{bew}[]
  \begin{align*}
    f(h):=\underbrace{\frac{R(h)}{|h|^p}}_{\overset{h\to 0}\longrightarrow 0}\to 0\text{ für }h \neq 0;\;f(0):=0
  \end{align*}
  nach Voraussetzung. \\
  $f$ ist stetig in $0$ und $X_n \overset{\text{P}}\to 0$ $\Rightarrow f(X_n)\overset{\text{P}}\to f(0)=0$ (continuous mapping theorem), d.h.
  \begin{align*}
    \frac{R(X_n)}{|X_n|^p}=o_P(1)\qed
  \end{align*}
\end{bew}
\begin{defi}{1.4 Varianzstabilisierende Transformationen (VST)}{}
  Sei $(Z_n)_{n \in \mathbb{N}}$ eine Folge von Zufallsvariablen mit $\sqrt{n}(Z_n-\theta)\overset{\text{D}}\to N(0,\underbrace{\sigma(\theta) ^2}_{>0})\; \forall\theta$. \\
  Eine Funktion heißt \underline{Varianzstablisierende Transformation} (VST) für $(Z_n)_n$, falls gilt
  \begin{align*}
    \sqrt{n}(g(Z_n)-g(\theta))\overset{\text{D}}\to N(0,1)\;\forall \theta \quad (\text{oder } N(0,c) \text{ für } c \in \mathbb{R}_+ \text{ konstant})
  \end{align*}
  \underline{Konstruktion}: Sei $g$ differenzierbar in $\theta$, $g'(\theta) \neq 0\; \forall \theta$ \\
  Delta Methode: $\sqrt{n}(g(Z_n)-g(\theta))\overset{\text{D}}\to N(0,g'(\theta)^2 \sigma(\theta) ^2)$  \\
  Wähle also $g$ so dass $g'(\theta)\sigma (\theta)=1 \Leftrightarrow g'(\theta)=\frac{1}{\sigma (\theta)}$, d.h.
  \begin{align*}
    g(\theta)=\int{\frac{1}{\sigma (\theta)}d \theta}
  \end{align*}
\end{defi}
\begin{bei}[Poisson]
  Sei $X_n\sim $ Pois$(\theta)$, $EX_n=Var(X_n)=\theta=\sigma ^2(\theta)$, dann gilt für 
  \begin{align*}
    \bar{X}=\frac{1}{n}\sum_{i=1}^{n}{X_i}\quad \text{ Stichprobenmittel}\\
    \sqrt{n}(\bar{X}_n-\theta)\overset{\text{D}}\to N(0,\theta)
  \end{align*}
  Wähle
  \begin{align*}
    g(\theta)=\int{\frac{1}{\sigma (\theta)}d \theta}=\int{\theta^{-\frac{1}{2}}d \theta}=2 \theta^{\frac{1}{2}}+c
  \end{align*}
  O.B.d.A. sei $c=0$ (im Nachfolgenden kürzt sich $c$ raus)\\
  Dann gilt
  \begin{align*}
    \sqrt{n}\left( 2 \sqrt{\bar{X}}+\cancel{c}-2\sqrt{\theta}-\cancel{c} \right)\overset{\text{D}}\to N(0,1)\\
    \Leftrightarrow \sqrt{n}\left( \sqrt{\bar{x}}-\sqrt{\theta} \right)\overset{\text{D}}\to N \left(0,\frac{1}{4}\right)
  \end{align*}
\end{bei}
\begin{theo}{1.5 Multivariate Delta-Methode}{}
  \underline{Gegeben}: $(X_n)$ Folge $k$-dim. Zufallsvariable, $\mu \in \mathbb{R}^k$, $\Sigma \in \mathbb{R}^{k \times k}$  positiv semi-definit, $c_n \in \mathbb{R}$, $n \in \mathbb{N}$,\\
  $\lim\limits_{n\to \infty }{c_n}=0$, $\frac{X_n-\mu }{c_n}\overset{\text{D}}\to N_k(0,\Sigma)$ \\
  Ist $g:\mathbb{R}^k\to \mathbb{R}^m$ ($m \leq k$) total differenzierbar in $\mu $ mit Jacobi-Matrix $g'(\mu )=D^T \in \mathbb{R}^{m \times k}$ mit $\det(D^TD)\neq 0$, dann gilt
  \begin{align*}
    c_n ^{-1}(g(X_n)-g(\mu ))\overset{\text{D}}\to N_m \left(0,D^T\Sigma D\right)
  \end{align*}
\end{theo}
\chapter{Einführung in die Statistik und Stichprobenmomente}
\noindent Betrachte $X:\Omega \to \mathbb{R}^k$ Zufallsvariable/-vektor \\
W-Theorie: Eigenschaften $P^X$ \\
Statistik: Rückschlüsse auf $P^X$ (unbekannt) aufgrund von Beobchtung(en) von $X$  
\begin{bei}[2.1]
  (a) \\
  \underline{Wahlprognose}: Wird Kandidat $A$ gewählt? \\
  Befragung von $n$ Personen (Stichprobe) \\
  $X:=$Anzahl der Personen in Stichprobe die $A$ wählen \\
  Verteilung: $X\sim$ Bin$(n,\vartheta)$, $\vartheta\;(=p)$ unbekannt. \\
  \underline{Gesucht}: Schätzung $\hat{\vartheta}$ für $\vartheta$ (Schätzer) \\
  (b)\\
  Behauptung: Glühlampenhersteller: Lebensdauer $\geq 6$ Jahre \\
  Stimmt das? ($EX_j>6$?) \\
  Modell: $X_1,X_2,...,X_n$ iid $\sim$ Exp$(\frac{1}{\vartheta})$ (mit $EX_j=\vartheta$) \\
  (c)\\
 \underline{Gesucht}: Anzahl Fische $\vartheta=N$ in Teich $=$ ? \\
  Methode: \underline{Capture/ recapture sampling} \\
  d.h. fangen $K$ Fische, markieren sie, zurück in Teich \\
  1 Woche später: fange $n$ Fische, $X=$\#\{markierte Fische\} \\
  $\frac{X}{n}=$ Anteil markierter Fische in Stichprobe \\
  Dann ist $\frac{X}{n}\approx \frac{K}{\vartheta}$ und $\vartheta \approx \frac{K \cdot n}{X}$ \\
  \underline{oder} Herleitung eines Schätzers $\hat{\vartheta}$ mittels [$j$ Anzahl mark. Fische]
  \begin{align*}
    P(X=j)=\frac{\binom{k}{j}\binom{\vartheta-K}{n-j}}{\binom{\vartheta}{n}}\quad (K,n,j\text{ bekannt})
  \end{align*}
  (d)\\
  Volumen $X$ von $0.75l$ Weinflaschen \\
  \underline{Annahme}: $X_1,X_2,...,X_n$ iid $\sim N(\mu ,\sigma ^2)$ \\
  \underline{Gesucht}: Intervall $I$ mit $P(\mu \in I)=0.95$  
\end{bei}
\noindent\textbf{Modellannahmen} (2.2) \\
$(\Omega ,A,P)$ W-Raum mit unbekanntem $P \in \mathcal{P}=\left\{P_{\vartheta}:\vartheta \in \Uptheta \neq \emptyset \right\}$, $\Uptheta$ 'Parameterraum' \\
$(\mathcal{X},B)$ messbarer Raum (Messraum), $\mathcal{X}$ Stichprobenraum \\
$X:\Omega \to \mathcal{X}$, $A-B$-messbar  \\
Dann ist $\tilde{P}=\left\{P_{\vartheta}^X:\vartheta \in \Uptheta\right\}$ Familie von W-Maßen auf $\mathcal{X}$ \\
$(\mathcal{X},B,\tilde{P})$ 'stochastisches Modell' \\
$X$ statistische Experiment, Realisation von $X$ 'Stichprobe' \\
Das Modell ist parametrisch falls $\Uptheta \subseteq $ endlich-dimensionaler Vektorraum \\
Andernfalls ist das Modell nicht-parametrisch
\begin{bem}[2.3]
  (a) Oft wird nur die Zufallsvariable $X$ mit Verteilung $\mathcal{P}=\left\{P_{\vartheta}:\vartheta \in \Uptheta\right\}$ angegeben, d.h. $P_{\vartheta}^X$ wird mit $P_{\vartheta}$ identifiziert \\
  (b) Gilt $X\sim P_{\vartheta_0}$ für ein $\vartheta_0 \in \Uptheta$, dann heißt $\vartheta_0$ '\underline{wahrer} Parameter' (Annahme $\vartheta_1 \neq \vartheta_2 \Rightarrow P_{\vartheta_1}\neq P_{\vartheta_2}$) \\
  (c) Oft gilt $X_1,X_2,...,X_n$ iid, d.h. $X_1,X_2,...,X_n \sim P_{\vartheta}^{(1)}(=P_{\vartheta}^{X_1})$  
  \begin{align*}
    P_{\vartheta}=\bigotimes_{i=1}^{n}P_{\vartheta}^{(1)}, \quad \text{d.h. Angabe von } P_{\vartheta}^{(1)}\text{ genügt}
  \end{align*}
  \underline{Annahmen}: Sei $X:\Omega \to \mathcal{X}$ Zufallsvariable mit $X\sim P^X=P _{\vartheta}$ für ein $\vartheta \in \Uptheta$    \\
  $X$ ist meist diskret \underline{oder} stetig, $X(w)\in \mathbb{R}^k$ für ein $k \in \mathbb{N}$   \\
  Alternative Notation für $\mathcal{P}$ wenn $X$ stetig:
  \begin{align*}
    \mathcal{P}=\left\{f_{\vartheta}:\vartheta \in \Uptheta\right\}, \; X\sim f_{\vartheta}
  \end{align*}
\end{bem}
\begin{bei}[2.4 Medikamentenvergleich]
  Medikamente $M_1,M_2$\\
  $M_1:$ Heilung in 80\% aller Fälle \\ 
  $M_2:$ neues Medikament, Test an 50 Patienten \\
  Realisationen $x_1,x_2,...,x_{50}\in \left\{0,1\right\}$ von Zufallsvariablen $X_1,X_2,...,X_n$ iid Bin$(1,\vartheta)$ ($x_1=X_1(w),...$) \\
  $\vartheta(=p)$ Heilungs- oder Erfolgswahrscheinlichkeit \\
  Möglicher Schätzer $\hat{\vartheta}=\frac{1}{50}\sum_{i=1}^{50}{x_i}$, z.B. $\hat{\vartheta}=\frac{42}{50}=0.84$ \\
  Wie zuverlässig ist $\hat{\vartheta}=0.84$? Spricht dies deutlich für $M_2$? \\
  Mögliche Fehler?
\end{bei}
\noindent \textbf{Ziel} (2.5)\\
Aussagen über $\vartheta_0$ (wahrer Parameter) aufgrund von Beobachtung(en) $x=X(w)$, $X\sim P^X=P_{\vartheta_0}$  \\
(i) Punktschätzungen: $\hat{\vartheta}=\hat{\vartheta}(x)$ Schätzer von $\vartheta_0$  \\
Herleitung und Eigenschaften guter Schätzverfahren \\
(ii) Hypothesentests: Gilt $\vartheta \in \Uptheta_0$ oder $\vartheta \in \Uptheta_1=\Uptheta \backslash\Uptheta_0$  \\
(iii) Konfidenzbereiche: Zufällige Mengen $C(X)\in \Uptheta$ die $\vartheta_0$ mit einer gegebenen Wahrscheinlichkeit enthalten (z.B. $0.9,0.95,0.99$)  
\section{Stichprobenmomente}
\underline{Im restlichen Kapitel} sei $X$ Zufallsvariable mit Verteilungsfunktion $F$ und $X_1,X_2,...,X_n \overset{iid}\sim F$ (Stichprobe) \\
Par. Modell: $F=\mathcal{F}=\left\{F_{\vartheta}:\vartheta\in \Uptheta\right\}$, $\Uptheta$ endl. dim. \\
\underline{Ziel}: Rückschlüsse auf $\vartheta_0$ ($F=F_{\vartheta_0}$) 
\begin{defi}{2.6 Statistik}{}
  Sei $Y$ Zufallsvariable mit Werten in $\mathcal{Y}$. Die messbare Abbildung $h:\mathcal{Y}\to \mathbb{R}^k$ heißt \textbf{Statistik}, falls sie nicht von den unbekannten Parametern abhängt. \\
  Ist $Y=(X_1,X_2,...,X_n)$ mit $X_1,X_2,...,X_n$ iid, dann wird $h(Y)$ auch \textbf{Stichprobenstatistik} genannt.   
\end{defi}
\begin{defi}{2.7}{}
  Sei $X_1,X_2,...,X_n$ eine Stichprobe. Die Zufallsvariable 
  \begin{align*}
    a_k=\frac{1}{n}\sum_{i=1}^{n}{X_i^k}
  \end{align*}
  heißt \underline{k-tes Stichprobenmoment}. Insbesondere heißen 
  \begin{align*}
    a_1=\frac{1}{n}\sum_{i=1}^{n}{X_i}=:\bar{X}_n \text{ bzw. } \bar{X}\quad\text{ \underline{Stichprobenmittel}}
  \end{align*}
  \begin{align*}
    b_k=\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X}_n)^k}\quad\text{ \underline{zentrales k-tes Stichprobenmittel}}
  \end{align*}
  \begin{align*}
    \hat{S_n}^2=\frac{n}{n-1}b_2=\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})^2}\quad\text{ \underline{Stichprobenvarianz}}
  \end{align*}
\end{defi}
\begin{defi}{2.8}{}
  Sei $(X_1,Y_1),...,(X_n,Y_n)$ Stichprobe einer bivarianten Verteilung. Dann heißt 
  \begin{align*}
    S _{11}=S _{XY}=\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})(Y_i-\bar{Y})}\text{ Stichprobenkovarianz}
  \end{align*}
  und
  \begin{align*}
    \hat{\rho }_n=\frac{S _{11}}{\sqrt{S_1^2}\sqrt{S_2^2}}\text{ Stichprobenkorrelationskoeffizient/ Pearson-Koeffizient}
  \end{align*}
  mit 
  \begin{align*}
    S_1^2=S _{XX}=\frac{1}{n-1}\sum_{i=1}^{n}{(X_i-\bar{X})^2}, S_2^2=S _{YY}=\frac{1}{n-1}\sum_{i=1}^{n}{(Y_i-\bar{Y})^2}
  \end{align*}
\end{defi}
\begin{bem}[2.9]
  Sei $(x_1,x_2,...,x_n)=(X_1(w),X_2(w),...,X_n(w))$ Realisationen von $(X_1,X_2,...,X_n)$. Die Abbildung
  \begin{align*}
    \hat{F_n}:\mathbb{R} \to \mathbb{R} \text{ mit }\hat{F_n}(x)=\frac{1}{n}\sum_{i=1}^{n}{1(x_i \leq x)}
  \end{align*}
  heißt \underline{empirische Verteilungsfunktion}.
  \begin{center}
\begin{tikzpicture}
\begin{axis}[
  %ytick={0,1/5,2/5,3/5,4/5,1},
  ytick = \empty,
  extra y ticks = {0,1/5,2/5,3/5,4/5,1},
  extra y tick labels = {0,$\frac{1}{5}$,$\frac{2}{5} $,$\frac{3}{5} $,$\frac{4}{5} $,1},
  xtick= \empty,
xmin=0,
ymin=0,
xmax = 1.1,
ymax = 1.1,
xlabel = $x$,
ylabel = $\hat{F}_5(x)$,
samples = 8,
legend pos=outer north east,
axis lines = box,
ylabel style = {rotate =-90},
trig format plots = rad,
]
\addplot[domain=0:1.05, dotted, thick] {1};
\addplot[jump mark left, mark = *, domain=0:1.5]{floor(5*x-x^2+x^3)/5};
\draw (axis cs:0,3) circle [black, radius=0.2];
\addplot[black, thick, mark=x, only marks] coordinates {(0.208,0) (0.43,0)(0.65,0)(0.85,0)(1.07,0)};
\end{axis}
\end{tikzpicture}
  \end{center}
  $\hat{F_n}$ ist Verteilungsfunktion der Gleichverteilung (oder Laplace-Verteilung) auf $\left\{x_1,x_2,...,x_n\right\}$ vorausgesetzt $x_i \neq x_j\;\forall i\neq j$. \\
  Gilt $Y\sim \hat{F_n}$ dann gilt    \begin{align*}
    \Rightarrow EY&=\sum_{i=1}^{n}{x_iP(X_i=x_i)}=\frac{1}{n}\sum_{i=1}^{n}{x_i}=\bar{x} \\
    EY^k&=\sum_{i=1}^{n}{x_i^k \cdot \frac{1}{n}}=a_k\quad \text{(k-tes Stichprobenmoment)
}
  \end{align*}
\end{bem}
\begin{theo}{2.10}{}
  Mit der Notation wie in (2.7), (2.8) gilt
  \begin{align*}
    &(1)\quad E \bar{X}_n=EX_1,\quad Var(X_n)=\frac{Var(X_1)}{n}\\
    &(2)\quad E \hat{S_n^2}=Var(X_1),\quad Var(\hat{S_n^2})=\frac{1}{n}E[(X_1-EX_1)^4]+\frac{3-n}{n(n-1)}(VarX_1)^2 \\
    &(3)\quad ES _{11}=Cov(X_1,Y_1)
  \end{align*}
\end{theo}
\begin{bew}[]
  (1),(2) nachrechnen. \\
  (3)
  \begin{align*}
    ES _{11}&=\frac{n}{n-1}E\bigg({\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X})(Y_i-\bar{Y})}}\bigg)
  \end{align*}
  (Ausdruck in der Klammer Kovarianz der Gleichverteilung auf den Beobachtungen $(x_i,y_i)$, $(Cov(X,Y)=EXY-EXEY)$)
  \begin{align*}
    &=\frac{n}{n-1}E\bigg(\frac{1}{n}\sum_{}^{}{X_iY_i}-\frac{1}{n}\sum_{i}^{}{X_i} \frac{1}{n} \sum_{j}^{}{Y_j}\bigg)\\
    &=\frac{n}{n-1}E(X_1Y_1)-\frac{n}{n-1}\frac{1}{n^2}\sum_{i}^{}{\sum_{j}^{}{E(X_iY_j)}}\\
    &=\frac{n}{n-1}E(X_1Y_1)-\frac{1}{n(n-1)}\sum_{i}^{}{\bigg(\sum_{j \neq i}^{}{E(X_iY_j)}+E(X_iY_i)\bigg)}\\
    &=\frac{n}{n-1}E(X_1Y_1)-\frac{1}{n(n-1)}\sum_{i}^{}{\sum_{j \neq i}^{}{EX_iEY_j}}-\frac{1}{n(n-1)}nE(X_1Y_1)\\
    &=E(X_1Y_1)\left( \frac{n}{n-1}-\frac{1}{n-1} \right)-\frac{n(n-1)}{n(n-1)}EX_1\underbrace{EY_2}_{\overset{iid}=EY_1}\\
    &=E(X_1Y_1)-EX_1EY_1=Cov(X_1,Y_1)\;\qed
  \end{align*}
\end{bew}
\begin{lem}{2.11}{}
  Sei $X_1,X_2,...,X_n$ Stichproben, $E(X_1^{2k})<\infty, k \in \mathbb{N}$.
  \begin{align*}
    m_k:=EX_1^k,\quad m _{2k}=EX_1^{2k}.
  \end{align*}
  Dann gilt mit $n\to \infty $ für $a_k=\frac{1}{n}\sum_{i=1}^{n}{X_i^k}$:
  \begin{align*}
    \sqrt{n}\frac{a_k-m_k}{\sqrt{m _{2k}-m_k^2}}\overset{\text{D}}\to N(0,1).
  \end{align*}
\end{lem}
\begin{bew}[]
  Dies folgt mit dem Zentralen-Grenzwert-Satz (ZGW), denn
  \begin{align*}
    \frac{\sum_{}^{}{X_i^k}-E(\sum_{}^{}{X_i^k})}{\sqrt{Var \sum_{}^{}{X_i^k}}}
    &=\frac{\sum_{}^{}{X_i^k}-n \cdot m_k}{\sqrt{n \cdot Var X_1^k}}\\
    &\overset{\cdot \frac{1/n}{1/n}}=\frac{\frac{1}{n}\sum_{}^{}{X_i^k}-m_k}{\frac{1}{\sqrt{n}\cancel{\sqrt{n}}}\cancel{\sqrt{n}}\sqrt{Var X_1^k}}\\
    &=\sqrt{n}\frac{a_k-m_k}{\sqrt{m _{2k}-m_k^2}}\;\qed
  \end{align*}
\end{bew}
\begin{bem}[2.12]
  (1) Spezialfall: $\sqrt{n}(\bar{X}_n-EX_1)\overset{\text{D}}\to N(0,Var(X_1))$ ($\bar{X}_n$ Schätzer für $EX_1$, $Var(X_1)$ unbekannt)
  \begin{align*}
    \sqrt{n}\frac{\bar{X}_n-EX_1}{\sqrt{\hat{S_n^2}}}&=\sqrt{n}\frac{\bar{X}-EX_1}{\sqrt{Var X_1}}\cdot \frac{\sqrt{Var X_1}}{\sqrt{\hat{S_n^2}}}
                                                     \overset{\text{D}}\to N(0,1)
  \end{align*}
  Dies gilt weil
  \begin{align*}
    \sqrt{n}\frac{\bar{X}_n-EX_1}{\sqrt{Var X_1}}\overset{\text{D}}\to N(0,1)\quad (\text{ZGW})
  \end{align*}
  \begin{align*}
    \hat{S_n^2}\overset{\text{P}}\to Var X_1
  \end{align*}
  \begin{align*}
   \overset{\text{cont.}}{\underset{\text{mapping}}{\Rightarrow }} \sqrt{\frac{Var X_1}{\hat{S_n^2}}}\overset{\text{P}}\to 1\quad \text{und Slutskys Lemma } (X_n \overset{\text{D}}\to X, Y_n \overset{\text{P}}\to c, X_nY_n \overset{\text{D}}\to X \cdot c) 
  \end{align*}
  (2) Verteilung der Zentralen Sitchprobenmomente 
  \begin{align*}
    \frac{1}{n}\sum_{}^{}{(X_i-\bar{X})^k} \text{  siehe (2.13)(1) für $k=2$}
  \end{align*}
\end{bem}
\begin{lem}{2.13}{}
  (1) \\
  $X_1,X_2,...,X_n $ iid mit $EX_1^4< \infty$, $Var X_1=\sigma ^2>0$. Dann gilt
  \begin{align*}
    \sqrt{n}\left(\frac{1}{n}\sum_{}^{}{(X_i-\bar{X})^2-\sigma ^2}\right)&=\sqrt{n}\left(\frac{n-1}{n}\hat{S_n^2}-\sigma ^2\right)\overset{\text{D}}\to N(0,\mu _4-\mu _2^2)
  \end{align*}
  mit 
  \begin{align*}
    \mu _j:=E((X_1-EX_1)^j)\text{ (zentriertes $j$-tes  Moment)}
  \end{align*}   \\
  (2)\\
  $(X_1,Y_1),...,(X_n,Y_n)$ iid $N_2\left(\begin{pmatrix}\mu _1\\\mu _2\end{pmatrix},\begin{pmatrix}
    \sigma ^2&\rho _{\sigma \tau}\\\rho _{\tau \sigma }&\tau^2
  \end{pmatrix}\right)$  mit $VarX_1=\sigma ^2$, $Var Y_1=\tau^2$, $\rho =Corr(X_1,Y_1)$
  \begin{align*}
    \hat{\rho }=\frac{S _{11}}{\sqrt{S_1^2}\sqrt{S_2^2}}\text{ \underline{ Stichprobenkorrelationskoeffizient}}
  \end{align*}
  Dann gilt 
  \begin{align*}
    \sqrt{n}(\hat{\rho }-\rho )\overset{\text{D}}\to N(0,(1-\rho ^2)^2)
  \end{align*}
\end{lem}
\begin{bew}[2.13 (1)]
  Der Beweis von 2.13 (2) geht ähnlich mit Delta-Methode, ZGW. \\
  Setze $m_j:=EX_1^j$ $j$-tes Moment
  \begin{align*}
    \frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X})^2}&=\frac{1}{n}\sum_{i=1}^{n}{X_i^2-\bar{X}^2}=g\bigg(\bar{X},\frac{1}{n}\sum_{i=1}^{n}{X_i^2}\bigg), \quad g(y,z)=z-y^2 
  \end{align*}
  $g:\mathbb{R}^2\to \mathbb{R}$ ist stetig partiell differenzierbar, dementsprechend total differenzierbar (für Delta-Methode)
  \begin{align*}
    E \bar{X}=EX_1=m_1, \quad E \left(\frac{1}{n}\sum_{i=1}^{n}{X_i^2}\right)=EX_1^2=m_2
  \end{align*}
  \begin{align*}
    g(\underbrace{m_1,m_2}_{=\mu ^T})&=m_2-m_1^2=Var X_1=\sigma ^2
  \end{align*}
  2-dim. ZGW:
    \begin{align*}
     \sqrt{n}\left(\frac{1}{n}\sum_{i=1}^{n}{\begin{pmatrix}X_i\\X_i^2\end{pmatrix}-\begin{pmatrix}m_1\\m_2\end{pmatrix}}\right)
     &=\frac{\frac{1}{n}\sum\limits_{i=1 }^{n}{\bigg(\begin{pmatrix}X_i\\X_i^2\end{pmatrix}-\begin{pmatrix}m_1\\m_2\end{pmatrix}\bigg)}}{1/\sqrt{n}}\bigg(\triangleq \frac{X_n-\mu }{c_n}\text{ aus 1.5}\bigg)\overset{\text{D}}\to N\bigg(\binom{0}{0},\Sigma\bigg)
  \end{align*}
    \begin{align*}\Sigma = \begin{pmatrix}
      Var X_1&Cov(X_1,X_1^2)\\Cov(X_1,X_1^2)&Var X_1^2
    \end{pmatrix}=\begin{pmatrix}
      m_2-m_1^2&m_3-m_1m_2\\m_3-m_1m_2&m_4-m_2^2
    \end{pmatrix}
  \end{align*}
  In 1.5 $c_n ^{-1}(g(X_n)-g(\mu ))\overset{\text{D}}\to N(0,D^T\Sigma D)$ \\
  Hier $\sqrt{n}(g(\bar{X},\frac{1}{n}\sum_{}^{}{X_i^2})-\sigma ^2)\overset{\text{D}}\to N(0,D^T\Sigma D)$ 
  \begin{align*}
    D=g'(y,z)^T \bigg|_{(y,z)=(m_1,m_2)}=\begin{pmatrix}-2m_1\\1\end{pmatrix}
  \end{align*}
  \begin{align*}
    \det D^TD = \det\left((-2m,1)\begin{pmatrix}-2m_1\\1\end{pmatrix}\right)=4m^2+1>0 \text{ (pos. def.)}
  \end{align*}
  \begin{align*}
    D^T\Sigma D=...=\mu _4-\mu _2^2\;\square
  \end{align*}
\end{bew}
\begin{theo}{2.14}{}
  $X_1,X_2,...,X_n $ iid $\sim N(\mu ,\sigma ^2)$, $\hat{S^2}=\frac{1}{n-1}\sum_{}^{}{(X_j-\bar{X})^2}$.  Es gilt \\
  \begin{align*}
    &1)\quad  \bar{X}\sim N(\mu ,\frac{\sigma ^2}{n})\\
    &2)\quad  \frac{(n-1)\hat{S_n^2}}{\sigma ^2}=\frac{1}{\sigma ^2}\sum_{i=1}^{n}{(X_i-\bar{X})^2\sim\chi _{n-1}^2}\\
    &3)\quad  \bar{X} \perp\!\!\!\perp \hat{S_n^2}\\
    &4)\quad \frac{\sqrt{n}(\bar{X}-\mu )}{\sqrt{\hat{S_n^2}}}\sim t _{n-1}
  \end{align*}
\end{theo}
\begin{bew}[]
  (1) O.B.d.A. sei $\mu =0$ (Ansonsten betrachte $\tilde{X}=X-\mu $) \\
  Nach Abschnitt 1.2 sei $X=AZ+\mu $, $A \in \mathbb{R}^{k \times n}, \mu \in \mathbb{R}^k, Z\sim N_n(0, I_n)$ dann gilt \\
  $EX=\mu $, $CovX=AE(ZZ^T)A^T=AIA^T=AA^T=:\Sigma$, $X\sim N_k(\mu ,\Sigma)$. \\
  Sei $A \in \mathbb{R}^{n \times n}$ orthonormal, 1. Spalte $(1/\sqrt{n},...,1/\sqrt{n})^T$, $Y=A^TX$, $X=(X_1,...,X_n)^T\sim N_n(0,\sigma ^2 I_n)$. Dann gilt 
  \begin{align*}
    Y\sim \underbrace{N_n(0,CovY)}_{=N_n(0,\sigma ^2I_n)}, \quad CovY=A^TE(XX^T)A=A^T \sigma ^2I_nA=\sigma ^2I_n
  \end{align*}
  Demnach sind $Y_1,Y_2,...,Y_n $ unabhängig, $N(0,\sigma ^2)$-verteilt. Ebenfalls unabhängig sind $Y_1$ und $Y_2,...,Y_n$   bzw. $Y_1$ und $\sum_{j=2}^{n}{Y_j^2}$.
  \begin{align*}
    Y_1&=\left(\frac{1}{\sqrt{n}},...,\frac{1}{\sqrt{n}}\right)\begin{pmatrix}X_1\\\vdots\\X_n\end{pmatrix}=\frac{1}{\sqrt{n}}\sum_{i=1}^{n}{X_i}=\sqrt{n}\bar{X} \\
  \underline{\frac{1}{\sqrt{n}}Y_1} &= \bar{X}\sim N(0,\sigma ^2/n)\;\square
  \end{align*}
  (3) Weiter gilt mit $X=AY$ (denn $Y=A^TX=A^TAY=IY=Y$)
  \begin{align*}
    \underline{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}&=\sum_{j=1}^{n}{X_j^2-n \bar{X}^2}=X^TX-n \bar{X}^2 \\
                                   &=Y^T \underbrace{A^TA}_{I}Y-n\left(\frac{1}{\sqrt{n}}Y_1\right)^2=\sum_{j=1}^{n}{Y_j^2-Y_1^2} \\
                                   &=\underline{\sum_{j=2}^{n}{Y_j^2}}\text{ unabhängig von $Y_1$}
  \end{align*}
  also $\bar{X} \perp\!\!\!\perp \hat{S^2}$ $\square$  \\
  (2)    \\
  \begin{align*}
    \frac{1}{\sigma ^2}\sum_{i=1}^{n}{(X_i-\bar{X})^2}\overset{\text{eben}}=\sum_{j=2}^{n}{\left( \frac{Y_j}{\sigma } \right)^2}
  \end{align*}
  mit $\frac{Y_2}{\sigma },...,\frac{Y_n}{\sigma }$ iid $N(0,1)$ folgt 
  \begin{align*}
    \sum_{j=2}^{n}{\left(\frac{Y_j}{\sigma }\right)^2}\sim \chi _{n-1}^2\; \square
  \end{align*}
  (4) Es gilt: $\frac{N(0,1)}{\sqrt{\chi_n ^2/n}}\sim t_n$ $t$-Verteilung mit $n$ Freiheitsgeraden. \\
  Hier: 
  \begin{align*}
    \frac{\sqrt{n}(\bar{X}-\mu' )}{\sqrt{\hat{S_n^2}}}&=\frac{\sqrt{n}(\bar{X}-\mu )}{\sigma }\div \sqrt{\frac{\sum_{}^{}{(X_i-\bar{X})^2}}{\sigma ^2}\cdot \frac{1}{n-1}} \\
                                                      &=\frac{N(0,1)}{\sqrt{\chi _{n-1}^2 \frac{1}{n-1}}}\sim t _{n-1}\;\square
  \end{align*}
\end{bew}
\begin{theo}{2.15}{}
  Seien $X_1,X_2,...,X_m, Y_1,Y_2,...,Y_n$ unabhängig. $X_1,X_2,...,X_m$ iid $N(\mu _1,\sigma _1^2)$ und $Y_1,Y_2,...,Y_n $ iid $N(\mu _2,\sigma _2^2)$    
  \begin{align*}
    S_1^2 &= \frac{1}{m-1}\sum_{i=1}^{m}{(X_i-\bar{X})^2}, S_2^2=\frac{1}{n-1}\sum_{j=1}^{n}{(Y_j-\bar{Y})^2}
  \end{align*}
  Dann gilt: \\
  (a)    
  \begin{align*}
    \frac{S_1^2}{\sigma _1^2}\div\frac{S_2^2}{\sigma _2^2}=\frac{S_1^2 \sigma _2^2}{S_2^2 \sigma _1^2}\sim F(m-1,n-1)\text{ $F$-Verteilung}
  \end{align*}
  (b) 
  \begin{align*}
    \frac{\bar{X}_m-\bar{Y}_n-(\mu _1-\mu _2)}{\sqrt{(m-1)\frac{S_1^2}{\sigma _1^2}}+(n-1)\frac{S_2^2}{\sigma _2^2}}\cdot \sqrt{\frac{m+n-2}{\sigma _1^2/m+\sigma _2^2/n}}\sim t _{m+n-2}
  \end{align*}
\end{theo}
\begin{bew}[]
  (a) Nach Theorem 2.14b gilt 
  \begin{align*}
    \frac{(m-1)S_1^2}{\sigma _1^2}\sim \chi _{m-1}^2 \quad\perp\!\!\!\perp \quad  \frac{(n-1)S_2^2}{\sigma _2^2}\sim \chi _{n-1}^2
  \end{align*}
  und es gilt:  
  \begin{align*}
    \frac{\chi _m^2/m}{\chi _n^2/n}\sim F(m,n)
  \end{align*}
  Hier: 
  \begin{align*}
    \frac{\frac{S_1^2}{\sigma _1^2}\cdot \frac{m-1}{m-1}}{\frac{S_2^2}{\sigma _2^2}\cdot \frac{n-1}{n-1}} 
    &\sim \frac{\chi _{m-1}^2/(m-1)}{\chi _{n-1}^2/(n-1)}\sim F(m-1,n-1)
  \end{align*}
  (b) Wie in Beweis von Theorem 2.14 schreibe
  \begin{align*}
    \frac{(m-1)S_1^2}{\sigma _1^2}=\sum_{j=1}^{m-1}{Z_j^2}
  \end{align*}
  mit $Z_1,...,Z _{m-1}$ iid $N(0,1)$ ($S_2^2$ analog). $S_1^2 \perp\!\!\!\perp S_2^2$, also folgt 
  \begin{align*}
    N:=\frac{(m-1)S_1^2}{\sigma _1^2}+\frac{(n-1)S_2^2}{\sigma _2^2}=\sum_{j=1}^{n+m-2}{Z_j^2}\sim \chi _{m+n-2}^2
  \end{align*}
  wobei $Z_1,...,Z _{n+m-2}$ iid $N(0,1)$. \\
  Für den Zähler gilt:
  \begin{align*}
    Z &:= \bar{X}_m-\bar{Y}_n-(\mu _1-\mu _2)\sim N \left(0, \frac{\sigma _1^2}{m}+\frac{\sigma _2^2}{n}\right) \\
    \tilde{Z}&:=\frac{Z}{\sqrt{\sigma _1^2/m+\sigma _2^2/n}}\sim N(0,1)
  \end{align*}
  Nach Theorem 2.14 sind $N \perp\!\!\!\perp \tilde{Z}$ also folgt 
  \begin{align*}
    \underbrace{\frac{\tilde{Z}}{\sqrt{\frac{N}{n+m-2}}}}_{\text{Aus Behauptung}}
    &\sim \frac{N(0,1)}{\sqrt{\frac{\chi _{n+m-2}^2}{n+m-2}}}\sim t _{n+m-2}\;\square
  \end{align*}
\end{bew}
\begin{bem}[]
  Für $\sigma _1^2=\sigma _2^2$ gilt vereinfacht sich die Statistik in (b) zu
  \begin{align*}
    \frac{\bar{X}_m-\bar{Y}_n-(\mu _1-\mu _2)}{\sqrt{(m-1)S_1^2+(n-1)S_2^2}}\cdot \sqrt{\frac{mn(m+n-2)}{m+n}}
  \end{align*}
\end{bem}
\chapter{Schätzen}
\section{Eigenschaften von Punktschätzern}
\begin{bem}[3.1]
  In diesem Kapitel: $X$ Zufallsvariable mit Werten in $\mathcal{X}$, $X\sim P^X \in \left\{P_{\vartheta }:\vartheta \in \Uptheta\right\}, \Uptheta \subseteq \mathbb{R}^n$, Statistik $T:\mathcal{X}\to \mathbb{R}^l$. \\
  \underline{Ziel}: Schätzer für $\vartheta, \psi (\vartheta ) $ basierend auf Stichprobe $X_1,X_2,...,X_n $  \\
  \underline{Bezeichnung}: $E_{\vartheta }$, $Var_{\vartheta }$ etc. 'bezüglich' $P_\vartheta $
\end{bem}
\begin{defi}{3.2}{}
  Betrachte $\psi :\Uptheta \subseteq \mathbb{R}^m\to\Gamma \subseteq \mathbb{R}^l:\vartheta \mapsto \psi (\vartheta )$ \\
  Jede Statistik $\delta :\mathcal{X}\to \Gamma$, $x \mapsto \delta (x)$ heißt (Punkt)schätzer (oder Schätzfunktion) für $\psi (\vartheta )$   
  \begin{align*}
    \vartheta (x)=\vartheta (X(w))
  \end{align*}
  heißt Schätzwert (estimator) oder Schätzung (estimate)
\end{defi}
\begin{bei}[3.3]
  $X_1,X_2,...,X_n \sim$ Bin$(1,\vartheta )$ \\
  (a) \\
  $\psi (\vartheta )=\vartheta$, $\Uptheta=\Gamma=[0,1]$ \\
  Mögliche Schätzer: 
  \begin{align*}
    &\delta _1(X_1,X_2,...,X_n )=\bar{X}=\frac{1}{n}\sum_{i=1}^{n}{X_i}\\
    &\delta _2(X_1,X_2,...,X_n )=\frac{1}{2}\\
    &\delta _3(X_1,X_2,...,X_n )=X_1
  \end{align*}
  (b)\\
  $\psi (\vartheta )=Var_{\vartheta }(X_1)=\vartheta (1-\vartheta )$ \\
  Möglicher Schätzer: 
  \begin{align*}
    \alpha _i=\delta _i(X_1,X_2,...,X_n )\cdot (1-\delta _i(X_1,X_2,...,X_n ))\quad i=1,2,3
  \end{align*}
\end{bei}
\begin{defi}{3.4 Erwartungstreue, Verzerrung}{}
  $\delta (X)$ sei Schätzer für $\psi (\vartheta )$  \\
  \underline{Bias} oder Verzerrung von $\delta (X)$
  \begin{align*}
    b(\delta ,\psi (\vartheta ))=E_{\vartheta }(\delta(X))-\psi (\vartheta ) \qquad(E \hat{\psi }-\psi )
  \end{align*}
  $\delta $ heißt \underline{erwartungstreu} oder \underline{unverzerrt}/ \underline{unbiased} falls
  \begin{align*}
    E _{\vartheta }(\delta (X))=\psi (\vartheta )\qquad(bias=0)
  \end{align*}
  \underline{Mittlere quadratische Abweichung} (\underline{M}ean \underline{S}quared \underline{E}rror)
  \begin{align*}
    MSE _{\vartheta }(\delta )=E _{\vartheta }\left( (\delta (X)-\psi (\vartheta ))^2 \right)=Var _{\vartheta }(\delta (X))+b(\delta ,\psi (\vartheta ))^2
  \end{align*}
  denn 
  \begin{align*}
    E(\delta -\psi )^2 &= E(\delta -E \delta +E  \delta   -\psi )^2\\
                       &=E(\delta -E \delta )^2+E((\underbrace{E \delta  -\psi }_{bias}) ^2)+2E(\underbrace{(\delta -E \delta )}_{E=0}\underbrace{(E \delta -\psi )}_{\text{konst}}) \\
                       &= Var \delta +bias^2
  \end{align*}
\end{defi}
\begin{bei}[3.5]
  $X:=X_1,X_2,...,X_n$ iid $\sim U[0,\vartheta ]$, $f _{\vartheta }=\frac{1}{\vartheta }1_{[0,\vartheta ]}(x)$, $EX_1=\frac{\vartheta }{2}$  \\
  Mögliche Schätzer: \\
  $\delta _1(X)=2 \bar{X}=2 \frac{1}{n}\sum_{i=1}^{n}{X_i}$ ($\leadsto$ Momentenmethode)\\
  $\delta _2(X)=\max\limits _{i=1,...,n}X_i=:X _{(n)}$ ($\leadsto$ Max. Likelihood) 
  \begin{align*}
    E \delta _1(X) &= E(2 \bar{X})=2 \frac{1}{n}\sum_{i=1}^{n}{\underbrace{EX_1}_{\frac{\vartheta }{2}}}=\vartheta 
  \end{align*}
  erwartungstreu, d.h. $bias=0$
  \begin{align*}
    MSE(\delta _1(X)) &= Var (\delta _1(X))=Var\left(2 \frac{1}{n}\sum_{i=1}^{n}{X_i}\right)=\frac{4}{n^2}\sum_{i=1}^{n}{\underbrace{VarX_i}_{\frac{1}{12}(\vartheta -0)^2}}=\frac{4}{n^2}n \frac{1}{12}\vartheta ^2=\frac{\vartheta ^2}{3n}
  \end{align*}
  Dichte von $X _{(n)}$ (Übung $\frac{d}{dx} P(X_1 \leq x,X_2 \leq x,...,X_n \leq x)$), $x \in (0,\vartheta )$
  \begin{align*}
    f _{X _{(n)}}&=n(F _{\vartheta }(x))^{n-1}f _{\vartheta }(x) \text{ mit } F _{\vartheta }(x)=\int_{0}^{x}{\frac{1}{\vartheta }dt}=\frac{x}{\vartheta } \\
                 &=n \left(\frac{x}{\vartheta }\right)^{n-1} \frac{1}{\vartheta }1_{[0,\vartheta ]}(x) \\
                 &=n \frac{x^{n-1}}{\vartheta ^n}1_{[0,\vartheta ]}(x)
  \end{align*}
  \begin{align*}
    E _{\vartheta }(\delta_2(X))&=\int_{0}^{\vartheta }{x \cdot n \frac{x^{n-1}}{\vartheta ^n}dx}
    =\frac{n}{\vartheta ^n}\int_{0}^{\vartheta }{x^{n}dx}=\frac{n}{\vartheta ^n}\left[\frac{x^{n+1}}{n+1}\right]_0^{\vartheta } \\
                                &=\frac{n}{\vartheta ^n}\frac{\vartheta ^{n+1}}{n+1}=\frac{n}{n+1}\vartheta \neq \vartheta \Rightarrow \text{ nicht erwartungstreu}
  \end{align*}
  \begin{align*}
    b(\delta _2(X),\vartheta )&=E _{\vartheta }(\delta _2(X),\vartheta )-\vartheta = \vartheta \left(\frac{n}{n+1}-1\right)=\vartheta \frac{n-(n+1)}{n+1}\\&=-\frac{1}{n+1}\vartheta \overset{n \to \infty }\longrightarrow 0 \text{ 'asymptotisch erwartungstreu'}
  \end{align*}
  \begin{align*}
    Var(\delta _2(X))&=\int_{0}^{\delta }{x^2 n \frac{x^{n-1}}{\vartheta ^n}dx}-\left(\frac{n \vartheta }{n+1}\right)^2 \overset{\text{Ü}}=\frac{n \vartheta ^2}{(n+1)^2(n+2)}
  \end{align*}
  \begin{align*}
    MSE(\delta _2)&=Var (\delta _2)+(bias(\delta _2))^2
    =\frac{n \vartheta ^2+\vartheta ^2(n+2)}{(n+1)^2(n+2)}=\frac{\vartheta ^2(2n+2)}{(n+1)^2(n+2)} \\
                  &=\frac{2 \vartheta ^2}{(n+1)(n+2)}=O \left(\frac{1}{n^2}\right)
  \end{align*}
  $MSE(\delta _1)$ war $O \left(\frac{1}{n}\right)$, d.h. $\delta _2$ konvergiert schneller als $\delta _1$. \\
  $MSE(\delta _2)<MSE(\delta _1)$ für $n>?$ 
  \begin{align*}
    \Leftrightarrow \frac{2 \vartheta ^2}{(n+1)(n+2)}<\frac{\vartheta ^2}{3n}&\Leftrightarrow 6n < (n+1)(n+2)=n^2+3n+2 \\
                                                                             & \Leftrightarrow 3n < n^2+2 \text{ also für }n \geq 3
  \end{align*}
\end{bei} 
\begin{bem}[3.6]
  Sei $\delta $ Schätzer für $\psi (\vartheta )$ mit Werten in $\Gamma $. \\
  \underline{Verlustfunktion} $L:\Uptheta \times \Gamma \to \mathbb{R} _{\geq 0}$ (z.B. $L(\vartheta ,\gamma )=|\psi (\vartheta)-\gamma|^r$), $\gamma $ 'Schätzwert' mit 
  $L(\vartheta ,\psi (\vartheta )=0$ $\forall\;\vartheta \in \Uptheta$ \\
  \underline{Risiko} $R(\vartheta ,\delta )=E _{\vartheta }(L(\vartheta ,\delta (X)))$ (erwarteter Verlust) z.B. 
  $E _{\vartheta }(\psi (\vartheta) -\delta (X))^2)$ MSE \\
  Mögliche Ansätze für Schätzer: minimiere Risiko\\
  z.B. \underline{Minimax-}Ansatz: Wähle das $\delta $ welches das maximale Risiko $\sup\limits _{\vartheta \in \Uptheta}R(\vartheta ,\delta )$  
  minimiert \\
  \underline{Bayes-}Ansatz: minimiere $\int_{\Uptheta}^{}{R(\vartheta ,\delta )w(\vartheta )d \vartheta }$ bezüglich $\delta $  ($w(\vartheta )$ 'Vorinformation') 'Bayes-Risiko'
\end{bem}
\begin{defi}{3.7 asymptotische Eigenschaften}{}
  $X_1,X_2,...,X_n $ Folge von Zufallsvariablen, $X^{(n)}:=(X_1,X_2,...,X_n)$ mit Werten in $\mathcal{X}_n$, $\delta _n:\mathcal{X}\to \Gamma $ sei Schätzer für $\psi (\vartheta ), \psi :\Uptheta\to \Gamma $. \\
  $\delta _n(X^{(n)})$ heißt \\
  (a) \underline{asymptotisch erwartungstreu}, falls für alle $\vartheta \in \Uptheta $ gilt
  \begin{align*}
    \lim _{n\to \infty }b(\delta _n,\psi (\vartheta ))=0 \text{ d.h. } E _{\vartheta }(\delta _n(X^{(n)}))\overset{n \to \infty }\longrightarrow \psi (\vartheta )
  \end{align*} 
  (b) \underline{(schwach) konsistent}, falls für alle $\vartheta \in \Uptheta$ gilt:
  \begin{align*}
    \delta _n(X^{(n)})\overset{\text{P}}\to \psi (\vartheta ) \text{ d.h. }\lim _{n\to \infty }P(||\delta _n(X^{(n)})-\psi (\vartheta )||\geq \varepsilon )=0 \; \forall \varepsilon >0
  \end{align*}
  (stark konsistent, falls fast sichere Konvergenz)
\end{defi}  
\begin{bei}[3.8 Fortsetzung von 3.3a und 3.3b]
  (a) \\
 $\delta _1=\bar{X}_n$ ist erwartungstreu und konsistent für $\vartheta $ (LLN Law-of-Large-Numbers) \\
 $\delta _2=\frac{1}{2}$ ist weder erwartungstreu noch konsistent \\
 $\delta _3=X_1$ ist erwartungstreu aber nicht konsistent, weil $P(|X_1-\vartheta |>\varepsilon)\not \to 0$\\
 (b) \\
 $\alpha _1=\bar{X}_n(1-\bar{X}_n)$ ist konsistent da stetige Funktion von $\bar{X}$ (continuous mapping) \\
 $\alpha _1$ ist amsymptotisch erwartungstreu (Ü) \\
 (c) \\
 Sei $X_1,X_2,...,X_n $ iid $E|X|^k< \infty $ \\
 $\frac{1}{n}\sum_{i=1}^{n}{X_i^k}\overset{\text{P}}\to EX_1^k$ (LLN) d.h. $\frac{1}{n}\sum_{i=1}^{n}{X_i^k}$ ist erwartungstreu und konsistent für $E(X_1^k)$ 
\end{bei}
\begin{lem}{3.9}{}
  $\delta _n=\delta _n(X_1,X_2,...,X_n)$ sei Folge von asymptotisch erwartungstreuer Schätzer für $\psi (\vartheta )$, dann gilt 
  \begin{align*}
    \lim_{n\to \infty }{Var _{\vartheta }(\delta _n)}=0 \text{ impliziert } \delta _n \text{ konsistent für }\psi (\vartheta )
  \end{align*}
\end{lem}
\begin{bew}[]
  Sei $\varepsilon >0$, dann folgt mit der Markow-Ungleichung (Chebyshev-Ungleichung)
  \begin{align*}
    P _{\vartheta }(|\vartheta _n-\psi (\vartheta )| \geq \varepsilon )
    &\leq \frac{1}{\varepsilon ^2}\underbrace{E \left((\delta _n-\psi (\vartheta ))^2\right)}_{MSE(\vartheta )} \\
    &=\frac{1}{\varepsilon ^2}(\underbrace{Var _{\vartheta }\delta _n}_{\to0 \text{ (Vor.)}}+\underbrace{(b(\delta _n,\psi (\vartheta )))^2}_{\to0 \text{ (Vor.)}}) \overset{n\to \infty }\to0
  \end{align*}
  d.h. $MSE\to0$ (für Konsistenz) $\square$ 
\end{bew}
\begin{bei}[3.10 Erwartungstreue? Konsistenz?]
  Betrachte $X_1,X_2,...,X_n $ iid, $VarX_1 < \infty $ \\
  (a) $\delta _2=X _{(n)}=\max\limits_{i=1,...,n}X_i$, $X_i\sim U[0,\vartheta ]$  (siehe Beispiel 3.5) ist nicht erwartungstreu, ist konsistent \\
  (b) $\bar{X}_n=\frac{1}{n}\sum\limits_{i=1}^{n}{X_i}$ ist erwartungstreu, ist konsistent, da
  \begin{align*}
    E \bar{X}=EX_1,Var \bar{X}_n=\frac{VarX_1}{n} 
  \end{align*} 
  (c) $\hat{S}_n^2=\frac{1}{n-1}\sum_{}^{}{(X_i-\bar{X})^2}$ Stichprobenvarianz (Annahme $EX_1^4<\infty $)
  \begin{align*}
    \hat{S}_n^2&=\frac{n}{n-1}\underbrace{\frac{1}{n}\sum_{i=1}^{n}{(X_i-\bar{X}_n)^2}}_{=:\hat{\sigma }^2}
  \end{align*}
  \begin{align*}
    E \hat{\sigma }^2
    &=\frac{1}{n}\sum_{i=1}^{n}{E(X_i-\bar{X})^2} \\
    &=\frac{1}{n}\sum_{i=1}^{n}{E(X_i-EX_1+EX_1-\bar{X})^2} \\
    &=\frac{n-1}{n}VarX_1 \text{ (Ü bzw. siehe 2.10 (3) $ES _{11}=...$)} \\
    \Rightarrow E \hat{S}_n^2
    &=\frac{n}{n-1}E \hat{\sigma }^2 \\
    &=\cancel{\frac{n}{n-1}}\cancel{\frac{n-1}{n}}VarX_1=VarX_1 \text{ erwartungstreu}
  \end{align*}
  \begin{align*}
    Var \hat{S}_n^2
    &\overset{\text{Ü}}=\frac{1}{n}E((X_1-EX_1)^4)+\frac{3-n}{n(n-1)}(VarX_1)^2=O \left(\frac{1}{n}\right)\overset{n\to \infty }\to 0
  \end{align*}
  also auch konsistent.
\end{bei}
\chapter{Suffizienz und Vollständigkeit}
\begin{bei}[4.1]
  $X_1,X_2,...,X_n $ Bin$(1,\vartheta )$ z.B. Daten: $00101110101100001$ \\
  Frage: Enthält $\hat{\vartheta }=\frac{1}{n}\sum_{i=1}^{n}{X_i}$ alle Informationen über $\vartheta $? Oder gibt es zusätzliche Informationen in der Stichprobe?
\end{bei}
\begin{align*}
  T(X)=\sum_{i=1}^{n}{X_i}, \quad u_i \in \left\{0,1\right\}
\end{align*}
\begin{align*}
  P _{\vartheta }(X_1=u_1,...,X_n=u_n|T(X)=k)
  &=\frac{P _{\vartheta }(X_1=u_1,...,X_n=u_n,T(X)=k)}{P _{\vartheta }(T(X)=k)} (=0 \text{ für }\sum_{}^{}{u_i}\neq k)\\
  &=\frac{P(X_1=u_1,..,X_n=u_n)}{P _{\vartheta }(T(X)=k)} \text{ für }\sum_{}^{}{u_i}= k\\
  &=\frac{\prod_{i=1}^{n}{P _{\vartheta }(X_i=u_1)}}{P _{\vartheta }(T(X)=k)} \\
  &=\frac{\prod_{i=1}^{n}{\vartheta ^{u_i}(1-\vartheta )^{1-u_i}}}{\binom{n}{k}\vartheta ^k(1-\vartheta )^{n-k}} \\
  &=\frac{\vartheta ^{\overbrace{\Sigma u_i}^{k} }(1-\vartheta )^{n-\overbrace{\Sigma u_i}^{k} }}{\binom{n}{k}\vartheta ^k(1-\vartheta )^{n-k}} \\
  &=\begin{cases}
    \frac{1}{\binom{n}{k}} &\text{ für }\sum u_i=k\\
    0& \text{ sonst}
  \end{cases}
\end{align*}
Die verbleibende Information ist also unabhängig von $\vartheta \in \Uptheta=(0,1)$.  \\
(Zähl-)Dichte von $(X_1,X_2,...,X_n)$ :
\begin{align*}
  f _{\vartheta }(x_1,...,x_n)&\overset{\text{oben}}
  =\vartheta ^{\Sigma x_i}(1-\vartheta )^{n-\Sigma x_i}=\left(\frac{\vartheta }{1-\vartheta }\right)^{\Sigma x_i}(1-\vartheta )^k
\end{align*}
\begin{defi}{4.2}{}
  Eine Statistik $T=T(X_1,...,X_n)$ heißt \underline{suffizient} für $\vartheta $ (oder $\mathcal{P}=\left\{P _{\vartheta }:\vartheta \in \Uptheta\right\}$), falls die bedingte Verteilung von $(X_1,X_2,...,X_n)$ gegeben $T(X)=t$ (fest) unabhängig von $\vartheta $ ist.  
\end{defi}
\begin{bem}[4.3]
  Betrachte $T(X)$ statt $X=(X_1,X_2,...,X_n )$ (keine zusätzliche Info über $\vartheta $)$\longrightarrow $  Datenreduktion \\
  Wünschenswert: maximale Datenreduktion $\longrightarrow $ 'Minimal-Suffizienz' (später)\\
  $T(X_1,X_2,...,X_n )=(X_1,X_2,...,X_n )$ ist suffizient, soll aber ausgeschlossen werden. \\
  \textbf{Beispiel} 
  \begin{align*}
    P(X=x|X=t)=\frac{P(X=x,X=t)}{P(X=t)}=\begin{cases}
       \frac{P(X=t)}{P(X=t)}=1&x=t\\
       0&\text{sonst}
    \end{cases}
  \end{align*}
  Maßtheorie: %Suffizienz ist 
  Suffizient = Eigenschaft von $\sigma $-Alg. 
\end{bem}
\begin{bei}[4.4]
  $X,Y\sim$ Pois$(\lambda )$, $X,Y$ unabhängig, $T=X+Y$\\
  $P^{X|T=t}=$ Bin$(t,\frac{1}{2})$:
  \begin{align*}
    P(X=x|T=t)
    &=\frac{P(X=x,X+Y=t)}{P(X+Y=t)} \\
    &=\frac{P(X=x,Y=t-x)}{P(X+Y=t)} \\
    &=\frac{P(X=x)P(Y=t-x)}{P(\underbrace{X+Y}_{\sim \text{Pois}(2\lambda)}=t)} \\
    &=\frac{e^{-\lambda }\frac{\lambda ^x}{x!}e^{-\lambda }\frac{\lambda ^{t-x}}{(t-x)!}}{e^{-2 \lambda }\frac{(2 \lambda )^t}{t!}}\\
    &=\frac{e^{-2 \lambda }t!\lambda ^t}{e^{-2 \lambda }x!(t-x)!(2 \lambda )^t} \\
    &=\binom{t}{x}\left(\frac{1}{2}\right)^t=\binom{t}{x}\left(\frac{1}{2}\right)^x \left(1-\frac{1}{2}\right)^{t-x} \\
    & \text{Bin}\left(t,\frac{1}{2}\right) \text{ Dichte für }x=0,1,...,t
  \end{align*}
  Analog 
  \begin{align*}
    P(X=x,Y=y|T=t)
    &=\frac{P(X=x,Y=y,X+Y=t)}{P(X+Y=t)} \\
    &=\frac{P(X=x,Y=t-x,X+Y=t)}{P(X+Y=t)} \\
    &\overset{\text{oben}}=\binom{t}{x}\left(\frac{1}{2}\right)^t \text{ für }X+Y=t, \quad 0 \text{ sonst}
  \end{align*}
  Die bedingte Verteilung von $(X,Y)$ gegeben $T$ ist Bin$\left(t,\frac{1}{2}\right)$, also unabhängig vom Parameter $\lambda $
  \begin{align*}
    \Rightarrow T \text{ ist suffizient für }\lambda 
  \end{align*}
\end{bei}
\begin{theo}{4.5 Faktorisierungssatz (Neyman-Kriterium)}{}
  Sei $X$ stetige oder diskrete Zufallsvariable mit Dichte $f _{\vartheta }$, $\vartheta \in \Uptheta$, $T:\mathcal{X}\to \mathbb{R}$ Statistik.\\
  Dann gilt 
  \begin{align*}
    &T \text{ ist suffizient für }\vartheta \\
    &\Leftrightarrow \exists\text{ Funktion }h:\mathcal{X}\to \mathbb{R}_{\geq 0} \text{ unabhängig von }\vartheta  \\
    & \text{ und zu jedem }\vartheta \in \Uptheta \text{ gibt es eine Funktion }g _{\vartheta }:\mathcal{T}\to \mathbb{R}_{\geq 0} \text{ mit } \\
    &(*)\quad f _{\vartheta }(x)=g _{\vartheta }(T(x))h(x) \text{ für alle }x \in \mathcal{X},\vartheta \in \Uptheta
  \end{align*}
\end{theo}
\begin{bew}[diskreter Fall]
  '$\Rightarrow $': Sei $T$ suffizient und $x \in \mathcal{X}$. Falls 
  \begin{align*}
    f _{\vartheta }(x)=P _{\vartheta }(X=x)=0 \text{ für alle } \vartheta 
  \end{align*}
  setze $h\equiv 0$ für alle $x \in \mathcal{X}$ und $g _{\vartheta }$ beliebig. Ansonsten 
  \begin{align*}
    \exists \vartheta _0:P _{\vartheta _0}(X=x)>0 \Rightarrow P _{\vartheta _0}(T(X)=T(x))>0
  \end{align*}
  und daraus folgt 
  \begin{align*}
    f _{\vartheta _0}(x)
    &=P _{\vartheta _0}(X=x)=P _{\vartheta _0}(X=x,T(X)=T(x)) \\
    &=P _{\vartheta _0}(X=x|T(X)=T(x))P _{\vartheta _0}(T(X)=T(x))
  \end{align*}
  Da $T$ suffizient ist, ist $P _{\vartheta _0}=P$. Also ist dies äquivalent zu 
  \begin{align*}
    h(x)\cdot g _{\vartheta_0 }(T(x))>0
  \end{align*}
  $(*)$ gilt auch wenn $g _{\vartheta _1}(T(x))=0$ für ein $\vartheta _1:\underbrace{P _{\vartheta _1}(X=x)}_{0}=\underbrace{g _{\vartheta _1}(T(x))}_{0}\cdot h(x)$   \\
  '$\Leftarrow$': Es gelte $(*)$. Sei $t_0 \in \mathcal{T}$ mit $P _{\vartheta }(T(X)=t_0)>0$. Dann gilt 
  \begin{align*}
    P _{\vartheta }(T(X)=t_0)
    &=\sum_{x:T(x)=t_0}^{}{P _{\vartheta }(X=x)} \\
    &=\sum_{x:T(x)=t_0}^{}{g _{\vartheta }(T(x))h(x)}\\
    &=g _{\vartheta }(t_0)\sum_{x: T(X)=t_0}^{}{h(x)}\quad(**)
  \end{align*}
  Für $x$ mit $T(x)\neq t_0$ ist $P _{\vartheta }(X=x|T(X)=t_0)=0$ (unabhängig von $\vartheta $). \\
  Sei also $T(x)=t_0:$
  \begin{align*}
&P _{\vartheta }(X=x|T(X)=t_0)=\frac{P _{\vartheta }(X=x)}{P _{\vartheta }(T(X)=t_0)} \\
&\overset{(*)}{\underset{(**)}{=}}\frac{g _{\vartheta }(T(x))h(x)}{g _{\vartheta }(t_0)\sum_{x:T(x)=t_0}^{}{h(x)}}=\frac{h(x)}{\sum_{x:T(x)=t_0}^{}{h(x)}}
  \end{align*}
  ist unabhängig von $\vartheta$, d.h. $T$ ist suffizient $\square$ 
\end{bew}
\begin{bem}[4.6]
  Für den allgemeinen maßtheoretischen Beweis siehe Witting, Mathematische Statistik I, Seite 343.
\end{bem}
\begin{lem}{4.7}{}
  Sei $T:\mathcal{X}\to \mathcal{T}$ suffizient für $\vartheta \in \Uptheta$, $k:\mathcal{T}\to \mathcal{T}^*$ bijektiv (messbar) dann gilt 
  \begin{align*}
    T^*=k \circ T \text{ ist suffizient für }\vartheta 
  \end{align*}
\end{lem}
\begin{bew}[]
  Ü: Betrachte $k(T(X))=t, k ^{-1}$ 
\end{bew}
\begin{bei}[4.8]
  (a) \\
  In Beispiel 4.1: Dichte von $X=(X_1,X_2,...,X_n )$, $X_1,X_2,...,X_n $ iid $\sim$ Bin$(1,\vartheta )$,\\
  $f _{\vartheta }(x)=\underbrace{\left(\frac{\vartheta }{1-\vartheta }\right)^{T(x)}(1-\vartheta )^n}_{g _{\vartheta }(T(X))}\cdot \underbrace{1}_{h(x)}$ mit $T(x)=\sum_{i=1}^{n}{X_i}$  $\overset{4.5}\Rightarrow T$ suffizient\\
  (b) \\
  $X=(X_1,X_2,...,X_n )$ mit $X_1,X_2,...,X_n $ iid $\sim N(\mu ,\sigma ^2)$, $\vartheta =(\mu ,\sigma ^2)$
  \begin{align*}
    f _{\vartheta }(x)
    &=\frac{1}{(2 \pi \sigma ^2)^{\frac{n}{2}}}\exp \left(-\frac{1}{2 \sigma ^2} \sum_{}^{}{(X_i-\mu )^2}\right) \\
    &=\frac{1}{(2 \pi \sigma ^2)^{\frac{n}{2}}}\exp \bigg(-\frac{1}{2 \sigma ^2} \underbrace{\sum_{}^{}{X_i^2}}_{T_2}{-\frac{1}{2 \sigma ^2} \sum_{}^{}{\mu ^2}+\frac{2}{2 \sigma ^2}\mu} \underbrace{\sum_{}^{}{X_i}}_{T_1}\bigg) \\
    &=g _{\vartheta }(T_1(x),T_2(x))\cdot 1
  \end{align*}
  $\Rightarrow T=(T_1,T_2)$ ist suffizient für $\vartheta =(\mu ,\sigma ^2)$  
 
\end{bei}
\begin{defi}{4.9}{}
  Sei $X$ Zufallsvariable (diskret/ stetig) mit Dichte $f \in \left\{f _{\vartheta }:\vartheta \in \Uptheta\right\}$, $T:\mathcal{X}\to \Gamma \subseteq \mathbb{R}^k$ Statistik. \\
  $T$ heißt \underline{vollständig}, falls für jede (messbare) Funktion $g:\Gamma \to \mathbb{R}$ gilt:
  \begin{align*}
    E _{\vartheta }(g(T(X)))=0 \text{ für alle }\vartheta \in \Uptheta \Rightarrow P _{\vartheta }(g(T(X))=0)=1 \text{ für alle }\vartheta 
  \end{align*}
  d.h. $g$ verschwindet fast sicher auf $T(\mathcal{X})$.   
\end{defi}
\begin{bei}[4.10]
  (a) \\
  $X_1,X_2,...,X_n $ iid $\sim$ Bin$(1, \vartheta )$, $\vartheta \in \Uptheta=(0,1)$ \\
  $T(X)=\sum_{i=1}^{n}{X_i}$ mit $T \sim$ Bin$(n, \vartheta )$ ist suffizient.  
  \begin{align*}
    E _{\vartheta }(g(T(X)))
    &=\sum_{t=0}^{n}{g(t)\binom{n}{t}\vartheta ^t(1-\vartheta )^{n-t}}
  \end{align*}
  ist Polynom $n$-ten Grades in $\vartheta $. Also ist das Polynom nur dann $\equiv 0$ wenn alle Koeffizienten gleich $0$ sind, d.h. 
  \begin{align*}
    g(t)=0 \text{ für alle }t \in \left\{0,1,...,n\right\}
  \end{align*}
  $\Rightarrow T$ ist vollständig. \\
  (b) \\
  $X_1,X_2,...,X_n $ iid $\sim N(\vartheta ,\vartheta ^2)$ \\
  Bekannt: $T(X)=(\sum_{}^{}{X_i},\sum_{}^{}{X_i^2})$ ist suffizient (4.8), aber \\
  $T$ ist nicht vollständig: 
  \begin{align*}
    \exists g(u,v)=2u^2-(n+1)v \neq 0
  \end{align*}
  \begin{align*}
    E _{\vartheta }(g(T(X)))
    &=E _{\vartheta }(g(\sum_{}^{}{X_i},\sum_{}^{}{X_i^2})) \\
    &=E _{\vartheta }\left(2 (\sum_{}^{}{X_i})^2-(n+1)\sum_{}^{}{X_i^2}\right) \\
    &\overset{\text{Ü}}=0
  \end{align*}
\end{bei}
\begin{theo}{4.11}{}
  Sei $X:\Omega \to \mathbb{R}^n$ diskrete oder stetige Zufallsvariable mit Dichte $f _{\vartheta }(x):\mathbb{R}^n\to \mathbb{R}$ und \\
  Träger $A=\left\{x \in \mathbb{R}^n:f _{\vartheta }(x)>0\right\}$ der nicht von $\vartheta $ abhängt (also z.B. \underline{nicht} $U(0,\vartheta )$). \\
  Angenommen es gibt Abbildungen $Q_1,...,Q_k,D:\Uptheta \to \mathbb{R}$ und $T_1,...,T_k,S:\mathbb{R}^n\to \mathbb{R}$ ($k \leq n$), sodass
  \begin{align*}
    f _{\vartheta }(x)=\exp \left(\sum_{i=1}^{k}{Q_i(\vartheta )T_i(x)}+D(\vartheta )+S(x)\right) \text{ für alle }\vartheta \in \Uptheta, x \in A
  \end{align*}
  ('$k$-parametrige Exponentialfamilie') \\
  und die Menge
  \begin{align*}
    \mathcal{Q}=\left\{(Q_1(\vartheta ),...,Q_k(\vartheta )):\vartheta \in \Uptheta\right\} \text{ist offene Teilmenge von } \mathbb{R}^k
  \end{align*}
  Dann ist 
  \begin{align*}
    T=(T_1(X),...,T_k(X))
  \end{align*}
  suffizient und vollständig.
\end{theo}
\begin{bew}[]
  Der Träger sei unabhängig von $\vartheta $. \\ 
  Zunächst die Suffizienz:
  \begin{align*}
    f _{\vartheta }(x)
    &=g _{\vartheta }(T(x))\cdot \underbrace{\exp(S(x))}_{h(x)}\overset{4.5}\Rightarrow \text{ Suffizienz}
  \end{align*}
  Nun zur Vollsändigkeit: für $X$ diskret, $k=1$ (Allgemeiner Fall siehe wieder Witting oder Lehmann, Testing statistical hypothesis) \\
  Angenommen 
  \begin{align*}
    E _{\vartheta }(g(T))
    &=\sum_{t \in T(\mathcal{X})}^{}{g(t)P _{\vartheta }(T=t)}\\
    &=\sum_{t}^{}{g(t)\exp(Q(\vartheta )t+D(\vartheta )+S^*(t))} \\
    &=0\;\forall\;\vartheta \in \Uptheta\quad (*)
  \end{align*}
  Sei $(\alpha ,\beta ) \subseteq \Uptheta \subseteq \mathbb{R}$, $\xi =Q(\vartheta )$, $\xi_0 \in (\alpha ,\beta )$ fest. \\
  Sei $g=g^+-g^-$ mit $g^+=\max(g,0)$, $g^-=\max(-g,0)$ dann folgt mit $(*)$
  \begin{align*}
    \underbrace{\sum_{t}^{}{g^+(t)\exp(\xi t+S^*(t))}}_{=:a(\xi)}\cancel{\exp(D(\vartheta )})
    &=\sum_{t}^{}{g^-(t)\exp(\xi t+S^*(t))}\cancel{\exp(D(\vartheta )})
  \end{align*}
Mit den Dichten
\begin{align*}
  p^+:=\frac{1}{a(\xi_0)}g^+\exp(\xi_0+S^*(t)),\quad p^-:=\frac{1}{a(\xi_0)}g^-\exp(\xi_0+S^*(t))
\end{align*}
(Wiederholung: Die charakteristische Funktion $Ee^{itX}$ bzw. momenterzeugende Funktion $Ee^{tx}$ charakterisieren Verteilung, mit der momenterzeugenden Funktion ist oft leichter zu rechnen, sie existiert aber im Vergleich zur charakteristischen Funktion nicht immer) \\
Die momenterzeugende Funktion von $Z\sim p^+$ ist gleich
\begin{align*}
  M^+(s)
  &=E(e^{sZ}) \\
  &=\frac{1}{a(\xi_0)}\sum_{t}^{}{\exp(\underbrace{st+\xi_0t}_{(s+\xi_0)t}+S^*(t))g^+(t)}\\
  &\overset{(*)}=\frac{1}{a(\xi_0)}\sum_{t}^{}{\exp((s+\xi_0)t+S^*(t))g^-(t)}=M^-(s)
\end{align*}
der momenterzeugenden Funktion von $p^-$ für alle $s+\xi_0 \in (\alpha ,\beta )$ d.h. für alle $s \in (\alpha -\xi_0,\beta -\xi_0)\ni 0$ offen, d.h. $M^+$ und $M^-$ stimmen auf einer offenen Umgebung von $0$ überein, demnach ist $p^+=p^-$ fast sicher und somit $g^+=g^-$ fast sicher und somit $g=0$ in auf $T(\mathcal{X})\Rightarrow $ Vollständigkeit $\square$ 
\end{bew}
\begin{bei}[4.12]
  Betrachte $X\sim N(\mu ,\sigma ^2)$, $2$-parametrige Exponentialfamilie ($\vartheta =(\mu ,\sigma ^2$)):
  \begin{align*}
    f _{\vartheta }(x)
    &=\frac{1}{\sqrt{2 \pi \sigma ^2}}\exp \left(-\frac{1}{2 \sigma ^2}(x-\mu )^2\right) \\
    &=\underbrace{\exp(\ln((2\pi \sigma ^2)^{-\frac{1}{2}}))}_{\exp(-\frac{1}{2}\ln(2 \pi \sigma ^2))}\cdot \exp \left(-\frac{x^2}{2 \sigma ^2}+\frac{2x \mu }{2 \sigma ^2}-\frac{\mu ^2}{2 \sigma ^2}\right) \\
    &=\exp \bigg(\underbrace{-\frac{1}{2 \sigma ^2}}_{Q_1(x)}\underbrace{x^2}_{T_1(\vartheta )}+\underbrace{x}_{T_2} \underbrace{\frac{\mu }{\sigma ^2}}_{Q_2}-\frac{1}{2}\left(\frac{\mu ^2}{\sigma ^2}+\ln(2 \pi \sigma ^2)\right)\bigg)
  \end{align*}
  Für $X_1,X_2,...,X_n $ iid $N(\mu ,\sigma ^2)$ erhält man
  \begin{align*}
    T_1=\sum_{}^{}{X_i^2},\quad T_2=\sum_{}^{}{X_i}\text{ mit } \mathcal{Q}=\mathbb{R}^- \times \mathbb{R} \text{ offen}
  \end{align*}
  $\Rightarrow T=(T_1,T_2)$ suffizient und vollständig. \\
\end{bei}
$T$ vollständig $\Leftrightarrow \forall g$ gilt $E _{\vartheta }(g(T(X)))=0 \Rightarrow P _{\vartheta }(g(T(X))=0)=1 \; \forall \vartheta $  
\begin{bem}[4.13]
  Suffiziente Statistiken sind \underline{nicht} eindeutig.
\end{bem}
\begin{bei}[]
  $X_1,X_2,...,X_n \overset{iid}\sim N(0,\sigma ^2)$ 
  \begin{align*}
    f _{\sigma ^2}(x)
    &=(2 \pi \sigma ^2)^{-\frac{n}{2}}\exp \left(-\frac{1}{2 \sigma ^2}\sum_{}^{}{X_i^2}\right)\cdot 1 \\
    &=g _{\sigma ^2}(T(x))h(x)
  \end{align*}
  Suffizient sind 
  \begin{align*}
    & T_1(X)=(X_1^2,X_2^2,...,X_n^2 )\\
    & T_2(X)=(X_1^2+X_2^2,X_3^2,...,X_n^2)\\
    & T_3(X)=\sum_{i=1}^{n}{X_i^2}
  \end{align*}
  $T_1$ ist nicht vollständig. Betrachte $g(x)=x_1-x_2$. 
  \begin{align*}
    Eg(T_1(X))=E(X_1^2-X_2^2)=0 \text{ (obwohl }g \neq 0 \text{)}
  \end{align*}
  $T_2$ ist nicht vollständig. Betrachte $g(x)=x_1-2x_2$ 
  \begin{align*}
    Eg(T_2(X))=E(X_1^2+X_2^2-2X_3^2)=EX_1^2+EX_2^2-2EX_3^2=0
  \end{align*}
  $T_3$ ist vollständig, siehe 4.11/4.12
\end{bei}
\begin{defi}{4.14}{}
  Eine suffiziente Statistik $T^*$ heißt \underline{minimal-suffizient} für $\vartheta \in \Uptheta$, falls $T^*$ über jede für $\vartheta $ suffiziente Statistik faktorisiert, d.h.
  \begin{align*}
    \forall \;T \text{ suffizient }\exists \;H:T^*(X)=H(T(X))
  \end{align*}
  D.h. $T^*$ ist suffizient und nimmt möglichst wenige Werte an. 
\end{defi}
\begin{bei}[4.15]
  Sei $\Uptheta=(\vartheta _0,\vartheta _1,...,\vartheta _k)$ und $\mathcal{P}=\left\{P _{\vartheta }:\vartheta \in \Uptheta\right\}$ eine endliche Familie von Verteilungen, mit Dichten $f _{\vartheta_j }$ für $j=0,1,...,k$ die denselben Träger haben. Dann ist 
  \begin{align*}
    T^*(X)=\left(\frac{f _{\vartheta _1}(X)}{f _{\vartheta _0}(X)},...,\frac{f _{\vartheta _k}(X)}{f _{\vartheta _0}(X)}\right)
  \end{align*}
  minimal suffizient.
\end{bei}
\noindent \textbf{Begründung}: \\
1.) Sei $h(x)=f _{\vartheta _0}(x)$ mit $\vartheta _0$ fest, bekannt. \\
Definiere $g _{\vartheta _j}(x)=x_j$ für $j=1,...,k$, $x=(x_1,...,x_k)$. \\
Dann gilt 
\begin{align*}
 f _{\vartheta _j}=\begin{cases}
  \frac{f _{\vartheta _j}(x)}{f _{\vartheta _0}(x)}f _{\vartheta _0}(x)=g _{\vartheta _j}(T^*(x))h(x) &j=1,...,k\\
  h(x)\cdot 1 \text{ mit }g _{\vartheta _0}(T^*(x)):=1 &j=0
 \end{cases} 
\end{align*}
Mit Theorem 4.5 folgt, dass $T^*$ suffizient ist. \\
2.) Sei nun $T$ beliebig suffizient. Mit Theorem 4.5 folgt 
\begin{align*}
  \exists\;\tilde{h},\tilde{g}_{\vartheta }(T(x)):f _{\vartheta }(x)=\tilde{g}_{\vartheta }(T(x))\tilde{h}(x) \quad \forall\; \vartheta 
\end{align*}
Daraus folgt
\begin{align*}
  T^*(x)=\left(\frac{\tilde{g}_{\vartheta _1}(T(x))\cancel{\tilde{h}(x)}}{\tilde{g}_{\vartheta _0}(T(x))\cancel{\tilde{h}(x)}},...,\frac{\tilde{g}_{\vartheta _k}(T(x))\cancel{\tilde{h}(x)}}{\tilde{g}_{\vartheta _0}(T(x))\cancel{\tilde{h}(x)}}\right)=H(T(x))
\end{align*}
mit 
\begin{align*}
  H(y)=\left(\frac{\tilde{g}_{\vartheta_1 }(y)}{\tilde{g}_{\vartheta _0}(y)},...,\frac{\tilde{g}_{\vartheta_k }(y)}{\tilde{g}_{\vartheta _0}(y)}\right)
\end{align*}
also ist $T^*$ per Definition minimal-suffizient. 
\begin{theo}{4.16}{}
  Suffiziente vollständige Statistiken sind minimal-suffizient.
\end{theo}
\begin{bew}[]
  Siehe Kapitel 5. Beachte: Die Umkehrung gilt im Allgemeinen nicht und der Satz gilt nur in Euklidischen Räumen.
\end{bew}
\begin{bei}[4.17 nicht-parametrische suffiziente Statistik]
  $X_1,X_2,...,X_n $ stetige iid Zufallsvariablen mit Dichten $\vartheta \in \Uptheta=\left\{\vartheta :\mathbb{R}\to \mathbb{R}\text{ Dichtefunktionen}\right\}$ ($\infty $-dimensional)\\
  Die Ordnungsstatistik 
  \begin{align*}
    T(X_1,X_2,...,X_n )=(X _{(1)},...,X _{(n)})\text{ mit }X _{(1)}\leq X _{(2)}\leq ... \leq X _{(n)}
  \end{align*}
  ist suffizient für $\vartheta $;\\
  Die gemeinsame Dichte von $X=(X_1,X_2,...,X_n )$ ist:
  \begin{align*}
    f _{\vartheta }(x_1,...,x_n)=\prod_{i=1}^{n}{\vartheta (x_i)}=\underbrace{\prod_{i=1}^{n}{\vartheta (x _{(i)})}}_{g _{\vartheta }(T(x))}\cdot \underbrace{1}_{h(x)}
  \end{align*}
\end{bei}
\chapter{Erwartungstreue Schätzer}
\begin{defi}{5.1}{}
  (a) \\
  Bekannt aus Kapitel 3: MSE oft nicht minimierbar. \\
  Möglicher Ausweg: Beschränkung auf erwartungstreue Schätzer (Minimierung der Varianz). \\
  Existiert ein erwartungstreuer Schätzer für $\psi (\vartheta )$, dann heißt $\psi $ \underline{schätzbar}. \\
  (b) \\
  $\psi :\Uptheta\to \mathbb{R}$ sei schätzbar. $\mathcal{U}:=\left\{T:\mathcal{X}\to \mathbb{R} \text{ Schätzer, }E _{\vartheta }(T(x))=\psi (\vartheta ),E _{\vartheta }(T^2(x))<\infty \; \forall \vartheta \in\Uptheta\right\}$ \\
  sei die Menge aller für $\psi (\vartheta )$ erwartungstreuen Schätzer  mit existenter Varianz.  \\
  (Einschub: Das $k$-te Moment existiert, falls $E|X|^k<\infty $)  \\
  $T_0 \in \mathcal{U}$ heißt \underline{\underline{U}niformly \underline{M}imimum \underline{V}ariance \underline{U}nbiased} (UMVU) Schätzer (oder UMVUE), d.h. $T_0$ hat die gleichmäßig kleinste Varianz unter den erwartungstreuen Schätzern, falls gilt 
  \begin{align*}
    E _{\vartheta }[(T_0(x)-\psi (\vartheta ))^2]\leq E _{\vartheta }[(T(x)-\psi (\vartheta ))^2]\quad \forall\;\vartheta \in \Uptheta, T \in \mathcal{U}
  \end{align*}
  (c)\\
  Beachte $E _{\vartheta }[(T(X)-\psi (\vartheta ))^2]=Var _{\vartheta }(T(X))=MSE _{\vartheta }(T(X))$ für alle $T \in \mathcal{U}$ (da erwartungstreu)  
\end{defi}
\begin{bem}[5.2a]
  Nicht jede Funktion ist schätzbar.
\end{bem}
\begin{bei}[]
  $X\sim Bin(1,p)$, $\psi (p)=p^2$. \\
  Angenommen es gibt ein Schätzer $T(X)$ der erwartungstreu ist, dann gilt 
  \begin{align*}
    p^2&=E_pT(X)=T(1)\underbrace{P(X=1)}_{p}+T(0)\underbrace{P(X=0)}_{1-p}\\
    \Leftrightarrow p^2&=T(1)p+T(0)-T(0)p \\
    \Leftrightarrow p^2&-p(T(1)-T(0))-T(0)=0 \quad \underline{\forall p \in (0,1)}
  \end{align*}
  D.h. $\equiv 0$ unmöglich. 
\end{bei}
\begin{bem}[5.2b]
  Nicht jeder erwartungstreue Schätzer ist sinnvoll.
\end{bem}
\begin{bei}[]
  $X\sim$ Pois$(\lambda )$, $\psi (\lambda )=e^{-3 \lambda }$. $T(X)=(-2)^x$ ist erwartungstreu:
  \begin{align*}
    E _{\lambda }(T(X))
    &=\sum_{k=0}^{\infty }{(-2)^k \frac{\lambda ^k}{k!}e^{- \lambda }} \\
    &=e^{-\lambda }\sum_{k=0}^{\infty}{\frac{(-2 \lambda )^k}{k!}} \\
    &=e^{-\lambda }e^{-2 \lambda }=e^{-3 \lambda }
  \end{align*}
  \underline{Aber}: $\psi (\lambda )>0$ für alle $\lambda $, aber $T(x)<0$ für $x$ ungerade.   
\end{bei}
\begin{bem}[5.2c]
  (i)\\
  Sind $T_1,T_2$ fast sicher verschiedene, erwartungstreue Schätzer für $\psi (\vartheta )$, dann sind durch 
  \begin{align*}
    R=\alpha T_1+(1-\alpha )T_2\quad \alpha \in (0,1)
  \end{align*}
  unendlich viele erwartungstreue Schätzer gegeben. \\
  Welches $\alpha $ ist sinnvoll? \\
  (ii)\\
  Sei $T$ ein erwartungstreuer Schätzer für $\psi (\vartheta )$. Dann sind durch
  \begin{align*}
    T+V\quad V \neq 0,\quad E _{\vartheta }V=0\quad \forall \vartheta \in \Uptheta
  \end{align*}
  \underline{alle} erwartungstreuen Schätzer für $\psi (\vartheta )$ gegeben.
  (Angenommen $\tilde{T}$ erwartungstreu, $\tilde{T}=\underbrace{\tilde{T}-T}_{=:V}+T$ )
\end{bem}
\begin{theo}{5.3}{}
  Die Klasse $\mathcal{U}$ aller erwartungstreuen Schätzer sei nicht-leer. \\
  (a)  
  \begin{align*}
    &T_0 \in \mathcal{U}\text{ ist UMVUE }\\
    &\Leftrightarrow E _{\vartheta }(T_0(x)V(x))=0 \;\forall\;\vartheta \in \Uptheta\text{ und }\\
    &\ \ \quad\forall V \in \mathcal{U}_0:\left\{V:\mathcal{X}\to \mathbb{R}:E _{\vartheta }V(X)=0, Var _{\vartheta } V(x)\text{ existiert }\forall\;\vartheta\right\}
  \end{align*}
  (b) \\
  Es gibt höchstens einen UMVU-Schätzer
\end{theo}
\begin{bew}[]
  Es gilt $E _{\vartheta }(T_0(X)V(X))=Cov(T_0(X),V(X))$ existiert, da $Var _{\vartheta }T_0$, $Var _{\vartheta }V$ existiert nach Voraussetzung. \\
  (Cauchy-Schwarz-Ungleichung: $Cov^2(T_0(X),V(X))\leq Var T_0(X) \cdot Var V(X)$) \\
  '$\Rightarrow $': Angenommen $T_0$ ist UMVUE und es existieren $V_0 \in \mathcal{U}_0$, $\vartheta_0 \in \Uptheta$ mit 
  \begin{align*}
    E _{\vartheta_0 }(T_0(X)V(X)) \neq 0
  \end{align*}
  Dann folgt 
  \begin{align*}
    E _{\vartheta _0}(V_0^2(X))=Var _{\vartheta _0}(V_0(X))>0
  \end{align*}
  Außerdem gilt 
  \begin{align*}
    T_0+\lambda V_0 \in \mathcal{U}\quad \forall \lambda \in \mathbb{R}
  \end{align*}
  Mit $\lambda _0:=-\frac{E _{\vartheta _0}(T_0(X)V_0(X))}{E _{\vartheta _0}(V_0^2(X))}$ folgt 
  \begin{align*}
    Var _{\vartheta _0}(T_0(X)+\lambda _0V_0(X))
    &=E _{\vartheta _0}[(T_0(X)+\lambda _0V_0(X))^2]-[\psi (\vartheta )]^2 \\
    &=E _{\vartheta _0}(T_0(X)^2)+\underbrace{\lambda _0^2E _{\vartheta _0}(V_0(X))^2}_{(i)}+\underbrace{2 \lambda _0E _{\vartheta _0}(T_0(X)V_0(X))}_{(ii)}-\psi ^2(\vartheta _0)
  \end{align*}
  \begin{align*}
    (i)&=\frac{(E(T_0V_0)^{{2}})}{(EV_0^2)^{\cancel{2}}}\cancel{EV_0^{{2}}} \\
  (ii)&=-2 \frac{E(T_0V_0)}{E(V_0^2)}E(T_0V_0)
  \end{align*}
  \begin{align*}
     &=E _{\vartheta _0}(T_0(X)^2)-\underbrace{\frac{E _{\vartheta_0 }(T_0(X)V_0(X))^2}{E(V_0(X)^2)}}_{>0}-\psi ^2(\vartheta ) <E _{\vartheta _0}(T_0(X)^2)-\psi ^2(\vartheta )=Var _{\vartheta _0}(T_0(X))  \end{align*}
  Widerspruch zu $T_0$ UMVUE. \\
  '$\Leftarrow$': Sei $T \in \mathcal{U}\Rightarrow V=T_0-T \in \mathcal{U}_0$. Per Voraussetzung folgt
  \begin{align*}
    E _{\vartheta }[T_0(x)(\underbrace{T_0(x)-T(x))}_{V}]=0 \quad \forall \vartheta  
  \end{align*}
  Mit der Cauchy-Schwarz-Ungleichung gilt:
  \begin{align*}
    (*)\quad &E _{\vartheta }(T_0^2(X))=E _{\vartheta }(T_0(X)T(X)) 
             \leq [E _{\vartheta }(T_0^2(X))E _{\vartheta }(T^2(X))]^{\frac{1}{2}}
  \end{align*}
  und somit durch Teilen, Quadrieren 
  \begin{align*}
    E _{\vartheta }(T_0^2(X))\leq E _{\vartheta }(T^2(X)) \text{ falls }E _{\vartheta }T_0^2(X)>0
  \end{align*}
  \begin{align*}
    \Leftrightarrow Var _{\vartheta }T_0=E _{\vartheta }(T_0^2(X))-\psi (\vartheta )^2 \leq \underbrace{E _{\vartheta }(T^2(X))-\psi (\vartheta )^2}_{Var _{\vartheta }(T(X))}\quad \forall \vartheta  \in \Uptheta
  \end{align*}
  Falls $E _{\vartheta }T_0^2(X)=0$ folgt $P _{\vartheta }(T_0(X)=0)=1$ und damit $\psi (\vartheta )=0$, d.h. $T_0$ erwartungstreu für $\psi (\vartheta )=0$. Also gilt auch in diesem Fall $Var _{\vartheta }(T_0(X)) =0\leq Var _{\vartheta }(T(X))$ somit is $T_0$ UMVUE.  \\
  (b) Seien $T,T_0 \in \mathcal{U}$ beide UMVU-Schätzer für $\psi (\vartheta )$
  \begin{align*}
    &\Rightarrow T-T_0 \in \mathcal{U}_0 \overset{(a)}\Rightarrow E _{\vartheta }(T_0(X)[T(X)-T_0(X)])=0 \\
    &\Rightarrow E _{\vartheta }(T_0(X)T(X))=E _{\vartheta }(T_0^2(X))=E _{\vartheta }(T^2(X))
  \end{align*}
   und in $(*)$ gilt Gleichheit, d.h. es gibt Konstanten $a,b:(a,b) \neq (0,0)$ (nicht gleichzeitig Null), sodass 
   \begin{align*}
    P _{\vartheta }(a \cdot T(X)+b \cdot T_0(X)=0)=1
   \end{align*}
   Da $E _{\vartheta }(T_0(X))=E _{\vartheta }(T(X))$ folgt 
   \begin{align*}
    P _{\vartheta }(T(X)=T_0(X))=1 \;\square
   \end{align*}
\end{bew}
\begin{theo}{5.4 Rao-Blackwell]}{}
  Sei $\mathcal{F}=\left\{F _{\vartheta }:\vartheta \in \Uptheta\right\}$ eine Familie von Verteilungen, $\psi $ schätzbar (es existiert ein erwartungstreuer Schätzer) und $h \in \mathcal{U}$ ein erwartungstreuer Schätzer für $\psi (\vartheta )$. \\
  $T=T(X)$ sei suffizient für $\mathcal{F}$. Dann ist
  \begin{align*}
    T_0=E(h(X)|T)
  \end{align*}
  unabhängig von $\vartheta $ und erwartungstreu für $\psi (\vartheta )$. Es gilt
  \begin{align*}
    E _{\vartheta }[(E(h(X)|T)-\psi (\vartheta ))^2] \leq E _{\vartheta }[(h(X)-\psi (\vartheta ))^2]\quad \forall \vartheta 
  \end{align*}
  mit Gleichheit genau dann wenn 
  \begin{align*}
    P _{\vartheta }(h(X)=E(h(X)|T))=1\quad \forall \vartheta 
  \end{align*}
  (d.h. $T_0$ ist gleichmäßig in $\vartheta $ gleich gut oder besser [im Bezug auf MSE/ Var] als $h(X)$)
\end{theo}
\begin{bew}[]
  $E _{\vartheta }(h(X)|T)=E(h(X)|T)=T_0$ unabhängig von $\vartheta $, da $T$ suffizient ist. 
  \begin{align*}
    E _{\vartheta }[E(h(X)|T)]\overset{\text{bed.}}{\underset{\text{Erw.}}{=}}E _{\vartheta }(h(X))\overset{\text{Vor.}}= \psi (\vartheta )
  \end{align*}
  also gilt
  \begin{align*}
    E _{\vartheta }(T_0-\psi (\vartheta ))^2
    &=Var _{\vartheta }T_0=Var _{\vartheta }(E(h(X)|T)) \\
    &\overset{\text{bed.}}{\underset{\text{Erw.}}{=}}Var _{\vartheta }(h(X))-\underbrace{E _{\vartheta }[Var (h(X)|T)]}_{\geq 0} \\
    & \leq Var _{\vartheta }(h(X))=E _{\vartheta }((h(X)-\psi (\vartheta ))^2)\quad \forall \vartheta  \in \Uptheta
  \end{align*}
  mit Gleichheit genau dann wenn $\forall \vartheta \in \Uptheta$ gilt
  \begin{align*}
    0=E _{\vartheta }(Var(h(X)|T))
    &=E _{\vartheta }[E _{\vartheta }(\{h(X)-E _{\vartheta }(h(X)|T)\}^2|T)] \\
    &\!\!\!\overset{\text{bed.}}{\underset{\text{Erw.}}{=}}E _{\vartheta }[\{h(X)-E(h(X)|T)\}^2] \\
    \Leftrightarrow P _{\vartheta }[h(X)&=E(h(X)|T)]=1\;\square
  \end{align*}
\end{bew}
\begin{theo}{5.5 Lehmann-Scheffé}{}
  Sei $T$ suffizient und \underline{vollständig} für $\vartheta $, $h=h(X)$ ein erwartungstreuer Schätzer für $\psi (\vartheta )$.  Dann gilt  
  \begin{align*}
    T_0=E[h(X)|T]
  \end{align*}
  ist fast sicher eindeutiger UMVU Schätzer für $\psi (\vartheta )$. 
\end{theo}
\begin{bew}[]
  Sei $\delta \in \mathcal{U}$ erwartungstreu für $\psi (\vartheta )$, dann folgt 
  \begin{align*}
    E _{\vartheta }[\underbrace{E(h(X)|T)-E(\delta (X)|T)}_{=:g(T)}]=0\quad \forall \vartheta \in \Uptheta
  \end{align*}
  Da $T$ vollständig ist, folgt
  \begin{align*}
    1= P _{\vartheta }(g(T)=0)=P(T_0=E(\delta  (x)|T))\quad \forall \vartheta 
  \end{align*}
  \begin{align*}
    \Rightarrow E _{\vartheta }((T_0-\psi (\vartheta ))^2)
    &=E _{\vartheta }((E(\delta (X)|T)-\psi (\vartheta ))^2) \\
    & \!\!\!\!\!\overset{\text{Rao}}{\underset{\text{Blackw.}}{\leq }} E _{\vartheta }((\delta (X)-\psi (\vartheta ))^2)\quad \forall \vartheta 
  \end{align*}
  Also hat $T_0$ unter allen Schätzern $\delta (X)\in \mathcal{U}$ die gleichmäßig kleinste Varianz und ist somit UMVUE. Aus Theorem 5.3b folgt die Eindeutigkeit.
\end{bew}
\begin{bem}[5.6a]
  Sei $T$ suffizient und vollständig, $h(X)=\tilde{h}(T)$ (d.h. $h$ hängt nur von $T$ ab) erwartungstreu für $\psi (\vartheta )$. Dann folgt mit (5.5), dass 
  \begin{align*}
    E (h(X)|T)=E(\tilde{h}(T)|T)=\tilde{h}E(1|T)=\tilde{h}(T)=h(X)
  \end{align*}
  ein UMVUE ist. \\
  \underline{Also} hängt ein Schätzer nur von $T$ suffizient und vollständig ab, ist er UMVUE (einfach zu finden für exponentielle Familien siehe 4.11)
\end{bem}
\begin{bei}[]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $(\sum_{}^{}{X_i},\sum_{}^{}{X_i^2})$ suffizient und vollständig  (siehe 4.12) \\
  Ü: $\left(\frac{1}{n}\sum_{}^{}{X_i},\frac{1}{n-1}\sum_{}^{}{(X_i-\bar{X})^2}\right)=(\bar{X},\hat{S}^2)$ suffizient und vollständig und erwartungstreu für $(\mu ,\sigma ^2)$. Also ist $(\bar{X},\hat{S}^2)$ UMVUE 
\end{bei}
\begin{bem}[5.6b]
  (i)\\
  $X_1,X_2,...,X_n \overset{iid}\sim U(0,\vartheta )$, $X _{(n)}=\max\limits _{i=1,...,n}X_i$ ist suffizient und vollständig (Ü) \\
  \underline{Gesucht}: Erwartungstreuer Schätzer der nur von $X _{(n)}$ abhängt. \\
  \underline{Bekannt}: $E _{\vartheta }(X _{(n)})=\frac{n \vartheta }{n+1}\Rightarrow T_0=\frac{n+1}{n}X _{(n)}$ erwartungstreu für $\vartheta $ $\overset{(a)}\Rightarrow T_0$ UMVUE.    \\
  Oder: $\delta _1(X)=\frac{2}{n}\sum_{}^{}{X_i}$ erwartungstreu für $\vartheta $ (siehe 3.5) \\
  Ü: $\overset{5.5}\Rightarrow E(\delta _1(X)|X _{(n)})=\frac{n+1}{n}X _{(n)}$ ist UMVUE. \\
  (ii) \\
  \underline{Bsp}: Nicht-parametrischer UMVUE für Verteilungsfunktion $F$ \\
  $X_1,X_2,...,X_n \overset{iid}\sim F$, ($X _{(1)},...,X _{(n)}$) suffizient (siehe 4.17) und vollständig für $F$ (Ü)  \\
  Dann gilt: $h(X_1,X_2,...,X_n )=1_{\{X_1 \leq z\}}$ ist erwartungstreu:
  \begin{align*}
    &E(1(X_1 \leq z))=P(X_1 \leq z)=F(z) \\
    &\overset{5.5}\Rightarrow E(1(X_1 \leq z)|X _{(1)},...,X _{(n)})=\frac{1}{n}\sum_{i=1}^{n}{1(X _{(i)}\leq z)} \\
    &\qquad=\frac{1}{n}\sum_{i=1}^{n}{1(X_i \leq z)}=\hat{F}_n(z) \text{ empirische Verteilungsfunktion ist UMVUE}
  \end{align*}
\end{bem}
\begin{bew}[5.7 Beweis von 4.16 mit Lehmann-Scheffé]
  Sei $S$ $(\triangleq T)$ suffizient und vollständig für $\left\{f _{\vartheta }:\vartheta \in \Uptheta\right\}$ mit $E _{\vartheta }(S(X)^2)<\infty $. \\
  Dann ist $S(X)$ $(\triangleq h(X))$ ist erwartungstreu für $\psi (\vartheta )=E _{\vartheta }(S(X))$ und $E(S(X)|S(X))$ $(\triangleq E(h(X)|T))$ ist UMVUE für $\psi (\vartheta )$ (5.5). \\
  Sei $S _{1}(X)$ beliebige suffiziente Statistik für $\psi (\vartheta )$ (zu zeigen $\exists H:T^* =S(X)=H(S_1(X))$). \\
  Dann gilt 
  \begin{align*}
    E _{\vartheta }(S(X)|S_1(X))
    &=E (S(X)|S_1(X)) \text{ ($S_1$ suffizient)}
  \end{align*}
  ist erwartungstreuer Schätzer und Rao-Blackwell liefert 
  \begin{align*}
    Var _{\vartheta }(E(S(X)|S_1(X)))\leq Var _{\vartheta }S(X)\quad \forall \vartheta 
  \end{align*}
  Da $S(X)$ UMVUE ist (minimale Varianz), muss Gleichheit gelten
  \begin{align*}
    \Rightarrow S(X)=E(S(X)|S_1(X))=H(S_1(X))\text{ fast sicher}
  \end{align*}
  woraus die minmale Suffizienz folgt $\square$ 
\end{bew}
\begin{theo}{5.8 Cramer-Rao Ungleichung}{}
  $X$ sei $n$-dim. Zufallsvariable mit Dichte $f _{\vartheta }$ (diskret oder stetig), $\vartheta \in \Uptheta$, $\Uptheta\subseteq \mathbb{R}^1$   offen \\
  \underline{Annahme an $f _{\vartheta }$}: \\
  (i) Träger hängt nicht von $\vartheta $ ab \\
  (ii) $\frac{\partial}{\partial \vartheta }\ln f _{\vartheta }(x)$ existiert für alle $x,\vartheta $ \\
  (iii) (a) $E \left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\right)=0$ und 
  (b) $\frac{\partial }{\partial \vartheta }E _{\vartheta }(T(X))=E _{\vartheta }\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)\cdot T(X)\right)$, \\
  dabei sei $T$ eine Statistik mit $Var _{\vartheta }(T(X))< \infty \forall\;\vartheta $. \\
  Setze $\psi (\vartheta ):=E _{\vartheta }(T(X))$ und 
  \begin{align*}
    I_n(\vartheta ):=E _{\vartheta }\left( \left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)\right)^2\right)\text{ 'Fischer-Information'}
  \end{align*}
  Gilt $0<I_n(\vartheta )<\infty $ für alle $\vartheta \in \Uptheta$, dann folgt
  \begin{align*}
    Var _{\vartheta }(T(X))\geq \underbrace{\frac{(\psi '(\vartheta ))^2}{I_n(\vartheta )}}_{\text{untere Schranke}}\quad \forall\;\vartheta \in \Uptheta
  \end{align*}
\end{theo}
\begin{bew}[]
  \begin{align*}
    \psi '(\vartheta )
    &=\frac{\partial }{\partial \vartheta }E _{\vartheta }(T(X)) \\
    &\!\!\!\!\overset{(iii)b}=E _{\vartheta }\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }\cdot T(X)\right) \\
    &\!\!\!\!\overset{(iii)a}=Cov \left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X),T(X)\right)\\
    & \!\!\!\!\!\!\!\overset{\text{Cauchy}}{\underset{\text{Schwarz}}{=}}\leq \left(Var _{\vartheta }\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)\right)\cdot VarT(X)\right)^{\frac{1}{2}} \\
    &\!\!\!\!\overset{(iii)a}=\left(E _{\vartheta }\left[\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)\right)^2\right]Var _{\vartheta }T(X)\right)^{\frac{1}{2}} \\
    &=\sqrt{I_n(\vartheta )\cdot Var _{\vartheta }T(X)} \\
    &\Rightarrow Var _{\vartheta }(T(X))\geq \frac{\psi '(\vartheta )^2}{I_n(\vartheta )}\;\square
  \end{align*} 
  Anmerkung: Cauchy-Schwarz Ungleichung
  \begin{align*}
    |E(XY)|\leq \sqrt{EX^2EY^2}
  \end{align*}
  Hier: $X\triangleq T(X)-\psi (X), Y \triangleq \frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)$ mit Gleichheit, falls $T(X)-\psi (\vartheta )=\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\cdot k(\vartheta )$ ($k$ konstant) 
\end{bew}
\begin{bem}[5.9]
  (a)\\
  Ist $T$ erwartungstreu für $\psi (\vartheta )=\vartheta $, dann folgt $\psi '(\vartheta )=1$ und für die Schranke gilt
  \begin{align*}
    Var _{\vartheta }(T(X))\geq \frac{1}{I_n(\vartheta )}
  \end{align*}
  (b)\\
  Ist $X=(X_1,X_2,...,X_n)$ mit $X_1,X_2,...,X_n \overset{iid}\sim f _{\vartheta }^{(1)}$ eindimensionale Dichte, dann gilt (Ü)
  \begin{align*}
    I_n(\vartheta )=n \cdot I_1(\vartheta ), \quad I_1 (\vartheta )=\left(E \left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }^{(1)}(X_1)\right)^2\right)
  \end{align*}
  (c) 
  \begin{align*}
    \frac{\psi' (\vartheta )^2}{I_n(\vartheta )}\left(\overset{b}=\frac{\psi '(\vartheta )^2}{n I_1(\vartheta )}\overset{n\to \infty }\longrightarrow 0\right)\text{ 'Cramér-Rao Schranke'}
  \end{align*}
  (d) \\
  Bedingung (iii)b setzt voraus, dass Differentiation und Integration vertauscht werden dürfen. \\
  Stetiger Fall:
  \begin{align*}
    \frac{\partial }{\partial \vartheta }E _{\vartheta }(T(X))
    &\overset{\text{Ann.}}=E _{\vartheta }\bigg(T(X)\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\bigg) \\
    &=\int{T(X)\underbrace{\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\right)}_{\frac{1}{f _{\vartheta }(x)}\frac{\partial }{\partial \vartheta }f _{\vartheta }(x)}f _{\vartheta }(x)dx} \\
    &=\int{T(x) \frac{\partial }{\partial \vartheta }f _{\vartheta }(x)dx} \\
    &\!\!\!\overset{\text{Ann.}}=\frac{\partial }{\partial \vartheta }\int{T(x)f _{\vartheta }(x)dx}\\
    &=\frac{\partial }{\partial \vartheta }E _{\vartheta }(T(X))
  \end{align*}
  (e) \\
  Existieren $\frac{\partial^2 }{\partial \vartheta ^2}f _{\vartheta }(x)$ und sind Vertauschungen erlaubt, dann gilt \begin{align*}
    I _n(\vartheta )
    &=E _{\vartheta }\left(\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\right)^2\right) 
    =-E _{\vartheta }\left(\frac{\partial^2 }{\partial \vartheta ^2}\ln f _{\vartheta }(x)\right)
  \end{align*}
  (Nebenbemerkung: 2. Ableitung oft einfacher)
\end{bem}
\begin{defi}{5.10 effiziente Statistik}{}
  $T(X)$ heißt (unter den obigen Annahmen) \underline{effizient} für $\psi (\vartheta )$, wenn 
  \begin{align*}
    Var _{\vartheta }(T(X))=\frac{\psi'(\vartheta )^2}{I_n(\vartheta )}
  \end{align*}
  Beachte: UMVUE nicht immer effizient (unbiased starke Einschränkung), \\
  Aus Erwartungstreue und Effizienz folgt aber UMVUE
\end{defi}
\begin{bei}[5.11]
  (a) \\
  $X_1,X_2,...,X_n \overset{iid}\sim$ Bin$(1,\vartheta )$, $f _{\vartheta }(x)=\vartheta ^x(1-\vartheta )^{1-x}$ mit $x \in \left\{0,1\right\}$, $\vartheta \in (0,1)$  
  \begin{align*}
    I_1(\vartheta )
    &=E _{\vartheta }\left(\left(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\right)^2\right) \\
    &=E _{\vartheta }\left(\left(\frac{\partial }{\partial \vartheta }\ln \left(\vartheta ^{x_1}(1-\vartheta )^{1-x_1}\right)\right)^2\right)\\
    &=E _{\vartheta }\left[\left(\frac{\partial }{\partial \vartheta }[x_1\ln \vartheta +(1-x_1)\ln(1-\vartheta )]\right)^2\right] \\
    &= E _{\vartheta }\left[\left(\frac{x_1}{\vartheta }+(1-x_1)\frac{1}{1-\vartheta }(-1)\right)^2\right] \\
    &=E _{\vartheta }\left[\left(\frac{x_1(1-\vartheta )-(1-x_1)\vartheta }{\vartheta (1-\vartheta )}\right)^2\right] \\
    &=\frac{1}{\vartheta ^2(1-\vartheta )^2}E _{\vartheta }\left[(x_1-\cancel{\vartheta x_1}-\vartheta +\cancel{\vartheta x_1})^2\right] \\
    &=\frac{E _{\vartheta }(x_1-\vartheta )^2}{\vartheta ^2(1-\vartheta )^2} \\
    &=\frac{Var _{\vartheta} (x_1)}{\vartheta ^2(1-\vartheta )^2} \\
    &=\frac{\vartheta (1-\vartheta )}{\vartheta ^2(1-\vartheta )^2} \\
    &=\frac{1}{\vartheta (1-\vartheta )}
  \end{align*}
  Demnach ist 
  \begin{align*}
    I_n (\vartheta )=n I_1(\vartheta )=\frac{n}{\vartheta (1-\vartheta )}
  \end{align*}
  Für alle $T(X)$ mit $E _{\vartheta }T(X)=\vartheta $ gilt also:
  \begin{align*}
    Var _{\vartheta }(T(X))\geq \frac{\vartheta (1-\vartheta )}{n}
  \end{align*}
  Für $T^*(X)=\bar{X}$ ist $T^*$ erwartungstreu ($E \bar{X}=\vartheta $) und 
  $Var T^*=\frac{\vartheta (1-\vartheta )}{n}\leq Var _{\vartheta }T(X)$ \\
  Aus der Erwartungstreue und Effizienz folgt, dass $T^*(X)=\bar{X}$ UMVUE ist.  \\
  (b)\\
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$ mit $\vartheta =\mu $ und $\sigma ^2$ bekannt.   
  \begin{align*}
    f _{\vartheta }^{(1)}(x)=\frac{1}{\sqrt{2 \pi \sigma ^2}}\exp \left(-\frac{1}{2 \sigma ^2}(x-\vartheta )^2\right)
  \end{align*}
  \begin{align*}
    I_1(\vartheta )
    &=E _{\vartheta }\left[\left(\frac{\partial }{\partial \vartheta }\bigg[\ln \frac{1}{\sqrt{2 \pi \sigma ^2}}-\frac{1}{2 \sigma ^2}(x_1-\vartheta )^2\bigg]\right)^2\right] \\
    &=E _{\vartheta } \left[\bigg(0-\frac{1}{2 \sigma ^2}2(x_1-\vartheta )(-1)\bigg)^2\right] \\
    &= E _{\vartheta }\left[\left(\frac{x_1-\vartheta }{\sigma ^2}\right)^2\right]=\frac{1}{\sigma ^4}\underbrace{Var X_1}_{\sigma ^2} \\
    &=\frac{1}{\sigma ^2}
  \end{align*}
  also ist 
  \begin{align*}
    I_n(\vartheta )=n \cdot I_1(\vartheta )=\frac{n}{\sigma ^2}
  \end{align*}
  und demnach 
  \begin{align*}
    Var _{\vartheta }(T(X))\geq \frac{\sigma ^2}{n}
  \end{align*}
  für alle $T(X)$ erwartungstreu mit $Var T < \infty $. \\
  $\hat{\vartheta }=\bar{X}$ ist erwartungstreu und $Var \bar{X}=\frac{\sigma ^2}{n}$ (effizient) \\
  und daraus folgt, dass $\bar{X}$ UMVUE ist.
\end{bei}
\begin{bem}[5.12]
  Sei $X$ $n$-dimensionale Zufallsvariable mit Dichte $f _{\vartheta }$, $\vartheta  \in \Uptheta \subseteq \mathbb{R}^k$ offen. \\
  Die Rao-Cramér Schranke kann analog 5.8 hergeleitet werden: \\
  \underline{Annahmen}: \\
  (i) Der Träger ist unabhängig von $\vartheta $ \\
  (ii) Für den '\underline{Score-Vektor}' 
  \begin{align*}
    U _n(\vartheta )=\left(\frac{\partial }{\partial \vartheta _1}\ln f _{\vartheta }(x),...,\frac{\partial }{\partial \vartheta _k}\ln f _{\vartheta }(x)\right)^T
  \end{align*}
  gilt 
  \begin{align*}
    E U_n(\vartheta )=0 \quad \forall\;\vartheta \in \Uptheta
  \end{align*}
  (iii) $T=(T_1,...,T_l)^T$ sei $\mathbb{R}^l$-wertige Statistik mit 
  \begin{align*}
    E _{\vartheta }(\underbrace{T(X)U_n(\vartheta )^T}_{(l \times k)\text{-Matrix}})=\left(\frac{\partial }{\partial \vartheta _1}E _{\vartheta }(T(X)),...,\frac{\partial }{\partial \vartheta _k}E _{\vartheta }(T(X))\right)=:G(\vartheta )
  \end{align*}
  Angenommen die Fischer-Informationsmatrix 
  \begin{align*}
    I _{n}(\vartheta )=E _{\vartheta }(U_nU_n^T)
  \end{align*}
  existiert und ist positiv definit. Dann gilt
  \begin{align*}
    Cov(T(X))=E _{\vartheta }(T(X)T(X)^T)-E _{\vartheta }(T(X))E _{\vartheta }(T(X)^T)\geq G(\vartheta )I_n ^{-1}(\vartheta )G(\vartheta )^T
  \end{align*}
  Dabei gilt $A \geq B$ für Matrizen $A,B$ $\Leftrightarrow A-B$ positiv semidefinit.  \\
  \end{bem}
\begin{bei}[5.13]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $\vartheta =(\mu ,\sigma^2)^T$ \\
  \begin{align*}
    f _{\vartheta }^{(1)}(x)=\frac{1}{\sqrt{2 \pi \sigma ^2}}\exp \left(-\frac{1}{2 \sigma ^2}(x-\mu )^2\right)
  \end{align*}
  \begin{align*}
    I_n(\vartheta )\overset{iid}=n I_1(\vartheta )=n E _{\vartheta }(U_1(\vartheta )U_1(\vartheta )^T)
  \end{align*}
  \begin{align*}
    \ln f _{\vartheta }^{(1)}(x)=-\frac{1}{2}\ln(2 \pi \sigma ^2)-\frac{1}{2 \sigma ^2}(x-\mu )^2
  \end{align*}
  \begin{align*}
    \frac{\partial }{\partial \mu }\ln f _{\vartheta }^{(1)}(x)=-\frac{1}{2 \sigma ^2}2(x-\mu )(-1)=\frac{x-\mu }{\sigma ^2}
  \end{align*}
  \begin{align*}
    \frac{\partial }{\partial \sigma ^2}\ln f _{\vartheta }^{(1)}(x)
    &=-\frac{1}{2 \sigma ^2}-\frac{(x-\mu )^2}{2}\frac{\partial }{\partial \sigma ^2}(\sigma ^2)^{-1}\\
    &=-\frac{1}{2 \sigma ^2}-\frac{(x-\mu )^2}{2}(\sigma ^2)^{-2}(-1) \\
    &=-\frac{1}{2 \sigma ^2}+\frac{(x-\mu )^2}{2 \sigma ^4}
  \end{align*}
  \begin{align*}
    U_1 (\vartheta )
    &=\begin{pmatrix}\frac{\partial }{\partial \mu }\ln f _{\vartheta }^{(1)}(x)\\\frac{\partial }{\partial \sigma ^2 }\ln f _{\vartheta }^{(1)}(x)\end{pmatrix} \\
    &=\begin{pmatrix}\frac{x-\mu }{\sigma ^2}\\-\frac{1}{2 \sigma ^2}+\frac{(x-\mu )^2}{2 \sigma ^4}\end{pmatrix}
  \end{align*}
  \begin{align*}
    I_n(\vartheta )=n E _{\vartheta }(U_1(\vartheta )U_1(\vartheta )^T)=n \begin{pmatrix}
      a &b \\b &c
    \end{pmatrix}
  \end{align*}
  mit 
  \begin{align*}
    a&= E \left(\frac{X_1-\mu }{\sigma }\right)^2=\frac{\sigma ^2}{\sigma ^4}=\frac{1}{\sigma ^2} \\
    b&=E \left[\left(\frac{X_1-\mu }{\sigma ^2}\right)\left(-\frac{1}{2 \sigma ^2}+\frac{(X_1-\mu )^2}{2 \sigma ^4}\right)\right]\\
     &=-\frac{1}{2 \sigma ^2}E \left(\frac{X_1-\mu }{\sigma ^2}\right)+E \left(\frac{(X_1-\mu )^3}{2 \sigma ^6}\right)\\
     &=0
  \end{align*}
  (ungerade Momente der $N(0,\sigma ^2)$-Verteilung sind $0$)
  \begin{align*}
    c=E \left[\left(-\frac{1}{2 \sigma ^2}+\frac{(X_1-\mu )^2}{2 \sigma ^4}\right)^2\right]\overset{\text{Ü}}=\frac{1}{2 \sigma ^4}
  \end{align*}
  (Verwenden kann man dabei, dass $E(X_1-\mu)^4=3 \sigma ^4$)
  \begin{align*}
    I_n(\vartheta )=\begin{pmatrix}
      \frac{n}{\sigma ^2}&0\\0&\frac{n}{2\sigma ^4}
    \end{pmatrix}
  \end{align*}
  Für $T=(T_1,T_2)^T$ erwartungstreu für $\vartheta =(\mu ,\sigma ^2)^T$ gilt 
  \begin{align*}
    G(\vartheta )
    &=\left(\frac{\partial }{\partial \mu }\underbrace{E _{\vartheta }(T(X))}_{=(\mu ,\sigma ^2)^T},\frac{\partial }{\partial \sigma ^2}E _{\vartheta }(T(X))\right) \\
    &=\begin{pmatrix}
      \frac{\partial }{\partial \mu }\mu &\frac{\partial }{\partial \sigma ^2}\mu \\\frac{\partial }{\partial \mu }\sigma ^2&\frac{\partial }{\partial \sigma ^2}\sigma ^2
    \end{pmatrix}=\begin{pmatrix}1&0\\0&1\end{pmatrix}
  \end{align*}
  Also (5.12): 
  \begin{align*}
    Cov(T)\geq I_n ^{-1}=\begin{pmatrix}
      \frac{\sigma ^2}{n}&0\\0&\frac{2 \sigma ^4}{n}
    \end{pmatrix}
  \end{align*}
  Der Schätzer $T^*=(\bar{X},\hat{S}^2)$ ist erwartungstreu und UMVUE aber nicht effizient, da (Ü)
  \begin{align*}
    Cov T^*=\begin{pmatrix}
      \frac{\sigma ^2}{n}&0\\0&\frac{2 \sigma ^4}{n \cdot (-1)}
    \end{pmatrix}
  \end{align*}
\end{bei}
\chapter{Momentmethode und Maximum-Likelihood Schätzung}
\noindent \textbf{Bemerkung und Definition} (\underline{Momentenmethode})\\
  Sei $X_1,X_2,...,X_n \overset{iid}\sim P _{\vartheta }$, $\vartheta \in \Uptheta$ (Stichprobe)  \\
  \underline{Annahme}: $E _{\vartheta }X_1,E _{\vartheta }X_1^2,..., E _{\vartheta }X_1^k$ existieren, $m_j(\vartheta ):=E _{\vartheta }X_1^j$ \\
  Wir wollen $\psi (\vartheta )=h(m_1(\vartheta ),...,m_k(\vartheta ))$ schätzen. \\
  Momentenmethode: \\
  \begin{align*}
    \hat{\psi }(\vartheta )=h(\hat{m_1},...,\hat{m_k}) \text{ (Substitution/ plug-in)}
  \end{align*}
  mit 
  \begin{align*}
    \hat{m}_j=\frac{1}{n}\sum_{i=1}^{n}{X_i^j}\text{ (Stichprobenmomente)}
  \end{align*}
  (erwartungstreu, konsistent, asmyptotisch normal) \\
  Für $h$ stetig gilt (nach dem Continuous Mapping Theorem), dass $\hat{\psi }(\vartheta )$ konsistent ist, zusätzlich  ist $\hat{\psi }$ asymptotisch normal, falls die Voraussetzungen für die multivariate Delta-Methode erfüllt sind.
\begin{bei}[6.2]
  (a)\\ $X_1,X_2,...,X_n \overset{iid}\sim P _{\vartheta }$ schätzen \\
  $\psi (\vartheta )=Var _{\vartheta }(X_1)=E _{\vartheta }X_1^2-(E _{\vartheta }X_1)^2=m_2(\vartheta )-m_1(\vartheta )^2$ \\
  Method of Moments (MoM) Schätzer: 
  \begin{align*}
    \hat{\sigma }^2=\frac{1}{n}\sum_{}^{}{X_i^2}-\left(\frac{1}{n}\sum_{}^{}{X_i}\right)^2=\frac{1}{n}\sum_{}^{}{(X_i-\bar{X})^2} =\frac{n-1}{n}\hat{S}_n^2
  \end{align*}
  (b)\\
  Beispiel (3.5), $X_1,X_2,...,X_n \overset{iid}\sim U(0, \vartheta )$, $E _{\vartheta }X_1=\frac{\vartheta }{2}$  
  \begin{align*}
    \psi (\vartheta )=\vartheta =2 \cdot \frac{\vartheta }{2}=2E _{\vartheta }X_1=2 m_1(\vartheta )
  \end{align*}
  \begin{align*}
    \Rightarrow \hat{\vartheta }=2 \bar{X}
  \end{align*}
  (c)\\
  $X_1,X_2,...,X_n \overset{iid}\sim$ Gam$(\alpha ,\beta )$ mit $f _{\vartheta }=\frac{\beta ^{\alpha }}{\Gamma (\alpha )}x ^{\alpha -1}e^{-\beta x}$, $x>0$ \\
$E _{\vartheta }X_1=\alpha \beta =m_1(\vartheta )$ \\
$E _{\vartheta }X_1^2=Var _{\vartheta }X_1+(E _{\vartheta }X_1)^2=\alpha \beta ^2+(\alpha \beta )^2=m_2(\vartheta )$
\begin{align*}
  \beta =\frac{\alpha \beta ^2}{\alpha \beta }=\frac{Var _{\vartheta }(X_1)}{E _{\vartheta }X_1}=\frac{m_2(\vartheta )-(m_1(\vartheta ))^2}{m_1(\vartheta )}
\end{align*}
\begin{align*}
  \alpha =\frac{(\alpha \beta )^2}{\alpha \beta ^2}=\frac{(E _{\vartheta }X_1)^2}{Var _{\vartheta }X_1}=\frac{m_1(\vartheta )^2}{m_2(\vartheta )-(m_1(\vartheta ))^2}
\end{align*}
\begin{align*}
  \Rightarrow \hat{\beta }=\frac{\hat{\sigma }^2}{\bar{X}},\quad \hat{\alpha }=\frac{\bar{X}^2}{\hat{\sigma}^2}\quad (\hat{\sigma }^2 \overset{(a)}=\frac{1}{n}\sum_{}^{}{(X_i-\bar{X})^2})
\end{align*}
\end{bei}
\begin{bei}[6.3 Zur Maximum-Likelihood (ML) Schätzung]
  Zu Schätzen: Anzahl $N(=\vartheta )$ der Fische in einem Teich mittels capture/ recapture sampling: \\
  Fange und markiere $K$ Fische, Zeit später fange $n$ Fische, von denen sind $x$ markiert. \\
  ($\Rightarrow \frac{x}{n}\approx \frac{K}{N}\Rightarrow N\approx \frac{K \cdot n}{x}$) \\
  Sei $X$ Zufallsvariable Anzahl der markierten Fische (von $n$) 
  \begin{align*}
    P_N(X=j)=\frac{\binom{K}{j}\binom{N-K}{n-j}}{\binom{N}{n}}\quad N \geq \max(K,n)=:N^*
  \end{align*}
  Angenommen $X(w)=x$ \\
  \underline{Idee}: Wähle $N (\geq N^*)$ für das $P_N(X=x)$ maximal ist. \\
  Es gilt:
  \begin{align*}
    \frac{P_N(X=x)}{P _{N-1}(X=x)}=\frac{\cancel{\binom{K}{x}}\binom{N-K}{n-x}}{\binom{N}{n}}\cdot \frac{\binom{N-1}{n}}{\cancel{\binom{K}{x}}\binom{N-1-K}{n-x}}
  \end{align*}
  Nebenrechnung: 
  \begin{align*}
    \frac{\binom{N-1}{n}}{\binom{N}{n}}=\frac{(N-1)!}{\cancel{n!}(N-1-n)!}\cdot \frac{\cancel{n!}(N-n)!}{N!}=\frac{N-n}{N}
  \end{align*}
  Nebenrechnung vorbei. \\
  Nach der Nebenrechnung gilt 
  \begin{align*}
    \frac{P_N(X=x)}{P _{N-1}(X=x)}
    &=\frac{(N-n)(N-K)}{N(N-K-(n-x))}
  \end{align*}
  Für das größte $N$ mit $P_N(X=x)\geq P _{N-1}(X=x)$ gilt 
  \begin{align*}
    (N-n)(N-K)\geq N(N-K-n-x)\Leftrightarrow nK \geq Nx \Leftrightarrow N \leq \frac{n \cdot K}{x}
  \end{align*}
  daraus folgt
  \begin{align*}
    \Rightarrow \hat{N}(x)=\max \left\{i \in \mathbb{N}:i \leq \frac{nK}{x}\right\}=\bigg\lfloor \frac{nK}{x}\bigg\rfloor
  \end{align*} 
  $\hat{N}(x)$ heißt ML-Schätzer für $N$.  
\end{bei}
\begin{defi}{6.4}{}
  Sei $X$ Zufallsvariable mit (diskreter oder stetiger) Dichte $f _{\vartheta }$, $\vartheta \in \Uptheta$. Man nennt
  \begin{align*}
    L:\Uptheta\to \mathbb{R}:\vartheta \to L(\vartheta ,x)=f _{\vartheta }(x) \quad (x\text{ fest})\text{  \underline{Likelihood-Funktion}}
  \end{align*}
  \begin{align*}
    l=\ln L \text{ \underline{log-Likelihood-Funktion}}
  \end{align*}
  Ein Schätzer $\hat{\vartheta }:\mathcal{X}\to \Uptheta$ heißt \underline{Maximimum-Likelihood Schätzer}, falls gilt 
  \begin{align*}
    \forall\;x \in \mathcal{X}:\sup _{\vartheta \in \Uptheta}L(\vartheta ,x)=L(\hat{\vartheta },x)
  \end{align*}
  d.h. $\hat{\vartheta }=\text{arg}\sup _{\vartheta \in \Uptheta} f _{\vartheta }(x)$ 
\end{defi} 
\begin{bem}[6.5]
  (a) \\
  Für $X$ diskret: wähle das 'wahrscheinlichste' $\vartheta $, also $\hat{\vartheta }$ mit $P _{\hat{\vartheta }}(X=x)\geq P _{\vartheta }(X=x)$  \\
  (b)\\
  Oft einfacher: maximiere $l=\ln L$ statt $L$ (geht, da $\ln$ streng monoton)   \\
  (c)\\
  Für $X_1,X_2,...,X_n \overset{iid}\sim f _{\vartheta }^{(1)}$ gilt:
  \begin{align*}
    &L(\vartheta ,x_1,...,x_n)=\prod_{i=1}^{n}{f _{\vartheta }^{(1)}(x_i)}\\
    &l(\vartheta ,x_1,...,x_n)=\sum_{i=1}^{n}{\ln f _{\vartheta }^{(1)}(x_i)}
  \end{align*}
  (d)\\
  Ist $f _{\vartheta }(x),\vartheta \mapsto f _{\vartheta }(x)$ differenzierbar, dann erfüllt der ML Schätzer die (log-)Likelihood Gleichungen:
  \begin{align*}
    \frac{\partial }{\partial \vartheta _i}l(\vartheta ,x_1,...,x_n)\bigg|_{\vartheta =\hat{\vartheta }}^{}=0\quad \forall\;j=1,...,k\;\;\forall\;x \in \mathcal{X}
  \end{align*}
  ($\vartheta =(\vartheta _1,...,\vartheta _k)\in \Uptheta \subseteq \mathbb{R}^k$)
\end{bem}
\begin{bei}[6.6]
  (a)\\
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $\vartheta :=(\mu ,\sigma ^2)^T \in \Uptheta:=\mathbb{R}\times (0,\infty )$, $\nu :=\sigma ^2$. 
  \begin{align*}
    &L_x(\vartheta ):=L(\vartheta ,x)=\prod_{j=1}^{n}{f_j(X_j|\vartheta )}\\
    &l_x(\vartheta ):=l(\vartheta ,x)=\sum_{j=1}^{n}{-\frac{n}{2}\ln(2 \pi )-\frac{n}{2}\ln(\nu )-\frac{1}{2}\nu ^{-1}}\sum_{j=1}^{n}{(x_j-\mu )^2}
  \end{align*}
  \begin{align*}
    &\frac{\partial l_x(\vartheta ) }{\partial \mu }=\nu ^{-1}\sum_{j=1}^{n}{(X_j-\mu )}\overset{!}=0 \Leftrightarrow \hat{\mu} =\bar{X}_n \\
    &\frac{\partial l_x(\vartheta)}{\partial \nu }=-\frac{n}{2}\nu ^{-1}+\frac{1}{2}\nu ^{-2}\sum_{j=1}^{n}{(X_j-\mu )^2}\overset{!}=0 \Rightarrow \hat{\nu} =\frac{1}{n}\sum_{j=1}^{n}{(X_j-\mu )^2}
  \end{align*}
  %Probe: 2. Ableitung (Übungsaufgabe, hier aber nicht nötig, Exponentialfamilie $\Rightarrow $ konvex)\\
  Zudem:
  \begin{align*}
    \lim_{|\mu |\to \infty }{L_x(\vartheta )}=0=\lim_{\nu \to \infty }{L_x(\vartheta )},\text{ also }\hat{\vartheta }_{ML}(X)=\left(\bar{X}_n,\frac{1}{n}\sum_{j=1}^{n}{(X_j-\bar{X}_n)^2}\right)^T=(\hat{\mu },\hat{\nu })^T
  \end{align*}
  d.h. der MLE (Maximum Likelihood Estimator) stimmt mit dem MomE (Method of moments estimator) überein,\\
  $\hat{\vartheta }=(\hat{\mu },\hat{\sigma })$ ist konsistent, $\hat{\mu }$ erwartungstreu, $\hat{\nu }$ asymptotisch unerwartungstreu \\
  \underline{Beachte}: $\mu $ bekannt $\Rightarrow \tilde{\nu }=\frac{1}{n}\sum_{j=1}^{n}{(X_j-\mu )^2}$, $\nu $ bekannt $\Rightarrow \tilde{\mu }=\hat{\mu }\sim N(\mu ,\frac{\nu }{n})$ (beide erwartungstreu)
  \begin{align*}
    \frac{n \tilde{\nu }}{\nu }=\sum_{i=1}^{n}{\bigg(\underbrace{\frac{X_i-\mu }{\sigma }}_{\sim N(0,1)}\bigg)^2}\sim \chi _n^2 \text{ \ aber  \ }\frac{n \hat{\nu }}{\nu }=\frac{(n-1)\hat{S}_n^2}{\sigma ^2}\sim \chi _{n-1}^2
  \end{align*}
  (b)\\
  $X_1,X_2,...,X_n \overset{iid}\sim U(0,\vartheta )$, $\Uptheta=(0,\infty )$, $y \in (0,\infty )^n$,
  \begin{align*}
    L_y(\vartheta )=\vartheta ^{-n} 1_{(0,\vartheta )}(\max\{y_1,...,y_n\})=\vartheta ^{-n}1(0<Y _{(n)}<\vartheta )
  \end{align*} 
  $\vartheta ^{-n}$ fallend in $\vartheta $, $Y _{(n)}<\vartheta$ wähle also das kleinste $\vartheta > Y _{(n)}$
  \begin{align*}
    \Rightarrow \hat{\vartheta }_{ML}(X)=\max \left\{X_1,X_2,...,X_n \right\}=X _{(n)}\neq MomE
  \end{align*}
  Nebenbemerkung:
  \begin{align*}
    L(\vartheta ,x):=f _{\vartheta }(x)=\begin{cases}
      P _{\vartheta }[\{x\}] &\text{diskret}\\
      \frac{d P _{\vartheta }}{d \gamma }(x) &\text{stetig}
    \end{cases}
  \end{align*}
  Nebenbemerkung vorbei. \\
  Hier und im Allgemeinen gilt ML-Schätzer und MoM-Schätzer stimmen nicht überein.
\end{bei}
\begin{theo}{6.7}{}
  Sei $T$ suffiziente Statistik für $\vartheta $ und $\hat{\vartheta }$ MLE für $\vartheta \Rightarrow \hat{\vartheta }$ ist Funktion von $T$; $\xi \circ T$    
\end{theo}
\begin{bew}[]
  Nach (4.5) (Neyman-Fischer) gilt für $T$ suffizient, $x \in \mathcal{X}$ fest
  \begin{align*}
    L(\vartheta ,x)=f _{\vartheta }(x)=g _{\vartheta }\circ T(x) h(x)=g _{\vartheta }(t)h(x)
  \end{align*}
 $\hat{\vartheta }=\text{arg}\sup\limits _{\vartheta \in \Uptheta}L(\vartheta ,x)=\text{arg}\sup\limits _{\vartheta  \in \Uptheta}g _{\vartheta (t)}$ $\square$ 
\end{bew}
\begin{theo}{6.8}{}
  Die Voraussetzung von (5.8) (Cramér-Rao bound) seien erfüllt. \\
  Sei $T(X)$ erwartungstreu und effizient für $\vartheta $ ($\psi =\text{id}_{\vartheta }$) d.h. $Var(T(X))=I_n(\vartheta )$\\
  Dann hat die Likelihood-Gleichung die eindeutige Lösung 
  \begin{align*}
    \hat{\vartheta }(x)=T(X), \text{ d.h. }\vartheta _{ML}=T(X)
  \end{align*}
  %Memo: $Var_{\vartheta }T(X)\geq \frac{(\psi '(\vartheta ))^2}{I _{n}(\vartheta )}$ und Anmerkung $|EXY|\leq \sqrt{EX^2}\sqrt{EY^2}$, $\tilde{X}=T(X)-\psi (\vartheta )$, $\tilde{Y}=\frac{\partial }{\partial \vartheta  }\ln f _{\vartheta }(X)$ $(\#)$ Gleichheit für $T(X)-\psi (\vartheta )=k(\vartheta )\frac{\partial }{\partial \vartheta }\ln _{\vartheta }(X)$, $E \tilde{X}\tilde{Y}=\psi '(\vartheta )^2$ 
\end{theo}
\begin{bew}[]
  %Hier gilt nach $(\#)$  
  %\begin{align*}
  %  \frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)=\frac{1}{k(\vartheta )}(T(X)-\vartheta )=0  \Leftrightarrow T(X)=\vartheta  \text{ eindeutige Lösung}
  %\end{align*} 
  %weiter 
  %\begin{align*}
  %  \frac{\partial^2 }{\partial \vartheta ^2}l(\vartheta ,X)\bigg|_{T(X)=\vartheta }^{}
  %  &=\frac{\partial }{\partial \vartheta }\frac{1}{k(\vartheta )}(T(X)-\vartheta )=-k^{-2}\cdot  k'(T-\vartheta )-k ^{-1}\bigg|_{T(X)=\vartheta }^{}\\
  %  &= -k(\vartheta ) ^{-1}\overset{!}<0 
  %\end{align*}
  %Mit Theorem (5.8) (iii) (b):
  %\begin{align*}
  %  \frac{\partial }{\partial \vartheta }E _{\vartheta }T(X)=E _{\vartheta }\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)T(X)
  %\end{align*}
  %folgt für $\psi =\text{id}_{\Uptheta}$ 
  %\begin{align*}
  %  1=\psi '(\vartheta )=E _{\vartheta }\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)T(X); \;((iii)(a) E _{\vartheta }\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)=0)
  %\end{align*}
  %\begin{align*}
  %  1 = E _{\vartheta }(T(X)-\vartheta )\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(X)
  %  &\overset{(\#)}=E _{\vartheta }k(\vartheta )(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x))^2 \\
  %  &=k(\vartheta )I_n(\vartheta )\Rightarrow \frac{1}{k(\vartheta )}=I_n(\vartheta )>0 \forall\;\vartheta \in \Uptheta \Rightarrow \square
  %\end{align*}
  Siehe Bemerkung 5.9: \\
  In Rao-Cramer Ungleichung wird Gleichheit angenommen, falls mit Wahrscheinlichkeit $1 $ gilt:
  \begin{align*}
    &\frac{\partial }{\partial \vartheta }f(\vartheta ,x)=\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\overset{\text{Bem.}}=\frac{1}{k(\vartheta )}(T(X)-\vartheta )=0 \\
    &\Leftrightarrow T(X)-\vartheta =0 \Rightarrow \hat{\vartheta }=T(X) \text{ eindeutige Lösung}
  \end{align*}
  Weiter gilt 
  \begin{align*}
    \frac{\partial ^2}{\partial \vartheta ^2}l(\vartheta ,x)=\frac{\partial }{\partial \vartheta }\bigg(\frac{1}{k(\vartheta )}\bigg)\cdot (\underbrace{T(X)}_{\hat{\vartheta }}-\vartheta )+\frac{1}{k(\vartheta )}(0-1)=-\frac{1}{k(\vartheta )}  \text{ für }\vartheta =\hat{\vartheta }
  \end{align*}
  zu zeigen bleibt $\frac{\partial ^2}{\partial \vartheta ^2}l(\vartheta ,x)\bigg|_{\vartheta =\hat{\vartheta }}=-\frac{1}{k(\hat{\vartheta })}<0 $ ($\Rightarrow  $ lokales Maximum) \\
  Mit 5.8 Annahme (iiib) folgt für $\psi (\vartheta )=\vartheta  $:
  \begin{align*}
    1&=\psi '(\vartheta )=\frac{\partial }{\partial \vartheta }E _{\vartheta }(T(X))\overset{5.8}=E _{\vartheta }\bigg(T(X)\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\bigg)\\
     &=E _{\vartheta }\bigg([T(X)-\vartheta ]\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\bigg)\text{ da }E _{\vartheta }\bigg(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\bigg)=0 \\
     &\!\!\!\!\overset{\text{Bem.}}{\underset{\text{zu 5.8}}{=}}E _{\vartheta }\bigg(k(\vartheta )\bigg(\frac{\partial }{\partial \vartheta }\ln f _{\vartheta }(x)\bigg)^2\bigg)=k(\vartheta )I_n(\vartheta )
  \end{align*}
  \begin{align*}
    \Rightarrow \frac{1}{k(\vartheta )}=I _n(\vartheta )>0\quad \forall\;\vartheta \in \Uptheta \text{ also }-\frac{1}{k(\hat{\vartheta })}<0\;\square
  \end{align*}
\end{bew}
\begin{bem}[6.9]
  $\hat{\vartheta }$ erwartungstreu, effizient und Anmerkung (5.8) sei erfüllt. Dann folgt
  \begin{align*}
    \hat{\vartheta } \text{ ist MLE}
  \end{align*}
  \underline{Aber}: nicht jeder MLE ist erwartungstreu oder effizient.
\end{bem}
\begin{bem}[6.10]
  Ist $\hat{\vartheta }$ MLE für $\vartheta $, dann ist $\hat{\gamma }=\gamma (\hat{\vartheta })$ (plug-in) MLE für $\gamma =\gamma (\vartheta )$.  \\
  Rechtfertigung:
\end{bem}
\begin{theo}{6.11}{}
  Es seien $\Uptheta \subseteq \mathbb{R}^{k}$, $\psi :\Uptheta\to \Gamma =\psi (\Uptheta) \subseteq \mathbb{R}^p$, $1 \leq p \leq k$,  $\{f _{\vartheta }:\vartheta  \in  \Uptheta\}$ Familie von diskreten oder stetigen Dichten und $\hat{\vartheta }$ MLE für $\vartheta $.\\
  Dann maximiert $\hat{\gamma }=\psi (\hat{\vartheta })$ die von $\gamma $ induzierte Likelihood $M(\gamma ,x)=\sup\limits _{\vartheta \in \Uptheta _{\gamma }}L(\vartheta ,x)$, wobei \\
  $\Uptheta _{\gamma }:=\{\vartheta \in \Uptheta:\psi (\vartheta )=\gamma \}\overset{(**)}\subseteq \Uptheta $.
\end{theo}
\begin{bew}[]
  $\hat{\gamma }:=\psi (\hat{\vartheta }),\hat{\vartheta }\in \Uptheta _{\hat{\gamma }}$. Dann ist 
  \begin{align*}
    &M(\hat{\gamma },x)=\sup _{\vartheta \in \Uptheta _{\hat{\gamma }}}L(\vartheta ,x)\underline{\geq L(\hat{\vartheta} ,x)}\\
    &M(\hat{\gamma },x)\leq \sup _{\gamma \in \Gamma }M(\gamma ,x)\leq \sup _{\gamma \in \Gamma }\sup _{\vartheta \in \Uptheta _{\gamma }}L(\vartheta ,x)\underline{\overset{(**)}\leq} \sup _{\vartheta \in \Uptheta}L(\vartheta ,x)=\underline{L(\hat{\vartheta },x)}
  \end{align*}
  Ingesamt muss also Gleichheit gelten und demnach ist
  \begin{align*}
    M(\hat{\gamma },x)=\sup _{\gamma \in \Gamma }M(\gamma ,x)\;\square
  \end{align*}
\end{bew}
\begin{bei}[6.12]
  $X_1,X_2,...,X_n \overset{iid}\sim$ Bin$(1,p)$, $\Uptheta:=(0,1)$, $\psi :=V _{p}X_1=p(1-p)$    
  \begin{align*}
    \hat{p}_{ML}=\bar{X}_n \text{ ist MLE (Ü)} \Rightarrow \psi (\hat{p})=\bar{X}_n(1-\bar{X}_n)\text{ ist MLE für }\psi (p)
  \end{align*}
\end{bei}
\begin{bem}[6.13]
  MLEs sind (unter Regularitätsvoraussetzungen) asymptotisch normal; $\sqrt{n}(\hat{\vartheta }-\vartheta )\overset{\text{D}}\to N_k(0,I_1(\vartheta )^{-1})$ wobei $I_1(\vartheta )$ die Fischer-Matrix mit Einträgen $E _{\vartheta }(\frac{\partial }{\partial \vartheta _j}\ln f_{\vartheta }^{(1)}(X_1)\frac{\partial }{\partial \vartheta _k}\ln _{\vartheta }^{(1)}(X_1))$ ist.  
\end{bem}
\chapter{Lineare Regression}
Wozu? Modellierung der linearen Abhängigkeit zwischen einer Zufallsvariablen $X$ und einer Zufallsvariablen $Y$.
\begin{bei}[]
  - Länge einer Feder $Y$ hängt ab ab von Belastung $X$\\
  - Blutdruck $Y$ hängt ab von Alter $X$ 
\end{bei}
\noindent Beobachtungen: $(x_j,y_j)$, $j=1,...,n$, \\
$x_j$ 'Designpunkte' (deterministisch), \\
$y_j$ 'Beobachtungen' (zufällig)
\section*{Lineares Regressionsmodell}
$y_j=\underline{a}x_j+\underline{b}+\varepsilon _j\to$ Messfehler (zufällig) \\
\underline{Annahmen}: $\varepsilon _1,...,\varepsilon _n$ unabhängig, $E \varepsilon _j=0$, $Var \varepsilon _j=\sigma ^2$, $j=1,...,n$ \\
\underline{Ziel}: Schätze die Regressions-Koeffizienten $a,b$ und erkläre damit den Zusammenhang zwischen $X$ und $Y$.  
\begin{center}
\begin{tikzpicture}
\begin{axis}[
  xtick = \empty,
  ytick = \empty,
xmin=0,
ymin=0,
xmax = 1.0,
ymax = 1.0,
xlabel = $x$,
ylabel = $y$,
samples = 20,
legend pos=outer north east,
axis lines = box,
ylabel style = {rotate =-90},
trig format plots = rad,
]
\addplot[domain=0:1]{0.25+0.466*x};
%\draw (axis cs:0,3) circle [black, radius=0.2];
\addplot[black, mark=*, only marks] coordinates {(0.1,0.2)(0.2,0.4)(0.3,0.5)(0.4,0.4)(0.5,0.5)(0.6,0.5)(0.7,0.6)(0.8,0.7)(0.9,0.6)};
\end{axis}
\end{tikzpicture}
\end{center}
\underline{Ansätze für Schätzer}: Beschränkung auf lineare Schätzer, d.h. 
\begin{align*}
  \hat{a}=\sum_{i=1}^{n}{a_iy_i},\quad \hat{b}=\sum_{i=1}^{n}{b_iy_i}
\end{align*}
Suchen Koeffizienten $a_i,b_i$, $i=1,...,n$ die von den Designpunkten abhängen.  \\
\underline{Erwartungstreue}
\begin{align*}
  E \hat{a}
  =a &\Leftrightarrow E\left(\sum_{i=1}^{n}{a_iy_i}\right)=\sum_{i=1}^{n}{a_iE(y_i)} \\
  &=\sum_{i=1}^{n}{a_i(ax_i+b)}=a \underbrace{\sum_{i=1}^{n}{a_ix_i}}_{\overset{!}=1}+b \underbrace{\sum_{i=1}^{n}{a_i}}_{\overset{!}=0}=a
\end{align*}
Analog
\begin{align*}
  E \hat{b}=a \underbrace{\sum_{i=1}^{n}{b_ix_i}}_{\overset{!}=0}+b \underbrace{\sum_{i=1}^{n}{b_i}}_{\overset{!}=1}=b
\end{align*}
\underline{Fordern}: 
\begin{align*}
  &\sum_{i=1}^{n}{a_ix_i}=1, \quad \sum_{i=1}^{n}{a_i}=0 \\
  &\sum_{i=1}^{n}{b_ix_i}=0\quad \sum_{i=1}^{n}{b_i}=1
\end{align*}
\underline{In Matrixschreibweise}:
\begin{align*}
  C=\begin{pmatrix}
    a_1&...&a_n\\b_1&...&b_n
  \end{pmatrix}\quad X=\begin{pmatrix}
    x_1&...&x_n\\1&...&1
  \end{pmatrix}
\end{align*}
\begin{align*}
  &CX^T=\begin{pmatrix}
    a_1&...&a_n\\b_1&...&b_n
  \end{pmatrix}\begin{pmatrix}
    x_1&1\\\vdots&\vdots\\x_n&1
  \end{pmatrix}=\begin{pmatrix}
    \sum_{j=1}^{n}{a_jx_j}&\sum_{j=1}^{n}{a_j}\\\sum_{j=1}^{n}{b_jx_j}&\sum_{j=1}^{n}{b_j}
  \end{pmatrix}\overset{!}=\begin{pmatrix}1&0\\0&1\end{pmatrix} \Leftrightarrow \underbrace{CX^T=I}_{:\Leftrightarrow (F1)}
\end{align*}
\underline{Minimale Varianz}
\begin{align*}
  Var (\hat{a})
  &=Var \left(\sum_{i=1}^{n}{a_iy_i}\right)=\sum_{i=1}^{n}{a_i^2 Var(y _i)}=\sigma ^2 \sum_{i=1}^{n}{a_i^2}\\
  &=\sigma ^2 \cdot \left|\left|\begin{pmatrix}1&0\end{pmatrix}\cdot \begin{pmatrix}
  a_1&...&a_n\\b_1&...&b_n
  \end{pmatrix}\right|\right|_{2}^2=\sigma ^2||e_1^TC||_2^2
\end{align*}
Analog
\begin{align*}
  Var (\hat{b})=\sigma ^2||e_2^TC||_2^2
\end{align*}
\underline{Ansatz für $C$}: $C=DX$, $D \in \mathbb{R}^{2 \times 2}$ (F2) \\
Angenommen wir haben Matrix $C$, die $(F1)$ erfüllt und $\tilde{C}$ sei eine beliebige weitere solche Matrix. Wann gilt 
\begin{align*}
  \sigma ^2||e_j^TC||_2^2 \leq \sigma ^2||e_j^T \tilde{C}||_2^2 \;\;?\quad \text{(min. Varianz)}
\end{align*}
Dann folgt
\begin{align*}
  \tilde{C}X^T-CX^T=(\underbrace{\tilde{C}-C}_{=:\Delta})X^T=\begin{pmatrix}0&0\\0&0\end{pmatrix}
\end{align*}
und damit
\begin{align*}
  \Delta C^T=\Delta X^TD^T=0D^T={0}
\end{align*}
\begin{align*}
  \Rightarrow ||e_j^T \tilde{C}||_2^2=||e_j^TC+e_j^T\Delta||_2^2=||e_j^TC||_2^2+\underbrace{||e_j^T\Delta||_2^2}_{\geq 0}+\underbrace{e_j^T\Delta C^Te_j}_{=0}+\underbrace{e_j^TC\Delta ^Te_j}_{=0}\geq ||e_j^TC||_2^2
\end{align*}
also minimiert $C$ die Varianz, d.h. wähle die Einträge von $C$ für die Koeffizienten der Schätzer. \\
\underline{Zu zeigen}: Es existiert auch wirklich eine Matrix $C$ mit $CX^T=I$ und $C=DX$. 
\begin{align*}
  \Rightarrow DXX^T=I \Rightarrow D=(XX^T)^{-1} \text{ falls }XX^T \text{ invertierbar ist.}
\end{align*}
\begin{align*}
  XX^T&=\begin{pmatrix}
    x_1&...&x_n\\1&...&1
  \end{pmatrix}\begin{pmatrix}
    x_1&1\\\vdots&\vdots\\x_n&1
  \end{pmatrix}=\begin{pmatrix}
    \sum_{}^{}{x_i^2}&\sum_{}^{}{x_i}\\\sum_{}^{}{x_i}&n
  \end{pmatrix} \\
      &=n \begin{pmatrix}
        \bar{x}^2&\bar{x}\\\bar{x}&1
      \end{pmatrix}
\end{align*}
\begin{align*}
  \det(XX^T)=n^2\left(\bar{x}^2-(\bar{x})^2\right)
\end{align*}
$XX^T$ invertierbar $\Leftrightarrow \bar{x}^2\neq (\bar{x})^2$. Wann ist $\bar{x}^2=(\bar{x})^2$? \\
Betrachte Zufallsvariable $Z\sim U(\{x_1,...,x_n\}) $. 
\begin{align*}
  EZ&=\sum_{}^{}{\frac{1}{n}x_i}=\bar{x}\\
  VarZ&=\bar{x}^2-(\bar{x})^2
\end{align*}
Wann gilt $VarZ=0$? Falls $Z=EZ$ $P$-fast sicher  $\Leftrightarrow x_1=...=x_n$ \\
$\Rightarrow $ Sofern $x_i \neq x_j$ für ein Paar $(i,j)\in \{1,...,n\}^2$ (F3) ist $XX^T$ invertierbar. \\
Damit ergibt sich 
\begin{align*}
  D=(XX^T)^{-1},\quad C=DX=(XX^T)^{-1}X \text{ mit }\underline{y}=(y_1,...,y_n)^T \text{ und}
\end{align*}
\begin{align*}
  \begin{pmatrix}\hat{a}\\\hat{b }\end{pmatrix}=\begin{pmatrix}
  \underline{a}^T&\underline{y}\\\underline{b}^T&\underline{y}
  \end{pmatrix}=Cy
\end{align*}
\begin{theo}{}{}
  Wir betrachten das lineare Regressionsmodell mit der Zusatzvoraussetzung, dass nicht alle $x_i$ ($i=1,...,n$) übereinstimmen. Dann hat der Regressionsschätzer
  \begin{align*}
    \begin{pmatrix}\hat{a}\\\hat{b}\end{pmatrix}=(XX^T)^{-1}X \underline{y}
  \end{align*}
  für Koeffizienten $a$ und $b$ unter allen linearen erwartungstreuen Schätzern die kleinste Varianz. ('BLUE' Best Linear Unbiased Estimator)  
\end{theo}
\begin{bem}[]
  Die Gerade $\hat{a}x+\hat{b}$ ist die Ausgleichsgerade aus der Numerik, die man mit der Methode der kleinsten Quadrate erhält. \\
Minimierung mit Euklidischen Abstand $\triangleq$ Minimierung mit der Varianz.
\end{bem}
\chapter{Hypothesentests}
\section{Grundlagen und Beispiele} 
\begin{bei}[8.1]
  $X:\Omega \to \mathcal{X}$ Zufallsvariable, $X\sim\{P _{\vartheta }:\vartheta \in \Uptheta\}$, $\Uptheta=\Uptheta_0 \cup \Uptheta_1$ disjunkt, nicht-leer ($\Uptheta_0 \overset{.}\cup \Uptheta_1,\Uptheta_0+\Uptheta_1$) \\
  Gegeben: $X(w)=x$ \\
  Entscheide ob $H_0:\vartheta \in \Uptheta_0$ oder $H_1:\vartheta \in \Uptheta_1$? \\
  \underline{Bsp}: 2 Medikamente $M_1$ (etabliert), $M_2$ (neu) \\
  Heilungswahrscheinlichkeit von $M_1:\theta =0.8$ bekannt, von $M_2:\vartheta $ unbekannt \\
  $H_0:\vartheta \leq 0.8$, also $\vartheta \in [0,0.8]$ ($M_2$ nicht besser als $M_1$)\\
  $H_1:\vartheta \in \Uptheta_1=(0.8,1]$ ($M_2$ besser als $M_1$) \\
  Teste $M_2$ an 50 Personen: $X_1,...,X _{50}\overset{\text{iid}}\sim Bin(1,\vartheta )$, '$X_i=1$'$\triangleq$ geheilt   \\
  Angenommen $\sum_{i=1}^{n}{X_i}=42$, $\hat{\vartheta }=\frac{\sum_{}^{}{X_i}}{n}=\frac{42}{50}=0.84$ \\
  Entscheidung?
\end{bei}
\begin{defi}{8.2}{}
  Sei $X$ Zufallsvariable, $\vartheta \in \Uptheta=\Uptheta_0 \overset{.}\cup \Uptheta_1$. \\
  Ein \underline{Hypothesentest} ist eine (messbare) Abbildung 
  \begin{align*}
    \varphi :\mathcal{X}\to[0,1]:x\mapsto \varphi (x)=P(\text{'Entscheidung für $H_1$') falls $x=X(w)$ beobachtet wurde }
  \end{align*}
  $\varphi $ heißt \underline{nicht-randomisiert}, falls $\varphi (\mathcal{X})\subseteq \{0,1\}$ (im Allgemeinen $\varphi (\mathcal{X})=\{0,1\}$) ($\triangleq$ üblicher Fall)
\end{defi}
\begin{bem}[8.3 Übliche Sprechweisen]
  Entscheidung für $H_1$: '$H_0$ wird verworfen' \\
  Entscheidung für $H_0$: '$H_0$ wird beibehalten/ nicht verworfen' (nicht genug Anhaltspunkte, dass $H_1$ gilt)
\end{bem}
\underline{Mögliche Fehler}
\begin{align*}
  \begin{array}{|c|c|c|}\hline
    \text{Entscheidung für}&\vartheta \in \Uptheta_0&\vartheta \in \Uptheta_1\\\hline
    H_0&\checkmark&\text{Fehler 2. Art}\\\hline
    H_1&\text{Fehler 1. Art}&\checkmark
  \\\hline\end{array}
\end{align*}
Kontrolliert wird die Wahrscheinlichkeit für den Fehler 1. Art ($\leq \alpha $ im Allgemeinen $\alpha \in \{0.01,0.05,0.1\}$)
\begin{defi}{8.4}{}
  Sei $\varphi :\mathcal{X}\to[0,1]$ ein Test mit $H_0:\vartheta \in \Uptheta_0$ vs. $H_1:\vartheta \in \Uptheta_1$. Die Funktion 
  \begin{align*}
    \beta _{\varphi }:\Uptheta\to [0,1]:\vartheta \mapsto \beta _{\varphi }(\vartheta )=E _{\vartheta }(\varphi (x))
  \end{align*}
  heißt \underline{Güte-Funktion} von $\varphi $.\\
  Sei $\alpha \in [0,1]$, dann heißt $\varphi $ \underline{Test zum Niveau $\alpha $} (Level $\alpha $, Signifikanzniveau $\alpha $), falls
  \begin{align*}
    \beta _{\varphi }(\vartheta )\leq \alpha \quad\forall\;\vartheta \in \Uptheta_0
  \end{align*}
  Für $\vartheta \in \Uptheta_1$ heißt $\beta _{\varphi }(\vartheta )$ \underline{Power/ Güte}. \\
  $\Phi _{\alpha }$ sei die Menge aller Tests zum Niveau $\alpha $.  
  \begin{align*}
    \sup \left\{\beta _{\varphi }(\vartheta ):\vartheta \in \Uptheta_0\right\}
  \end{align*}
  heißt \underline{effektives Niveau} von $\varphi $ ('size') 
\end{defi}
\begin{bem}[8.5]
  $\beta _{\varphi }(\vartheta )=$ Wahrscheinlichkeit Ablehnung von $H_0$ falls $\vartheta $ wahr. \\
  $\varphi $ nicht randomisiert: $\beta _{\varphi }(\vartheta )=1 \cdot P _{\vartheta }(\varphi (x)=1)+0$  \\
  $\varphi $ randomisiert: Für $X$ diskret (analog stetig) gilt 
  \begin{align*}
    P _{\vartheta }(\varphi (x)=1)
    &=\sum_{x}^{}{P _{\vartheta }(\varphi (x)=1,X=x)}\\
    &=\sum_{x}^{}{\underbrace{P _{\vartheta }(\varphi (x)=1|X=x)}_{\varphi (x)}P _{\vartheta }(X=x)}\\
    &=E _{\vartheta }(\varphi (x))
  \end{align*}
  $\vartheta \in \Uptheta_0$: $\beta _{\varphi }(\vartheta )$ Wahrscheinlichkeit Fehler 1. Art\\
  $\vartheta \in \Uptheta_1$: $\beta _{\varphi }(\vartheta )$, $1-\beta _{\varphi }(\vartheta )$  Wahrscheinlichkeit Fehler 2. Art
\end{bem}
\begin{bei}[8.6 Einseitiger Binomialtest, vgl. Beispiel 8.1]
  $X_1,X_2,...,X_n \overset{iid}\sim Bin(1,\vartheta )$, sei $\vartheta _0 \in (0,1)=\Uptheta$ konstant, $H_0:\vartheta \leq \vartheta _0$, $H_1:\vartheta >\vartheta _0$  \\
\underline{Ansatz}: Lehne $H_0$ ab, falls $\hat{\vartheta }=\bar{X}$ bzw. $\sum_{i=1}^{n}{X_i}$ 'groß', d.h. 
  \begin{align*}
    \varphi (x)=\begin{cases}
      1 &\sum_{}^{}{X_i}>k\\
      0& \text{sonst}
    \end{cases}\quad\text{ (nicht randomisiert)}
  \end{align*}
   Bestimmung von $k$, sodass $\varphi \in \Phi _{\alpha }$:
  \begin{align*}
    \beta _{\varphi }(\vartheta )
    &=P _{\vartheta }(\varphi (x)=1)\\
    &=\underbrace{P _{\vartheta }\bigg({\overbrace{\sum_{i=1}^{n}X_i}^{\sim Bin(n,\vartheta )} }>k\bigg)}_{\text{mon. wachs.}}\\
    &=\sum_{j=k+1}^{n}{\underbrace{\binom{n}{j}\vartheta ^j(1-\vartheta )^{n-j}}_{=:b(j,n,\vartheta )}}
  \end{align*}
  $\beta _{\varphi }(\vartheta )$ monoton wachsend in $\vartheta \Rightarrow $ $\underbrace{\beta _{\varphi }(\vartheta )}_{\text{Fehlerw. Fehler 1. Art}}\leq \beta _{\varphi }(\vartheta _0)$ $\forall\;\vartheta \leq \vartheta _0$  \\
  Wähle $k$, sodass
  \begin{align*}
    \beta _{\varphi }(\vartheta _0)=\sum_{j=k+1}^{n}{b(j,n,\vartheta _0)}\leq \alpha \quad \text{Niveau $\alpha $}
  \end{align*}
  und $\forall\;\vartheta \geq \vartheta _0$:
  \begin{align*}
    1-\beta _{\varphi }(\vartheta _0)=\sum_{j=0}^{k}{b(j,n,\vartheta )}\text{ mit $k$ möglichst klein}
  \end{align*}
d.h. $k:=\min \left\{l \in \{-1,0,...,n\}:\sum_{j=l+1}^{n}{b(l,n,\vartheta_0 )}\leq \alpha \right\}$ \\
\underline{Im Beispiel 8.1}: \\
$\vartheta _0=0.8$, $n=50$, $\sum_{i=1}^{50}{X_i}=42$, $\alpha =0.05$    
\begin{align*}
  \sum_{j=l+1}^{n}{b(j,50,0.8)}=\begin{cases}
    0.1034>\alpha  &l=43\\
    0.048<\alpha & l=44 
  \end{cases}\Rightarrow k=44
\end{align*}
Da $\sum_{}^{}{X_i}=42 \not > 44$ wird $H_0$ beibehalten. \\
Hier 
\begin{align*}
  \sup _{\vartheta \in \Uptheta}\beta _{\varphi }(\vartheta )=\beta _{\varphi }(\vartheta _0)=0.048<\alpha \text{ effektives Niveau}
\end{align*}
d.h. Niveau wird nicht ausgeschöpft. \\
\underline{Ausweg}: Randomisieren \\
Betrachte $H_0':\vartheta =\vartheta _0$, $H_1:\vartheta >\vartheta _0$  
\begin{align*}
  \tilde{\varphi }(x)=\begin{cases}
    1 &\sum_{}^{}{X_i}>k\\
    \gamma & \sum_{}^{}{X_i}=k \\
    0 & \sum_{}^{}{X_i}<k
  \end{cases}
\end{align*}
mit 
\begin{align*}
  \gamma =\frac{\alpha -P _{\vartheta_0 }(\sum_{i=1}^{n}{X_i}>k)}{P _{\vartheta _0}(\sum_{}^{}{X_i}=k)}
\end{align*}
$\tilde{\varphi }(x)$ ist randomisierter Test mit 
\begin{align*}
  \beta _{\tilde{\varphi }}(\vartheta _0)=E _{\vartheta _0}(\tilde{\varphi }(x))=1 \cdot P _{\vartheta _0}(\sum_{}^{}{X_i}>k)+\underbrace{\gamma \cdot P _{\vartheta _0}(\sum_{}^{}{X_i}=k)}_{\alpha -P _{\vartheta _0}(\sum_{}^{}{X_i}>k)}+0=\alpha 
\end{align*}
In der Programmiersprache R:\\
$b(44,50,0.8)=$dbinom($44,50,0.8$) (dbinom Dichte)\\
$\sum_{j=45}^{50}{b(j,50,0.8)}=1$-pbinom($44,50,0.8$) (pbinom Verteilungsfunktion)
\end{bei}
\begin{bei}[8.7 Einseitiger Gaußtest]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $\vartheta =\mu $, $\sigma ^2$ bekannt, $\mu _0$ fest mit $\mu \leq \mu _0$ \\
  a) $H_0$: $\mu \leq \mu _0$ vs. $H_1:\mu >\mu _0$    \\
  $\Uptheta_0=(-\infty ,\mu _0]$, $\Uptheta_1=(\mu _0,\infty )$\\
  \underline{Ansatz}: verwende $\bar{X}$ (effizient und erwartungstreu)  \\
  Lehne $H_0$ ab für $\bar{X}$ groß, $\varphi (x)=1_{(\bar{X}>c)}$ \\
  Bestimmung von $c$, sodass $\varphi \in \Phi _{\alpha }$: 
  \begin{align*}
    \beta _{\varphi }(\mu )
    &=\underbrace{P _{\mu }(\bar{X}>c)}_{\text{mon. wachs. in $\mu $}}=P _{\mu }\bigg(
    \underbrace{\frac{\sqrt{n}(\bar{X}-\mu )}{\sigma }}_{\sim N(0,1)}>\frac{\sqrt{n}(c-\mu )}{\sigma }\bigg)\\
    &=1-\Phi \left(\frac{\sqrt{n}(c-\mu )}{\sigma }\right)
    \overset{\mu \leq \mu _0}\leq 1-\Phi \left(\frac{\sqrt{n}(c-\mu _0)}{\sigma }\right)\overset{!}=\alpha 
  \end{align*}
  Auflösen nach $c$:
  \begin{align*}
    1-\alpha =\Phi \left(\frac{\sqrt{n}(c-\mu _0)}{\sigma }\right)
    &\Leftrightarrow 
    \Phi ^{-1}(1-\alpha )=\frac{\sqrt{n}(c-\mu _0)}{\sigma }\\
    &\Leftrightarrow \Phi ^{-1}(1-\alpha )\frac{\sigma }{\sqrt{n}}=c-\mu _0 \\
    \Rightarrow \Phi(x)=1(\bar{X}>c)=1(\bar{X}>\mu _0+\underbrace{\Phi ^{-1}(1-\alpha )\frac{\sigma }{\sqrt{n}}}_{(i)})
  \end{align*}
  $(i)$ ist $U _{1-\alpha }$ das $(1-\alpha )$-Quantil der $N(0,1)$-Verteilung, $P(N(0,1)\leq U _{1-\alpha })=\Phi(U _{1-\alpha })=1-\alpha $ \\\\
  (b)\\
  $H_0:\mu \geq \mu _0$, $H_1:\mu < \mu _0$ analog zu (a) 
  \begin{align*}
    \varphi (x)
    &=1\left(\bar{X}<\mu _0-\frac{\sigma }{\sqrt{n}}U _{1-\alpha }\right) \\
    &=1 \bigg(\frac{\sqrt{n}(\bar{X}-\mu _0)}{\sigma }< \underbrace{-U _{1-\alpha }}_{=U _{\alpha }}\bigg)
  \end{align*}
  (c)\\
  $H_0:\mu =\mu _0$, $H_1:\mu  \neq \mu _0$
  (\underline{zwei}seitiger Gaußtest zum Niveau $\alpha $) 
  \begin{align*}
    \varphi (x)=1 \left(\frac{\sqrt{n}|\bar{X}-\mu _0|}{\sigma }>U _{1-\alpha /2}\right)
  \end{align*}
\end{bei}
\begin{bei}[8.8 t-Test]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $\vartheta =(\mu ,\sigma ^2)$, $\mu _0$ fest \\
  (a)\\
  $H_0:\mu \leq \mu _0$, $H_1:\mu > \mu _0$  \\
  Analog zu Beispiel 8.7: 
  \begin{align*}
    \varphi (x)&=1 \left\{\bar{X}>\mu _0+\frac{\sqrt{\hat{S}^2}}{\sqrt{n}}t _{n-1,1- \alpha }\right\}\\
               &=1 \bigg\{\underbrace{\sqrt{n}\frac{\bar{X}-\mu _0}{\sqrt{\hat{S}^2}}}_{\overset{\mu =\mu _0}\sim t _{n-1}}>\underbrace{t _{n-1,1-\alpha }}_{(1-\alpha )-\text{Quantil}}\bigg\} \\
               &\qquad 
  \end{align*}
  $\varphi \in \Phi _{\alpha }$:
  \begin{align*}
    \beta _{\varphi }(\vartheta )
    &= P _{\vartheta }\left(\frac{\sqrt{n}(\bar{X}-\mu _0+\mu -\mu )}{\sqrt{\hat{S}_n^2}}
    >t _{n-1,1-\alpha }\right) \\
    &=P _{\vartheta }\bigg(\frac{\sqrt{n}(\bar{X}-\mu) }{\sqrt{\hat{S}^2}}>t _{n-1,1-\alpha }+\frac{\sqrt{n}({\mu _0-\mu} )}{\sqrt{\hat{S}_n^2}}\bigg) \\
    &\leq P _{\vartheta }\bigg(\underbrace{\frac{\sqrt{n}(\bar{X}-\mu )}{\sqrt{\hat{S}_n^2}}}_{\sim t _{n-1}}>t _{n-1,1-\alpha }\bigg)\text{ für }\mu \leq \mu _0 \\
    &=1-F _{t _{n-1}}(t _{n-1,1-\alpha })=1-(1-\alpha )=\alpha 
  \end{align*}
  (b)\\
  $H_0:\mu \geq \mu _0$, $H_1:\mu < \mu _0$
  \begin{align*}
    \varphi (x)=1 \left\{\frac{\sqrt{n}(\bar{X}-\mu _0)}{\sqrt{\hat{S}_n^2}}<- t _{n-1,1-\alpha }\right\}
  \end{align*}
  (c)\\
  $H_0:\mu =\mu _0$, $H_1:\mu  \neq \mu _0$
  \begin{align*}
    \varphi (x)=1 \left\{|\bar{X}-\mu _0|>\frac{\sqrt{\hat{S}_n^2}}{\sqrt{n}}t _{n-1,1-\alpha /2}\right\}
  \end{align*}
\end{bei}
\begin{bei}[8.9 $\chi ^2$-Test/ Chi-Quadrat-Test]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $\vartheta =(\mu ,\sigma ^2)$, $\sigma _0^2$ fest   \\
  (a) \\
  $H_0:\sigma ^2=\sigma _0^2$, $H_1:\sigma ^2 \neq \sigma _0^2$  \\
  \underline{Ansatz}: Lehne $H_0$ ab, falls $\frac{\hat{S}_n^2}{\sigma _0^2}\ll1$ oder $\frac{\hat{S}_n^2}{\sigma _0^2}\gg 1$, also $\frac{\hat{S}_n^2}{\sigma _0^2}\notin [c_1,c_2]$. \\
  Bestimme $c_1,c_2$ sodass $\varphi \in \Phi _{\alpha }$. \\
  Für $\vartheta \in \Uptheta_0=\mathbb{R}\times \{\sigma _0^2\}$ gilt: 
  \begin{align*}
    \beta _{\varphi }(\vartheta )
    &=1- P _{\vartheta }\left(c_1 \leq \frac{\hat{S}^2}{\sigma _0^2}\leq c_2\right)\\
    &\overset{\vartheta \in \Uptheta_0}=1-P _{(\mu ,\sigma _0   ^2)}\bigg((n-1)c_1 \leq \underbrace{\frac{(n-1)\hat{S}^2}{\sigma _0^2}}_{\sim \chi _{n-1}^2}\leq (n-1)c_2\bigg)\\
    &=1-[F _{\chi _{n-1}^2}((n-1)c_2)-F _{\chi _{n-1}^2}((n-1)c_1)]
  \end{align*}
  Wähle zum Beispiel 
  \begin{align*}
    c_1=\frac{\chi _{n-1,\alpha /2}^2}{n-1}\quad c_2=\frac{\chi _{n-1,1-\alpha /2}^2}{n-1}
  \end{align*}
  \begin{align*}
    \Rightarrow \beta _{\varphi }(\vartheta )\overset{\vartheta \in \Uptheta_0}
    =&1-(1-\alpha /2-\alpha /2)=\alpha 
  \end{align*}
  $\Rightarrow $ \underline{Zweiseitiger $\chi ^2$-Test}: \\
  Lehne $H_0$ ab, falls 
  \begin{align*}
    \frac{(n-1)\hat{S}^2}{\sigma _0^2}\notin \left[\chi _{n-1,\alpha /2}^2,\chi _{n-1,1-\alpha /2}^2\right]
  \end{align*}
  (b)\\
  Einseitiger $\chi ^2$-Test \\
  $H_0:\sigma ^2 \leq \sigma _0^2$ und $H_1:\sigma ^2>\sigma _0^2$  (oder $\geq $ und $<$)\\
  Ablehnung von $H_0$ falls  
  \begin{align*}
    \frac{(n-1)\hat{S}^2}{\sigma _0^2}>\chi _{n-1,1-\alpha }^2\quad(<\chi _{n-1,\alpha }^2)
  \end{align*}
\end{bei}
\noindent\textbf{Bemerkung} (p-Wert/ p-Value) 
  \begin{center}
     \begin{tikzpicture}
  \begin{axis}[ymin = 0, ymax = 1.1, xmin = -1.2, xmax = 1.2, xtick = \empty, ytick = \empty, samples = 250,
  extra x ticks = {0.4},
  extra x tick labels = {$T(w) $}
    ]
        \addplot[name path = parab2, domain = -1.2:0.4] {1/sqrt(3.14*0.32)*2.78^(-x^2/0.32)};
        \addplot[name path = parab, domain = 0.4:1.2] {1/sqrt(3.14*0.32)*2.78^(-x^2/0.32)};
        \addplot[name path = floor, draw = none, domain = 0.4:1.2] {0};
        \addplot[color=gray] fill between[of = parab and floor];
    \node[] (source) at (axis cs: 0,.6) {$p $-Wert};
    \node (destination) at (axis cs:0.55,0.25){};
       \draw[thick,->](source)--(destination);
\addplot[black, thick, mark=x, only marks] coordinates {(0.77,0)};
    \addplot +[mark=none, black, thick] coordinates {(0.4, 0) (0.4, 0.598)};
    \node[] (source2) at (axis cs: -0.1,.3) {Beobachtung};
    \node (destination2) at (axis cs:0.42,0){};
       \draw[thick,->](source2)--(destination2);
\addplot +[mark=none, black, thick] coordinates {(0.4, 0) (0.4, 0.598)};
    \node[] (source3) at (axis cs: 0.77,.7) {kritischer Wert};
    \node (destination3) at (axis cs:0.77,0){};
       \draw[thick,->](source3)--(destination3);
    \end{axis}
\end{tikzpicture}
  \end{center}
\begin{defi}{8.10}{}
  Sei $\alpha \in [0,1]$. Ein Test $\varphi_0  \in \Phi _{\alpha }$ heißt \underline{gleichmäßig bester} oder '\underline{U}niformly \underline{M}ost \underline{P}owerful' Test zum Niveau $\alpha $, falls   
  \begin{align*}
    \beta _{\varphi _0}(\vartheta )=\sup _{\varphi \in \Phi _{\alpha }}\beta _{\varphi }(\vartheta )\quad \forall\;\vartheta \in \underline{\Uptheta_1}
  \end{align*}
\end{defi}
\chapter{Neyman-Pearson-Lemma}
\noindent\textbf{Vorbemerkung} (9.1) \\
Einfache Hypothesen, $\vartheta =\vartheta _0$ vs. $\vartheta =\vartheta _1$, $\Uptheta=\{\vartheta _0,\vartheta _1\} $\\
UMP (Uniformly Most Powerful) Test maximiert $\beta _{\varphi }(\vartheta _1)=E _{\vartheta _1}\varphi (x)$ unter den Tests $\varphi \in \Phi _{\alpha }$, d.h. $E _{\vartheta _0}(\varphi (x))\leq \alpha $  \\
Modell: $\{f _{\vartheta _0},f _{\vartheta _1}\}$ bzw. $\{f_0,f_1\}$
\begin{theo}{9.2 Neyman-Pearson Lemma}{}
  (a) \\
  Jeder (Neyman-Pearson) Test der Form
  \begin{align*}
    \varphi (x)=\begin{cases}
      1 &f_1(x)>k \cdot f_0(x)\\
      \gamma (x)& f_1(x)=k \cdot f_0(x)\\
      0& f_1(x)<k \cdot f_0(x)
    \end{cases}
  \end{align*}
  mit $k \geq 0$, $\gamma \in [0,1]$ ist UMP Test zum Niveau $\alpha:=\beta _{\varphi }(\vartheta _0) $ für $H_0:\vartheta =\vartheta _0$ vs. $H_1:\vartheta = \vartheta _1$\\
  (b) \\
  Für jedes $\alpha \in (0,1)$ existiert ein NP (Neyman-Pearson) Test $\varphi $ mit
  \begin{align*}
    \gamma (x)\equiv \gamma \text{ und }\beta _{\varphi }(\vartheta _0)=\alpha 
  \end{align*}
  Mit (a) folgt $\varphi $ ist UMP.
\end{theo}
\begin{bew}[stetiger Fall (diskreter analog)]
  (a)\\
  Sei $k \geq 0$, $\psi \in \Phi _{\alpha }$. Zu zeigen $\beta _{\varphi }(\vartheta _1)-\beta _{\psi }(\vartheta _1)\geq 0$ 
  \begin{align*}
    \beta _{\varphi }(\vartheta _1)-\beta _{\psi }(\vartheta _1)
    &=E _{\vartheta _1}(\varphi (x)-\psi (X)) 
    =\int{(\varphi (x)-\psi (x))f_1(x)dx}\\
    &=\int{1(f_1(x)>k f_0(x))(\overbrace{\varphi (x)-\psi (x)}^{\geq 0} )\overbrace{f_1(x)}^{>k f_0(x)} dx}\\
    &+\int{1(f_1(x)=k f_0(x))(\varphi (x)-\psi (x))\overbrace{f_1(x)}^{=kf_0(x)} dx} \\
    &+\int{1(f_1(x)<k f_0(x))\underbrace{(\underbrace{{\varphi (x)} -\psi (x)}_{\leq 0})\underbrace{f_1(x)}_{<k f_0(x)}}_{\geq kf_0(x)}dx}\\
    &\geq \int{[\varphi (x)-\psi (x)]kf_0(x)dx}
    =k [E _{\vartheta _0}\varphi (x)-E _{\vartheta _0}\psi (x)] 
    =k(\underbrace{\beta _{\varphi }(\vartheta _0)}_{\alpha :=}-\underbrace{\beta _{\psi }(\vartheta _0)}_{\leq \alpha })
    \geq 0 
  \end{align*}
  \begin{align*}
    \Rightarrow \beta _{\varphi }(\vartheta _1)\geq \beta _{\psi }(\vartheta _1)
  \end{align*}
  d.h. $\varphi $ ist UMP Test. \\
  (b) Sei $\alpha \in (0,1)$, $\gamma (x)\equiv \gamma $  
  \begin{align*}
    E _{\vartheta _0}\varphi (x)
    &=P _{\vartheta _0}(f_1(x)>k f_0(x))+\gamma P _{\vartheta _0}(f_1(x)=kf_0(x))+0 \\
    &=\underbrace{1-\underbrace{P _{\vartheta _0}\bigg(\frac{f_1(x)}{f_0(x)}\leq k\bigg)}_{\text{mon. wachs.}}}_{=:\alpha (k)\text{ mon. fall. rechts-stetig}}+\gamma P _{\vartheta _0}\bigg(\frac{f_1(x)}{{f_0(x)}}=k\bigg)
  \end{align*}
  $\frac{f_1(x)}{f_0(x)}$ ist fast sicher ungleich Null, da $P _{\vartheta _0}(x \in \text{Träger} P _{\vartheta _0})=1$ \\
  Bestimme $k$ sodass 
  \begin{align*}
    \alpha (k)\leq \alpha \leq \alpha (k-)=\lim _{l \uparrow k}\alpha (l)
  \end{align*}
  \begin{align*}
    \gamma :=\begin{cases}
      0 &\alpha (k)=\alpha (k-) (=\alpha) \\
      \frac{\alpha -\alpha (k)}{\alpha (k-)-\alpha (k)}& \text{sonst}
    \end{cases}
  \end{align*}
  \begin{center}
    \begin{tikzpicture}
\begin{axis}[
  %ytick={0,1/5,2/5,3/5,4/5,1},
  ytick = \empty,
  xtick= \empty,
  extra y ticks = {0.45},
  extra y tick labels = {$\alpha  $},
  extra x ticks = {0.5},
  extra x tick labels = {$k $},
xmin=0.1,
ymin=0,
xmax = 1,
ymax = 0.9,
samples = 8,
legend pos=outer north east,
axis lines = box,
ylabel style = {rotate =-90},
trig format plots = rad,
]
\addplot[domain=0:0.5, dotted, thick] {0.45};
\addplot[jump mark left, mark = *, domain=0:1, samples = 5]{floor(4*(-(x+0.2)+1))/4+0.1};
\node[] (source) at (axis cs: 0.3,.2) {$\alpha (k) $};
    \node (destination) at (axis cs:0.5,0.36){};
       \draw[thick,->](source)--(destination);
\node[] (source2) at (axis cs: 0.7,.75) {$\alpha (k-) $};
    \node (destination2) at (axis cs:0.484,0.588){};
       \draw[thick,->](source2)--(destination2);
%\draw (axis cs:0,3) circle [black, radius=0.2];
%\addplot[black, thick, mark=x, only marks] coordinates {(0.208,0) (0.43,0)(0.65,0)(0.85,0)(1.07,0)};
\end{axis}
\end{tikzpicture}
  \end{center}
  Mit 
  \begin{align*}
    P _{\vartheta _0}\bigg(\frac{f_1(x)}{f_0(x)}=k\bigg)=\alpha (k-)-\alpha (k)\text{ (Sprunghöhe)}
  \end{align*}
  folgt 
  \begin{align*}
    E _{\vartheta _0}(\varphi (x))=\alpha (k)+\gamma P _{\vartheta _0}\bigg(\frac{f_1(x)}{f_0(x)}=k\bigg)=
    \begin{cases}
      \alpha +0 &\alpha (k)=\alpha (k-)\\
      \alpha (k)+\frac{\alpha -\alpha (k)}{\alpha (k-)-\alpha (k)}(\alpha (k-)-\alpha (k)) &\text{sonst}
    \end{cases}=\alpha\;\square
  \end{align*}
\end{bew}
\begin{bem}[]
  Konstruktion nur für diskrete Zufallsvariablen notwendig, sonst gilt $\gamma =0$.
\end{bem}
kurze Wiederholung
$H_0:\vartheta =\vartheta _0$, $H_1:\vartheta =\vartheta _1$\\
NP-Lemma
\begin{align*}
  \begin{cases}
    1 &>\\
    \gamma (x)&f_1(x)=k \cdot f_0(x)\\
    0&<
  \end{cases}
\end{align*}
($k \geq 0,\gamma \in [0,1]$)\\
UMP-Test $\alpha =\beta _{\varphi }(\vartheta _0)$ \\
kurze Wiederholung vorbei \\\\
\textbf{Erweiterung}
Für $\alpha =0$ und $\alpha =1$ \\
\underline{$\alpha =1$}: abgedeckt durch (a) $k=0$, $\gamma =1$, d.h.
\begin{align*}
  \varphi (x)=\begin{cases}
    1 &f_1(x)\geq 0\\
    0 &f_1(x)<0
  \end{cases}
\end{align*}
\underline{$\alpha =0$}: Setze $\varphi (x)=1\{f_0(x)=0\}$ 
d.h. $\varphi \equiv 0$ fast sicher. \\
Das entspricht '$k=\infty $'
\begin{align*}
  \varphi (x)=\begin{cases}
    1 &f_1(x)\geq \infty f_0(x)\\
    0 &f_1(x)<\infty f_0(x)
  \end{cases}
\end{align*}
\begin{align*}
  \beta _{\varphi }(\vartheta _0)=\int{1\{f_0(x)=0\}}f_0(x)dx=0\quad (=\alpha )
\end{align*}
Bleibt zu zeigen, dass das der beste Test ist. Sei dazu $\psi \in \Phi _{\alpha }$, d.h. 
\begin{align*}
  \underbrace{E _{\vartheta _0} \psi}_{\int{\psi (x)f_0(x)dx}} \leq \alpha =0
\end{align*}
also $\psi =0$ im Träger von $f_0$  
\begin{align*}
  \Rightarrow \beta _{\varphi }(\vartheta _1)-\beta _{\psi }(\vartheta _1)
  &=\int{1\{f_0>0\} (\underbrace{\varphi (x)-\psi (x)}_{0-0})f_1(x)dx}
  +\int{1\{f_0=0\}\underbrace{(\varphi (x)-\psi (x))}_{\geq 0}f_1(x)dx}\geq 0 \\
  \Rightarrow \beta _{\varphi }(\vartheta _1)&\geq \beta _{\psi }(\vartheta _1)
\end{align*}
\begin{bem}[9.3]
  (a)\\
  Man kann zeigen: Ist $\varphi $ UMP Test für $H_0:\vartheta =\vartheta _0$, $H_1:\vartheta =\vartheta _1$, dann ist $\varphi $ NP-Test außer auf Nullmengen $A$ mit $P _{\vartheta _0}(A)=P _{\vartheta _1}(A)=0$     \\
  (b)\\
  Vgl. Beispiel 5.15 ($\Uptheta=\vartheta _0,\vartheta _1,...,\vartheta _k$): $\frac{f_1(x)}{f_0(x)}$ ist suffizient für $\vartheta \in \{\vartheta _0,\vartheta _1\}$ \\
  (c)\\
  Ist $T$ suffizient, dann ist $\frac{f _{\vartheta _1}(x)}{f _{\vartheta _0}(x)}=\frac{g _{\vartheta _1}(T(x))}{g _{\vartheta _0}(T(x))}$ NP-Test der nur von $T(x)$ abhängt. \\
  \underline{Allgemein} ($\Uptheta $ beliebig): Ist $T$ suffizient, dann reicht es Tests zu betrachten, die nur von $T(x)$ abhängen, denn: \\
  Ist $\varphi $ Test $\Rightarrow E(\varphi (x)|T(x))$ ist auch Test (unabhängig von $\vartheta $) mit Gütefunktion 
  \begin{align*}
    E _{\vartheta }(E(\varphi (x)|T(x)))
    &=E _{\vartheta }(\varphi (x))=\beta _{\varphi }(\vartheta )
  \end{align*}
  d.h. die Gütefunktionen stimmen überein. 
\end{bem}
\begin{bei}[9.4]
  (a) \\
  $X\sim f \in \{f_0,f_1\}\triangleq \{\vartheta _0,\vartheta _1\}$ mit 
  \begin{align*}
    f_0(x)=\frac{1}{\sqrt{2 \pi }}e^{-\frac{x^2}{2}}, \quad f_1(x)=\frac{1}{2}e^{-|x|}
  \end{align*}
  \begin{align*}
    \frac{f_1(x)}{f_0(x)}=\frac{\sqrt{2 \pi }}{2}e^{-|x|+\frac{x^2}{2}}=\sqrt{\frac{\pi }{2}}e^{\frac{1}{2}(x^2-2|x|+1-1)}=\sqrt{\frac{\pi }{2}}e^{-\frac{1}{2}}e^{\frac{1}{2}(|x|-1)^2}\begin{cases}
      > &\\
      = \\
      <
    \end{cases}k \Leftrightarrow \left||x|-1\right|\begin{cases}
      > &\\
      = \\
      <
    \end{cases}\tilde{k}
  \end{align*}
    für $\tilde{k}$ mit 
  \begin{align*}
    \alpha =E _{\vartheta _0}(\varphi (x))=\int{\underbrace{1 \{||x|-1|>\tilde{k}\}}_{\varphi (x)}f_0(x)dx}
  \end{align*}
  $\varphi $ ist UMP Test für $H_0:f=f_0$, $H_1:f=f_1$   \\\\
  (b) \\
  $X_1,X_2,...,X_n \overset{iid}\sim$ Bin$(1,\vartheta )$, $\vartheta =\{\vartheta _0,\vartheta _1\}$, $\vartheta _0<\vartheta _1$
  \begin{align*}
    f_i(x)=\vartheta _i^{T(x)}(1-\vartheta _i)^{n-T(x)}\quad (i=0,1),\quad T(x)=\sum_{i=1}^{n}{X_i} \text{ (suffizient)}
  \end{align*}
  \begin{align*}
    \varphi (x)=1 \left\{\frac{f_1(x)}{f_0(x)}>k\right\}+\gamma 1 \left\{\frac{f_1(x)}{f_0(x)}=k\right\} \text{ NP Test}
  \end{align*}
  $\varphi $ ist UMP $\in \Phi _{\varphi }$ falls $\alpha =E _{\vartheta _0}(\varphi (x))$
  \begin{align*}
    \frac{f_1(x)}{f_0(x)}
    &=\left(\frac{\vartheta _1}{\vartheta _0}\right)^{T(x)}\left(\frac{1-\vartheta _1}{1-\vartheta _0}\right)^{n-T(x)} \\
    &=\bigg(\underbrace{\frac{\vartheta _1}{\vartheta _0}}_{>1}\bigg)^{T(x)}\left(\frac{1-\vartheta _1}{1-\vartheta _0}\right)^{n}\bigg(\underbrace{\frac{1-\vartheta _0}{1-\vartheta _1}}_{>1}\bigg)^{T(x)} \\
  \end{align*}
  streng monoton wachsend in $T(x)$. \\
  Finde also $\tilde{k},\tilde{\gamma }$ mit 
  \begin{align*}
    \tilde{\varphi }(x)=\begin{cases}
      1 &T(x)> \tilde{k}\\
      \tilde{\gamma }&T(x)=\tilde{k} \\
      0&T(x)<\tilde{k}
  \end{cases}\text{ und }E _{\vartheta _0}(\tilde{\varphi} (x))=\alpha 
  \end{align*}
  Diese Bedingungen erfüllt der einseitige Binomialtest aus (8.6) ($H_0:\vartheta =\vartheta _0,H_1:\vartheta >\vartheta _0$) \\
  Der Test ist auch UMP unter $H_0:\vartheta  \leq \vartheta _0$, $H_1:\vartheta >\vartheta _0$  
\end{bei}
\chapter{Monotone Dichtequotienten}
\begin{bem}[10.1]
  Parameterraum beim NP Lemma: $\Uptheta=\{\vartheta _0,\vartheta _1\}$ (einfache Hypothesen) \\
Dennoch ist NP Lemma wichtig für kompliziertere Hypothesen, z.B. 
\begin{align*}
  H_0:\vartheta \leq \vartheta _0\quad H_1:\vartheta >\vartheta _0 \text{ einseitige Tests}
\end{align*}
\underline{falls} die Verteilungsfamilie einen isotonen (monoton wachsenden) Dichtequotienten hat.
\end{bem}
\begin{defi}{10.2}{}
  Die Familie von Dichten $\{f _{\vartheta }:\vartheta \in \Uptheta \subseteq \mathbb{R}\} $ hat einen (strikt) \underline{isotonen Dichtequotienten} in $T:\mathcal{X}\to \mathbb{R}$ falls $\forall\;\vartheta _0,\vartheta _1 \in \Uptheta$ mit $\vartheta _0<\vartheta _1$ gilt: \\
  Es existiert eine streng monoton wachsende Funktion 
  \begin{align*}
    H _{\vartheta _0,\vartheta _1}(T(.)):\mathbb{R}\to[0,\infty )
  \end{align*}
  mit
  \begin{align*}
    \frac{f _{\vartheta _1}(x)}{f _{\vartheta _0}(x)}=H _{\vartheta _0,\vartheta _1}(T(x))\quad \forall\;x \text{ mit }f _{\vartheta _1}(x)+f _{\vartheta _0}(x)>0
  \end{align*}
\end{defi}
\begin{bei}[10.3]
  (a)\\
  $f _{\vartheta }(x)=\exp(Q(\vartheta )T(x)+S(x)+D(\vartheta ))$ ein-parametrige Exponentialfamilie mit $Q$ (streng) monoton wachsend hat einen (streng) monotonen Dichtequotienten (DQ) in $T$:
  \begin{align*}
    \frac{f _{\vartheta _1}(x)}{f _{\vartheta _0}(x)}
    &=\exp \big([\underbrace{Q (\vartheta _1)-Q(\vartheta _0}_{\geq 0\text{ für }\vartheta _0<\vartheta _1})]T(x)\big)\underbrace{\exp \left(D(\vartheta _1)-D(\vartheta _2)\right)}_{> 0 } \\
    &=H _{\vartheta _0,\vartheta _1}(T(x))
  \end{align*}
  (b)\\
  $X_1,X_2,...,X_n \overset{iid}\sim U[0,\vartheta ]$, $\vartheta _0<\vartheta _1$, $\vec x$ mit $f _{\vartheta _0}(\vec x)+f _{\vartheta _1}(\vec x)>0$. Dann gilt 
  \begin{align*}
    \frac{f _{\vartheta _1}(\vec x)}{f _{\vartheta _0}(\vec x)}
    &=\frac{\left(\frac{1}{\vartheta _1}\right)^n1(X _{(n)}\leq \vartheta _1)}{\left(\frac{1}{\vartheta _0}\right)^n1(X _{(n)}\leq \vartheta _0)}\\
    &=\begin{cases}
      \left(\frac{\vartheta _0}{\vartheta _1}\right)^n &X _{(n)}\in [0,\vartheta _0]\\
      \infty &X _{(n)}\in (\vartheta _0,\vartheta _1]
    \end{cases}\\
    &=H _{\vartheta _0,\vartheta _1}(X _{(n)})
  \end{align*}
  streng monoton wachsend \\
  $\Rightarrow T(x)$ hat monoton wachsenden DQ (Dichte-Quotienten) in $T(x)=X _{(n)}$ \\
  (c)\\
  \underline{Cauchy-Verteilung}
  \begin{align*}
    f _{\vartheta }(x)=\frac{1}{\pi (1+(x-\vartheta )^2)}\quad \vartheta \in \mathbb{R},x \in \mathbb{R}
  \end{align*}
  \begin{align*}
    \frac{f _{\vartheta _1}(x)}{f _{\vartheta _0}(x)}=\frac{1+(x-\vartheta _0)^2}{1+(x-\vartheta _1)^2}\text{ kein isotoner DQ}
  \end{align*}
\end{bei}
\begin{theo}{10.4}{}
  Betrachte $H_0:\vartheta \leq \vartheta _0$, $H_1:\vartheta >\vartheta _0$, Zufallsvariable $X:\Omega \to \mathcal{X}$ mit Dichte $f _{\vartheta }$, $\vartheta \in \Uptheta \subseteq \mathbb{R}$. \\
  Angenommen $\{f _{\vartheta }:\vartheta \in \Uptheta\}$ hat einen monotonen Dichtequotienten in $T:\mathcal{X}\to \mathbb{R}$, dann gilt \\
  (a) \\
  Jeder Test der Form (mit noch zu bestimmenden $t_0$)
  \begin{align*}
    \varphi (x)=\begin{cases}
      1 &T(x)>t_0\\
      \gamma & T(x)=t_0\\
      0&T(x)<t_0
    \end{cases}
  \end{align*}
  hat eine monoton wachsende Gütefunktion $\beta _{\varphi }(\vartheta )$. \\
  $\varphi $ ist UMP Test zum Niveau $\alpha =E _{\vartheta _0}(\varphi (x))$ (falls $\alpha >0$) 
  für die Hypothesen $H_0:\vartheta \leq \vartheta _0$, $H_1:\vartheta >\vartheta _0$. \\
  (b)\\
  Für jedes $\alpha \in (0,1]$ und jedes $\vartheta _0 \in \Uptheta$ existiert ein $t_0 \in [-\infty ,\infty ]$ und $\gamma \in [0,1]$, sodass der Test aus Teilaussage (a) ein UMP Test zum Niveau $\alpha $ für obige Hypothesen ist.
\end{theo}
\begin{bew}[]
  (a) Zunächst Monotonie der Gütefunktion. Betrachte $\vartheta _1<\vartheta _2 \in \Uptheta$, $\alpha ':=E _{\vartheta _1}(\varphi (x))$. \\
  Zu zeigen: $\beta _{\varphi }(\vartheta _1)\leq \beta _{\varphi }(\vartheta _2)$. \\
  1.) $\alpha '=0$: $\beta _{\varphi }(\vartheta _1)=0 \leq \beta _{\varphi }(\vartheta _2)\geq 0\checkmark$  \\
  2.) $\alpha '>0$: Nach NP Lemma existiert ein bester Test für $H_0:\vartheta =\vartheta _1$, $H_2:\vartheta =\vartheta _2$ zum Niveau $\alpha '=\beta _{\varphi }(\vartheta _1)$ mit
  \begin{align*}
    \varphi (x)=\begin{cases}
      1 &\frac{f _{\vartheta _2(x)}}{f _{\vartheta _1}(x)}>k\\
      \gamma (x)& \frac{f_{ \vartheta _2(x)}}{f _{\vartheta _1}(x)}=k\quad 0 \leq k< \infty \quad \left(\frac{f _{\vartheta _2}(x)}{f _{\vartheta _1}(x)}=H _{\vartheta _1,\vartheta _2}(T(x))\text{ mon. wachsend}\right)\\
      0 &\frac{f_{ \vartheta _2(x)}}{f _{\vartheta _1}(x)}<k
    \end{cases}
  \end{align*}
  $\Rightarrow $ Der Test aus dem Theorem und $\varphi $ haben die gleiche Form falls $\alpha '>0$. \\
  $\Rightarrow \beta _{\varphi }(\vartheta _2)\geq \beta _{\varphi' }(\vartheta _2)$ $\forall\;\varphi ' \in \Phi$ mit $\beta _{\varphi '}(\vartheta _1)\leq \alpha'$ \\
  Für $\varphi '=\alpha' $ gilt $\beta _{\varphi }(\vartheta _2)\geq \beta _{\varphi '}(\vartheta _2)=\alpha '\overset{\text{Def.}}=\beta _{\varphi }(\vartheta _1)$ d.h. $\beta _{\varphi }$ monoton wachsend. \\
  Bleibt zu zeigen, dass $\varphi $ UMP Test ist. Betrachte dazu beliebige $\vartheta _2>\vartheta _1=:\vartheta _0$ mit $\alpha =E _{\vartheta _0}(\varphi (x))>0$\\
  $\Rightarrow \varphi $ ist bester Test für $H_0:\vartheta = \vartheta _0$, $H_1:\vartheta =\vartheta _2\;\forall\;\vartheta _2>\vartheta _0$ $(*)$ und $\beta _{\varphi }(\vartheta )\leq \beta _{\varphi }(\vartheta _0)$ $\forall\;\vartheta \leq \vartheta _0$ da $\beta _{\varphi }$ monoton wachsend  \\
  $\Rightarrow \varphi $ hat Niveau $\alpha $ für  $H_0:\vartheta \leq \vartheta _0$, $H_1:\vartheta >\vartheta _0$ \\
  $\overset{(*)}\Rightarrow \beta _{\varphi }(\vartheta _2)\geq \beta _{\varphi' }(\vartheta _2)$ $\forall\;\vartheta _2>\vartheta _0$ $\forall\;\varphi ' \in \Phi$ mit $\beta _{\varphi' }(\vartheta _0)\leq \alpha   $ also auch $\forall\;\varphi '$ mit $\beta _{\varphi' }(\vartheta )\leq \alpha $ $\forall\;\vartheta \leq \vartheta _0$   \\
  $\Rightarrow \varphi $ UMP für $H_0:\vartheta \leq \vartheta _0$, $H_1:\vartheta >\vartheta _0$ \\\\
  (b) Für $\alpha \in (0,1]$, $\vartheta _0 \in \Uptheta$, sei 
  \begin{align*} 
   \varphi (x)=\begin{cases}
    1 &T(x)>t_0\\
    \gamma &T(x)=t_0 \\
    0 &T(x)<t_0
   \end{cases}
  \end{align*}
  $t_0:=\inf \left\{t:P _{\vartheta _0}(T(x)>t)\leq \alpha \right\}$ und $\gamma =\begin{cases}
    \frac{\alpha -P _{\vartheta _0}(T(X)>t_0)}{P _{\vartheta _0}(T(x)=t_0)} &P _{\vartheta _0}(T(X)=t_0)>0\\
  0 & \text{sonst }(P=0)
  \end{cases}$ \\
  Der Test hat die Form aus Teilaussage (a). \\
  \underline{1. Fall}: $P(T(X)=t_0)>0$, dann gilt
  \begin{align*}
    E _{\vartheta_0 }(\varphi(x))=P _{\vartheta _0}(T(x)>t_0)+\gamma P _{\vartheta _0}(T(x)=t_0)\overset{\text{Def.}}{\underset{\gamma }{=}}\alpha 
  \end{align*}
  \underline{2. Fall}: $P(T(X)=t_0)=0$ \\
  $\Rightarrow $ Verteilungsfunktion von $T$ ist stetig in $t_0$\\
  $\Rightarrow P _{\vartheta _0}(T(x)>t_0)=\alpha $ und $\gamma =0$   \\
  $\Rightarrow E _{\vartheta _0}(\varphi (x))=\alpha $ $\square$  
\end{bew}
\begin{bem}[10.5]
  Analog: UMP Test $H_0:\vartheta \geq \vartheta _0$, $H_1:\vartheta <\vartheta _0$ (Ablehnen von $H_0$ falls $T(X)<t_0$)  \\
  Diese Tests minimieren die Fehlerwahrscheinlichkeit 1. und 2. Art.\\
  Vgl. Binomialtest: Konstruktionsvorschrift für $\gamma $ in 10.4 (b) $\leadsto$ UMP
  \begin{center}
    \begin{tikzpicture}
\begin{axis}[
  width = 7cm,
  height = 7cm,
title = $H_1:\vartheta >\vartheta _0 $,
xmin=0,
ymin=0,
xmax = 1,
ymax = 1.1,
samples = 500,
legend pos=outer north east,
axis lines = box,
xlabel = $\vartheta $,
ylabel = $\beta _{\varphi }(\vartheta )$,
ylabel style = {rotate =-90},
variable = x,
trig format plots = rad,
xtick = \empty,
ytick = \empty,
extra x ticks = {0.305},
extra x tick labels = {$\vartheta _0$},
extra y ticks = {0.263, 1},
extra y tick labels = {$\alpha $,$1$}
]
\addplot[black] {1/(1+2.78^(-5*(x-0.5)))-0.01}; 
\addplot[black] {0.94/(1+2.78^(-13*(x-0.4)))+0.05}; 
\addplot[black, dotted] {1}; 
\node[] (source2) at (axis cs: 0.2,.75) {UMP};
    \node (destination2) at (axis cs:0.4,0.52){};
       \draw[thick,->](source2)--(destination2);
\end{axis}
\end{tikzpicture}\qquad\begin{tikzpicture}
\begin{axis}[
  height = 7cm,
  width = 7cm,
title = $H_1:\vartheta <\vartheta _0 $,
xmin=0,
ymin=0,
xmax = 1,
ymax = 1.1,
samples = 500,
legend pos=outer north east,
axis lines = box,
xlabel = $\vartheta $,
ylabel = $\beta _{\varphi }(\vartheta )$,
ylabel style = {rotate =-90},
variable = x,
trig format plots = rad,
xtick = \empty,
ytick = \empty,
extra x ticks = {0.353},
extra x tick labels = {$\vartheta _0$},
extra y ticks = {0.666, 1},
extra y tick labels = {$\alpha $,$1$}
]
\addplot[black] {1/(1+2.78^(-5*(-x+0.5)))-0.01}; 
\addplot[black] {0.94/(1+2.78^(-13*(-x+0.4)))+0.05}; 
\addplot[black, dotted] {1}; 
\node[] (source2) at (axis cs: 0.2,.3) {UMP};
    \node (destination2) at (axis cs:0.4,0.52){};
       \draw[thick,->](source2)--(destination2);
\end{axis}
\end{tikzpicture}
  \end{center}
\end{bem}
\begin{bei}[10.6 Einseitiger Gauß-Test]
  $H_0:\mu \leq \mu _0$, $H_1:\mu >\mu _0$, $X_1,X_2,...,X_n $ iid $N(\mu ,\sigma ^2)$ mit $\sigma ^2$ \underline{bekannt} (sonst t-Test)\\
  Dann gilt 
  \begin{align*}
    \frac{f _{\mu _1}(x)}{f _{\mu _0}(x)}
    &=\frac{\exp \left(-\sum_{i=1}^{n}{\frac{(X_i-\mu _1)^2}{2 \sigma ^2}}\right)}{\exp \left(-\sum_{i=1}^{n}{\frac{(X_i-\mu _0)^2}{2 \sigma ^2}}\right)}\\
    &=\exp \left(\frac{1}{2 \sigma ^2}\sum_{i=1}^{n}{-\left[\cancel{X_i^2}+\mu _1^2-2 \mu _1X_i-\cancel{X_i^2}-\mu _0^2+2 \mu _0X_i\right]}\right)\\
    &=\exp \bigg(\frac{1}{ \sigma ^2}\underbrace{\sum_{i=1}^{n}{X_i}}_{=T(X)}(\mu _1-\mu _0)\bigg)\exp \left(\frac{n}{2 \sigma ^2}(\mu _0^2-\mu _1^2)\right) \\
    &=H _{\mu _0,\mu _1}(T(x))
  \end{align*}
  $\Rightarrow  T(X)$ isotoner Dichte-Quotient (monoton wachsend für $\mu _1-\mu _0>0$)\\
  $T(X)\sim N \left(n  \mu ,n  \sigma ^2\right)$  
  \begin{align*}
    P _{\mu }(T(x)=t_0)=0 \Rightarrow \gamma =0
  \end{align*}
  \begin{align*}
    \varphi (x)=1(T(x)>t_0)\text{ mit }t_0 \text{ sodass }E _{\mu _0}(\varphi (x))=\alpha :
  \end{align*}
  \begin{align*}
    P _{\mu _0}(T(x)>t_0)
    &=P _{\mu _0}\bigg(\underbrace{\frac{T(x)-n\mu _0}{\sqrt{n \sigma ^2}}}_{\sim N(0,1)}>\frac{t_0-n \mu _0}{\sqrt{n \sigma ^2}}\bigg) \\
    &=1-\Phi \underbrace{\left(\frac{t_0-n \mu _0}{\sqrt{n \sigma ^2}}\right)}_{=U _{1-\alpha }=\Phi ^{-1}(1-\alpha )}\overset{!}=\alpha 
  \end{align*}
  Auflösen nach $t_0$ (Quantil in Tabelle nachgucken z.B. $U _{0.95}=1.645$) 
\end{bei}
\begin{bem}[10.7]
  (a)\\
  $H_0:\vartheta \notin (\vartheta _1,\vartheta _2)$, $H_1:\vartheta \in (\vartheta _1,\vartheta _2)$  \\
  UMP Test existiert in ein-parametrigen Exponentialfamilien mit streng isotonen Dichtequotienten (siehe Lehmann) \\\\
  (b)\\
  $H_0:\vartheta \in [\vartheta _1,\vartheta _2]$, $H_1:\vartheta \notin [\vartheta _1,\vartheta _2]$ bzw. $\vartheta =\vartheta _0$, $\vartheta \neq \vartheta _0$    \\
  UMP Test existiert im Allgemeinen nicht, weitere Einschränkung nötig (siehe 11.2)\\
  \begin{center}
    \begin{tikzpicture}
\begin{axis}[
xmin=0,
ymin=-0.05,
xmax = 1,
ymax = 1.1,
samples = 500,
legend pos=outer north east,
axis lines = box,
xlabel = $\vartheta $,
ylabel = $\beta _{\varphi }(\vartheta )$,
ylabel style = {rotate =-90},
variable = x,
trig format plots = rad,
xtick = \empty,
ytick = \empty,
extra x ticks = {0.5},
extra x tick labels = {$\vartheta _0$},
extra y ticks = {0.1, 1},
extra y tick labels = {$\alpha $,$1$}
]
\addplot[black, dotted, thick] {1/(1+2.78^(-10*(x-0.72)))}; 
\addplot[black] {-1/(0.3*sqrt(10))*2.78^(-(x-0.5)^2/(2*0.3^2))+1.15}; 
\addplot[black, dotted] {1}; 
\node[] (source2) at (axis cs: 0.8,.1) {zweiseitiger Test};
    \node (destination2) at (axis cs:0.67,0.26){};
       \draw[thick,->](source2)--(destination2);
\node[] (source21) at (axis cs:0.8,0.02) {$H_1:\vartheta \neq \vartheta _0 $};

\node[] (source3) at (axis cs: 0.45,.68) {einseitiger Test};
    \node (destination3) at (axis cs:0.65,0.32){};
\node[] (source31) at (axis cs:0.45,0.6) {$H_1:\vartheta > \vartheta _0 $};
       \draw[thick,->](source31)--(destination3);
\end{axis}
\end{tikzpicture}
  \end{center}
\end{bem}
\chapter{Unverfälschte Tests}
Für zweiseitige Tests wie in Bemerkung 10.7(b) ist eine weitere Einschränkung nötig:
\begin{defi}{11.1}{}
  Ein Test $\varphi \in \Phi _{\alpha }$ für $H_0:\vartheta \in \Uptheta_0$, $H_1:\vartheta \in \Uptheta_1$ heißt \underline{unverfälscht} zum Niveau $\alpha $ (unbiased), falls
  \begin{align*}
    \beta _{\varphi }(\vartheta )\geq \alpha \quad \forall\;\vartheta \in \Uptheta_1
  \end{align*}
  $\Phi _{\alpha \alpha }$ bezeichne die Menge dieser Tests. \\
  Der Test $\varphi _0 \in \Phi _{\alpha \alpha }$ heißt gleichmäßig bester unverfälschter Test (UMPU - UMP Unbiased), falls
  \begin{align*}
    \beta _{\varphi _0}(\vartheta )\geq \beta _{\varphi }(\vartheta)\quad \forall\;\vartheta \in \Uptheta_1 \forall\;\varphi \in \Phi _{\alpha \alpha }
  \end{align*}
\end{defi}
\begin{theo}{11.2}{}
  Betrachte ein-parametrige Exponentialfamilie $\{f _{\vartheta }:\vartheta \in \Uptheta\} $ mit streng isotonen Dichte-Quotienten $T$. Sei $\alpha \in (0,1)$, $\vartheta _0,\vartheta_1 ,\vartheta _2 \in \Uptheta$, $\vartheta _1<\vartheta _2$. \\
  (i)\\
  Es existiert ein UMPU Test $\varphi \in \Phi _{\alpha \alpha }$ für $H_0:\vartheta \in [\vartheta _1,\vartheta _2]$, $H_1:\vartheta \notin [\vartheta _1,\vartheta _2]$ mit ($t_1,t_2$ noch zu bestimmen)
  \begin{align*}
    \varphi (x)=\begin{cases}
      1 &T(x)\notin  [t_1,t_2]\\
      \gamma _i&T(x)=t_1 \text{ oder }T(x)=t_2 \\
      0&\text{sonst}
    \end{cases}
  \end{align*}
  mit $\gamma _i,t_i$, sodass $\beta _{\varphi }(\vartheta _1)=\beta _{\varphi }(\vartheta _2)=\alpha $   \\\\
  (ii)\\ 
  Für $H_0:\vartheta =\vartheta _0$, $H_1:\vartheta \neq \vartheta _0$ existiert ein Test $\varphi $ wie in Teilaussage (i) der die folgenden zwei Bedingungen erfüllt: \\
  $\beta _{\varphi }(\vartheta _0)=\alpha $ und $E _{\vartheta _0}(\varphi (x)\cdot T(x))=\underbrace{E _{\vartheta _0}(\varphi(x) )}_{=\alpha }E _{\vartheta _0}(T(x))$  
\end{theo}
\begin{bew}[]
  Siehe Lehmann/Romano Seite 111
\end{bew}
\begin{bem}[11.3]
  Die Bedingungen aus 11.2(ii) bedeutet, dass die Gütefunktion die Steigung Null hat.
\end{bem}
\begin{bew}[]
  Betrachte 
  \begin{align*}
    f _{\vartheta }(x)
    &=\exp(Q(\vartheta )T(x)+S(x)+D(\vartheta ))\\
    &=\exp(Q(\vartheta )T(x)+S(x))\exp(D(\vartheta ))
  \end{align*}
  mit 
  \begin{align*}
    \exp(D(\vartheta ))=\frac{1}{\int{\exp(Q(\vartheta )T(x)+S(x))}dx}\bigg(\Rightarrow \int{f _{\vartheta }(x)dx}=1\bigg)
  \end{align*}
  Sei $Q$ streng monoton wachsend und differenzierbar. Dann gilt 
  \begin{align*}
    \beta _{\varphi }(\vartheta )
    &=\int{\varphi (x)f _{\vartheta }(x)dx}\\
    &=\frac{\int{\varphi (x)\exp(Q(\vartheta )T(x)+S(x))dx}}{v(\vartheta )}
  \end{align*}
  mit $v(\vartheta ):=\int{\exp(Q(\vartheta )T(x)+S(x))dx}$ 
  \begin{align*}
    \frac{\partial }{\partial \vartheta }\beta _{\varphi }(\vartheta )
    &=\frac{\int{\varphi (x)Q'(\vartheta )T(x)\exp(Q(\vartheta )T(x)+S(x))dx \cdot v(\vartheta )}}{v(\vartheta )^2}\\
    &-\frac{\int{\varphi (x)\exp(Q(\vartheta )T(x)+S(x))dx}}{v(\vartheta) }\cdot \frac{\int{Q'(\vartheta )T(x)\exp(Q(\vartheta )T(x)+S(x))dx}}{v(\vartheta )}\\
    &=\underbrace{Q'(\vartheta )}_{>0}E _{\vartheta }(\varphi (x)T(x))-\underbrace{Q'(\vartheta )}_{>0}\underbrace{E _{\vartheta }(\varphi (x))}_{\overset{\vartheta =\vartheta _0}=\alpha }E _{\vartheta }(T(x))\\
    &\overset{\vartheta =\vartheta _0}=Q'(\vartheta _0)[E _{\vartheta _0}(\varphi (x)T(x))-\alpha E _{\vartheta _0}(T(x))]\overset{\text{Bed. }2}=0
  \end{align*}
  \begin{align*}
    \Rightarrow \beta _{\varphi }'(\vartheta _0)=0
  \end{align*}
\end{bew}
\begin{bei}[11.4]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$, $\sigma ^2$ bekannt \\
  (a) \\
  \underline{Gaußtest auf relevanten Unterschied}\\
  $H_0:\mu \in [-\varepsilon ,\varepsilon ]$, $H_1:\mu \notin [-\varepsilon ,\varepsilon ]$ \\
  In Theorem 10.6 gezeigt: strikt isotoner DQ in $T(x)=\sum_{i=1}^{n}{X_i}$ \\
  Theorem 11.2: $\varphi (x)=1\{T(x)\notin [t_1,t_2]\}\in \Phi _{\alpha \alpha }$  UMPU ($T$ stetige Zufallsvariable $\Rightarrow \gamma =0$)\\
  Es gilt 
  \begin{align*}
    \beta _{\varphi }(\mu  )
    &=1-P _{\mu } \left(t_1 < \sum_{}^{}{X_i}< t_2\right)\\
    &=1-P _{\mu }\bigg(\frac{t_1-n \mu }{\sqrt{n \sigma ^2}}<\underbrace{\frac{\sum_{}^{}{X_i}-n \mu }{\sqrt{n \sigma ^2}}}_{\sim N(0,1)}<\frac{t_2- n \mu }{\sqrt{n \sigma ^2}}\bigg)\\
    &=1- \Phi \left(\frac{t_2-n \mu }{\sqrt{n \sigma ^2}}\right)+\Phi \left(\frac{t_1-n \mu }{\sqrt{n \sigma ^2}}\right)\overset{!}=\alpha \text{ für }\mu =\varepsilon ,\mu =-\varepsilon 
  \end{align*}
  Wähle $0<t_1=-t_2<0$ (Symmetrie)\\
  Für $\mu =\varepsilon $ und $\mu =-\varepsilon $ erhält man 
  \begin{align*}
    \beta _{\varphi }(\mu )\bigg|_{\mu =\pm \varepsilon }^{}=1-\underbrace{\Phi\bigg(\frac{t_2-n \varepsilon  }{\sqrt{n \sigma ^2}}\bigg)}_{\Phi ^{-1}(1-\alpha /2)}+\underbrace{\Phi\bigg(\frac{-t_2-n \varepsilon  }{\sqrt{n \sigma ^2}}\bigg)}_{\Phi ^{-1}(\alpha /2)}\overset{!}=\alpha 
  \end{align*}
  [$\Phi(x)=1-\Phi(-x)$]\\
  Kann eindeutig nach $t_2$ aufgelöst werden. \\\\
  (b) \\
  \underline{Zweiseitiger Gaußtest}\\
  $H_0:\mu =\mu _0=0$, $H_1:\mu \neq 0$ \\
  $\varphi (x)=1\{\sum_{}^{}{X_i}\notin [t_1,t_2]\}$ mit $t_1,t_2$ sodass
  \begin{align*}
    \alpha =\beta _{\varphi }(\mu _0)=\beta _{\varphi }(0)=1-\Phi\bigg(\frac{t_2-n \cdot 0}{\sqrt{n \sigma ^2}}\bigg)+\Phi \bigg(\frac{t_1-n \cdot 0}{\sqrt{n \sigma ^2}}\bigg)
  \end{align*}
  \begin{align*}
    0=\beta _{\varphi }'(0)=\frac{d}{d \mu }\beta  _{\varphi }(\mu )\bigg|_{\mu =0}^{}
    &=-\Phi'\bigg(\frac{t_2}{\sqrt{n \sigma ^2}}\bigg)\bigg(-\frac{n}{\sqrt{n \sigma ^2}}\bigg)+\Phi'\bigg(\frac{t_1}{\sqrt{n \sigma ^2}}\bigg)\bigg(-\frac{n}{\sqrt{n \sigma ^2}}\bigg)\\
    &=\sqrt{\frac{n}{\sigma ^2}}\bigg(\Phi'\bigg(\frac{t_2}{\sqrt{n \sigma ^2}}\bigg)-\Phi'\bigg(\frac{t_1}{\sqrt{n \sigma ^2}}\bigg)\bigg)=0 \text{ für }t_2=-t_1
  \end{align*}
  ($\Phi'=\varphi $ Dichte von $N(0,1)$-Verteilung)\\
  Mit $t_2=-t_1=\sqrt{n \sigma ^2}\underbrace{U _{1-\alpha /2}}_{\Phi ^{-1}(1-\alpha /2)}$ gilt auch
  \begin{align*}
    \beta _{\varphi }(0)
    &=1-\Phi\bigg(\frac{t_2}{\sqrt{n \sigma ^2}}\bigg)+\Phi\bigg(\frac{t_1}{\sqrt{n \sigma ^2}}\bigg)=1-\Phi(U _{1-\alpha /2})+\Phi(U _{\alpha /2})=1-(1 -\alpha /2)+\alpha /2=\alpha 
  \end{align*}
  \begin{align*}
    \varphi (x)=1\left\{\bigg|\sum_{}^{}{X_i}\bigg|>\sqrt{n \sigma ^2}U _{1-\alpha /2}\right\}=1 \left\{|\bar{X}|>\frac{\sigma }{\sqrt{n}}U _{1-\alpha /2}\right\}
  \end{align*}
  (bzw. äquivalent $\left|\frac{\sum_{}^{}{X_i}-0}{\sqrt{n \sigma ^2}}\right|>U _{1-\alpha /2}$ )\\\\
  \underline{Allgemeiner}: $H_0:\mu =\mu _0$, $H_1:\mu  \neq \mu _0$ 
  \begin{align*}
    \varphi (x)=1 \left\{|\bar{X}-\mu _0|>\frac{\sigma }{\sqrt{n}}U _{1-\alpha /2}\right\}
  \end{align*}
Ist $\sigma ^2$ \underline{un}bekannt ergibt sich mit $\hat{S}^2 \overset{P}\rightarrow \sigma ^2$ der \underline{zwei-seitige t-Test}:
\begin{align*}
  \varphi (x)=1 \bigg\{|\bar{X}-\mu _0|>\sqrt{\frac{\hat{S}^2}{n}}{t _{n-1,1-\alpha /2}}\bigg\}
\end{align*}
(c) \\
$X_1,X_2,...,X_n $ iid $N(0,\sigma ^2)$, $H_0:\sigma =\sigma _0$, $H_1:\sigma \neq \sigma _0$. \\
Bekannt: $\sum_{}^{}{X_i^2}$ suffizient. Die Familie hat strikt isotonen Dichtequotienten in $\sum_{}^{}{X_i^2}$ denn (Definition 10.2) $\forall\;\sigma _0,\sigma _1 \in \Uptheta$ mit $\sigma _0<\sigma _1$ gilt 
\begin{align*}
  \frac{f _{\sigma _1}(x)}{f _{\sigma _0}(x)}
  &=\frac{\sigma _0}{\sigma _1}\frac{\exp\big(-\frac{\sum_{}^{}{X_i^2}}{2 \sigma _1^2}\big)}{\exp\big(-\frac{\sum_{}^{}{X_i^2}}{2 \sigma _0^2}\big)}=\underbrace{\frac{\sigma _0}{\sigma _1}}_{>0}\exp \bigg(\frac{1}{2}\sum_{}^{}{X_i^2}\bigg(\underbrace{\frac{1}{\sigma _0^2}-\frac{1}{\sigma _1^2}}_{>0}\bigg)\bigg)
\end{align*}
Nach Theorem 11.2 gilt 
\begin{align*}
  \varphi (x)
  &=1 \{\sum_{}^{}{X_i^2}\notin (\tilde{t}_1,\tilde{t}_2)\}
  =1 \bigg\{\underbrace{\frac{\sum_{}^{}{X_i^2}}{\sigma _0^2}}_{T(x)\overset{H_0}\sim\chi_n^2}\notin \bigg(\underbrace{\frac{\tilde{t}_1}{\sigma _0^2},\frac{\tilde{t}_2}{\sigma _0^2}}_{t_1,t_2}\bigg)\bigg\}\in \Phi _{\alpha \alpha }
\end{align*}
1. Bedingung
\begin{align*}
  \beta _{\varphi }(\sigma _0^2)=1-P _{\sigma _0}\bigg(t_1<\frac{\sum_{}^{}{X_i^2}}{\sigma _0^2}<t_2\bigg)\overset{!}=\alpha 
\end{align*}
\begin{align*}
  \Rightarrow \int_{t_1}^{t_2}{f_n(x)}\overset{!}=1-\alpha  
\end{align*}
mit $f_n$ Dichte der $\chi_n^2$-Verteilung \\
2. Bedingung 
\begin{align*}
 E _{\sigma_0 }(\varphi (x)T(x))
 &=\alpha E _{\sigma _0}(T(x))=\alpha n  \\
 &=\int{1 _{(t_1,t_2)^c}(x)xf_n(x)dx} \\
 &\overset{\text{Ü}}=n \int{1 _{(t_1,t_2)^c}f _{n+2}(x)dx}\\
 &\Leftrightarrow 1-\int_{t_1}^{t_2}{f _{n+2}(x)dx}=\alpha \Leftrightarrow 1-\alpha =\int_{t_1}^{t_2}{f _{n+2}(x)dx}
\end{align*}
Bestimme $t_1,t_2$ numerisch sodass beide Bedingungen gelten.
\end{bei}
\chapter{Likelihood-Quotienten Tests}
Allgemeines Prinzip zur Herleitung von Tests der Form $H_0:\vartheta \in \Uptheta_0$ vs. $\vartheta  \in \Uptheta _1$, $\Uptheta:=\Uptheta_1 \overset{.}\cup \Uptheta_0$, $\Uptheta_1 \neq \emptyset \neq \Uptheta_0$   
\begin{defi}{12.1}{}
Gegeben sei das statistiche Experiment/ Modell mit Dichten $\{f _{\vartheta }:\vartheta \in \Uptheta\}$.  \\
Wir nennen 
\begin{align*}
  \lambda (x):=\frac{\sup\limits _{\vartheta \in \Uptheta_0}f _{\vartheta }(X)}{\sup\limits _{\vartheta \in \Uptheta}f _{\vartheta }(X)}=\frac{\sup\limits _{\vartheta \in \Uptheta_0}L(\vartheta ,x)}{\sup\limits _{\vartheta \in \Uptheta}L(\vartheta ,x)} \text{ ('klein' spricht gegen $H_0$)}
\end{align*}
\underline{Likelihood-Quotient} (LQ) (LR - likelihood ratio). \\
Ein Test der Form 
\begin{align*}
  \varphi (x):=1 \{\lambda (X)<c\}+\gamma 1 \{\lambda (X)=c\}, \gamma,c \in [0,1]
\end{align*}
\underline{Likelihood-Quotienten Test} (LQT). \\
\underline{Erläuterung}:\\
Für $\vartheta \in \Uptheta_1$ gilt '$\lambda (x)$ klein' \\
Für $\vartheta \in \Uptheta_0$ gilt '$\lambda (x)\approx 1$' \\
Ist $f _{\vartheta }$ stetig, dann ist $\gamma =0$ \\
- Spezialfall: $\Uptheta_0=\{\vartheta _0\},\Uptheta_1=\{\vartheta _1\}$ Neyman-Pearson Test \\
- in ein-parametrige Exponentialfamilien mit isotonen Dichtequotienten sind LQT UMPT für $H_0:\vartheta \leq \vartheta _0$ vs. $H_1:\vartheta >\vartheta _0$ zum Niveau $\alpha =\sup _{\vartheta \in \Uptheta_0}\beta _{\varphi }(\vartheta )$   
\end{defi}
\begin{bei}[12.2]
  (a) \\
  $X_1,X_2,...,X_n $ iid $N(\mu ,\sigma ^2)$, $\nu :=\sigma ^2$, $\theta :=(\mu ,\sigma ^2)$   \\
  $H_0:\mu =\mu _0$ vs. $H_1:\mu \neq \mu _0$, $\Uptheta_0=\{\mu _0\}\times (0,\infty )$, $\Uptheta_1=\mathbb{R}\backslash\{\mu _0\}\times (0,\infty ) $
  \begin{align*}
    L(X,\theta )=(2 \pi \nu )^{-n/2}\exp \left(-\frac{1}{2}\nu ^{-1}\sum_{j=1}^{n}{(X_j-\mu )^2}\right)
  \end{align*}
  Dann gilt 
  \begin{align*}
    \sup _{\vartheta \in \Uptheta}L(\vartheta,x )=L(\hat{\vartheta},x )\quad \sup _{\vartheta \in \Uptheta_0}L(\vartheta ,x)=L(\tilde{\vartheta }_0,x)
  \end{align*}
  mit $\hat{\vartheta }$ ML Schätzer für $\vartheta =(\mu ,\sigma ^2)$, $\hat{\vartheta }=(\bar{X},\hat{\sigma }^2)$  \\
  und $\tilde{\vartheta}_0=(\mu _0,\tilde{\sigma }_0^2)$ ML Schätzer für $\sigma ^2$ bei bekanntem $\mu =\mu _0$, $\tilde{\sigma }_0^2=\frac{1}{n}\sum_{}^{}{(X_i-\mu _0)^2}$
  \begin{align*}
    \Rightarrow \lambda (X)
    &=\frac{L(\tilde{\vartheta }_0,x)}{L(\hat{\vartheta}_0 ,x)}=\left(\frac{\hat{\sigma }^2}{\tilde{\sigma }^2}\right)^{\frac{n}{2}}\exp \bigg(\underbrace{-\frac{1}{2 \tilde{\sigma }^2}\sum_{j=1}^{n}{(X_j-\mu _0)^2}+\frac{1}{2 \hat{\sigma }^2}\sum_{j=1}^{n}{(X_j-\bar{X}_n)^2}}_{-\frac{n}{2}+\frac{n}{2}=0}\bigg)\\
    &=\left(\frac{\sum_{j=1}^{n}{(X_j-\bar{X}_n)^2}}{\sum_{j=1}^{n}{(X_j-\mu _0)^2}}\right)^{n/2}\cdot 1
  \end{align*}
  Nebenrechnung 
  \begin{align*}
    \sum_{j=1}^{n}{(X_i-\mu _0)^2}
    &=\sum_{j=1}^{n}{((X_j-\bar{X}_n)+(\bar{X}_n-\mu _0))^2}\\
    &=\sum_{j=1}^{n}{(X_j-\bar{X})^2}+n(\bar{X}-\mu _0)^2+2 \sum_{j=1}^{n}{(X_j-\bar{X})(\bar{X}-\mu _0)}\\
    &=\sum_{j=1}^{n}{(X_j-\bar{X})^2}+n(\bar{X}-\mu _0)^2+2 n(\bar{X}-\mu _0)\underbrace{\sum_{j=1}^{n}{X_j-\bar{X}}}_{n \bar{X}-n \bar{X}=0}
  \end{align*}
  Nebenrechnung vorbei.
  \begin{align*}
    \lambda (x)&=\left(\frac{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}{\sum_{j=1}^{n}{(X_j-\bar{X})^2+n(\bar{X}-\mu _0)^2}}\right)\\
    &=\Bigg(\frac{1}{1+\underbrace{\frac{n(\bar{X}-\mu _0)^2}{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}}_{=:T^2(X _{(n)})}}\Bigg)^{\frac{n}{2}}
  \end{align*}
  (Sei jetzt $X _{(n)}=(X_1,...,X_n)$) streng monoton fallend in 
  \begin{align*}
    T(X _{(n)})=\frac{|\bar{X}-\mu _0|}{\sqrt{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}}\geq 0
  \end{align*}
  Die Tests
  \begin{align*}
    \varphi (x):=1_{(-\infty ,c)}(\lambda (X))\text{ und }\tilde{\varphi} (X):=1_{(\tilde{c},\infty )}(T(X))
  \end{align*}
  sind äquivalent. \\
  $T(X)>\tilde{c} \Leftrightarrow \sqrt{\frac{n}{n-1}}T(X)>\sqrt{\frac{n}{n-1}}\tilde{c}=\tilde{\tilde{c}}$, betr. also 
  \begin{align*}
    \tilde{\tilde{\varphi }}(X)=1 \bigg\{\bigg|\underbrace{\frac{\sqrt{n}(\bar{X}-\mu _0)^2}{\sqrt{\hat{S}_n^2}}}_{\overset{H_0}\sim t _{n-1}}\bigg|>\tilde{\tilde{c}}\bigg\}
  \end{align*}
  \begin{align*}
    E(\tilde{\tilde{\varphi }}(X))
    &=P(|\tilde{T}|>\tilde{\tilde{c}})=2-2F(\tilde{\tilde{c}})\overset{!}\leq \alpha 
  \end{align*}
  folgt mit Symmetrie und Stetigkeit
  \begin{align*}
    \leadsto\tilde{c}=t _{n-1,1-\frac{\alpha }{2}}
  \end{align*}
  Nachrechnung
  \begin{align*}
    |\tilde{T}|\leq \tilde{\tilde{c}}\Leftrightarrow -\tilde{\tilde{c}}\leq \tilde{T}\leq \tilde{\tilde{c}}
  \end{align*}
  \begin{align*}
    F(\tilde{\tilde{c}})-F(-\tilde{\tilde{c}})=F(\tilde{\tilde{c}})-(1-F(\tilde{\tilde{c}}))=2F(\tilde{\tilde{c}})-1
  \end{align*}
  Nachrechnung vorbei \\
  (b) \\
  Mit dem LQ Ansatz erhält man auch andere t-Tests aus (8.8):
  \begin{align*}
    H_0:\mu \begin{cases}
      \leq \mu _0 \\
      \geq \mu _0
    \end{cases}\text{ vs. }H_1:\mu \begin{cases}
      > \mu _0 &\\
      < \mu _0
    \end{cases},
  \end{align*}
  lehne $H_0$ ab, falls 
  \begin{align*}
    \frac{\sqrt{n}(\bar{X}-\mu )}{\hat{S}_n}\begin{cases}
      >t _{n-1,1-\alpha } &\\
      <t _{n-1,\alpha }
    \end{cases}
  \end{align*}
  (c) \\
  Der zweiseitige $\chi ^2$-Test aus (8.9) ist auch LRT, ebenso die einseitigen Versionen
  \begin{align*}
    H_0:\sigma ^2 \begin{cases}
      \leq  &\\
      \geq  &\\
      =
    \end{cases}\sigma _0^2\text{ vs. }H_1:\sigma ^2 \begin{cases}
      > &\\
      < &\\
      \neq 
    \end{cases}\sigma _0^2
  \end{align*}
  $H_0$ ablehnen, wenn
  \begin{align*}
    \frac{(n-1)\hat{S}_n^2}{\sigma _0^2}\begin{cases}
      > \chi _{n-1,1-\alpha }^2\\
      < \chi _{n-1,\alpha }^2 \\
      > \chi _{n-1,1-\frac{\alpha }{2}}^2 \text{ oder}< \chi _{n-1,\frac{\alpha }{2}}^2
    \end{cases}
  \end{align*}
\end{bei}
\begin{bei}[12.3 (Zu 12.2a asymptotisch äquivalenter Test)]
  \begin{align*}
    \lambda (X)
    &=\left(\frac{\sum_{j=1}^{n}{(X_j-\mu _0)^2}}{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}\right)^{-n/2}
    =\left(1+\frac{n(\bar{X}-\mu _0)^2}{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}\right)^{-n/2}=\bigg(1+\frac{n(\bar{X}-\mu _0)}{(n-1)\hat{S}^2}\bigg)^{-n/2}
  \end{align*}
  \begin{align*}
    \Rightarrow -2\ln(\lambda (X))
    &=n\ln \bigg(1+\frac{n(\bar{X}-\mu _0)^2}{\sum_{j=1}^{n}{(X_j-\bar{X})^2}}\bigg)
    =n \ln \left(1+\frac{\left(\frac{\sqrt{n}(\bar{X}-\mu )}{\sigma }\right)^2}{(n-1)\frac{\hat{S}_n^2}{\sigma ^2}}\right)
  \end{align*}
  (Siehe Slutsky Lemma) \\
  Es gilt $Z:=\left(\frac{\sqrt{n}(\bar{X}-\mu _0)}{\sigma }\right)\overset{H_0}\sim N(0,1)$ \\
  $\frac{\hat{S}_n^2}{\sigma ^2}\overset{P}\to 1$ (da Stichprobenvarianz konsistent), also haben $-2\ln(\lambda (X))$ und $T_n(X)=n\ln \left(1+\frac{Z^2}{n-1}\right)$ dieselbe Grenzverteilung  
  \begin{align*}
    T_n(X)\overset{D}\longrightarrow Z^2\sim \chi _{1}^2 \text{ weil }\exp(T_n(y))=\bigg(1+\frac{y^2}{n-1}\bigg)^n \longrightarrow \exp(y^2)\forall\;y \in \mathbb{R}
  \end{align*}
\end{bei}
\chapter{Konfidenzbereiche}
Bereiche/ Intervalle in denen ein Parameter $\vartheta $ mit großer Wahrscheinlichkeit liegt (mehr Info als bei einem Punktschätzer)
\begin{defi}{13.1}{}
  Sei $X\sim P _{\vartheta },\vartheta \in \Uptheta$. \\
  Eine Abbildung $S:\mathcal{X}\to \mathfrak{P}(\Uptheta)$ heißt \underline{Konfidenzbereich} für $\vartheta $ zum Niveau $1-\alpha $ ($\alpha \in (0,1)$), falls
  \begin{align*}
    P _{\vartheta }(\vartheta \in S(x) )=P _{\vartheta }(x \in \mathcal{X}:\vartheta \in S(x))\geq 1-\alpha\quad \forall\;\vartheta \in \Uptheta
  \end{align*}
  Für eine Realisation $x:=X(w)$ heißt $S(x)$ \underline{konkreter Konfidenzbereich} und weiter heißt 
  \begin{align*}
    \inf _{\vartheta \in \Uptheta}P(\vartheta \in S(x) )\text{ \underline{effektives Konfidenzniveau}}
  \end{align*}
  Ist $\Uptheta \subseteq \mathbb{R}$, $S(x)$ Intervall $\forall\;x \in \mathcal{X}$ dann nennt man $S(x)$ \underline{Konfidenzintervall}.
\end{defi}
\begin{bei}[13.2]
  $X_1,X_2,...,X_n \overset{iid}\sim N(\mu ,\sigma ^2)$ \\
  (a)\\
  Konfidenzintervall für $\vartheta =\mu $ (Varianz ebenfalls unbekannt). Ansatz:% (Varianz ebenfalls unbekannt), 
  \begin{align*}
    S(X):=[\underbrace{\bar{X}}_{\hat{\mu }}-\varepsilon _1,\bar{X}+\varepsilon _2]
  \end{align*}
  \begin{align*}
    P _{\mu }(\mu \in S )
    &=P(\bar{X}-\varepsilon_1 \leq \mu \leq \bar{X}+\varepsilon_2 )\\
    &=P _{\mu }(-\varepsilon_2 \leq \bar{X}\leq \varepsilon_1 )\\
    &=P _{\mu }\bigg( \underbrace{-\sqrt{\frac{n}{\hat{S}_n^2}}\varepsilon_2}_{a}\leq \underbrace{\frac{\sqrt{n}(\bar{X}-\mu )}{\sqrt{\hat{S}_n^2}}}_{\sim t _{n-1}}\leq \underbrace{\sqrt{\frac{n}{\hat{S}_n^2}}\varepsilon_1}_{b}  \bigg)\\
    &=F _{t _{n-1}}(b)-F _{t _{n-1}}(a)\overset{!}\geq 1-\alpha 
  \end{align*}
  Für $b=-a=t _{n-1,1-\frac{\alpha }{2}}$ (Symmetrie) (kürzestes KI)
  \begin{align*}
    \Rightarrow \varepsilon _1=b \cdot \frac{\hat{S}_n}{\sqrt{n}}=t _{n-1,1-\frac{\alpha }{2}}\frac{\hat{S}_n}{\sqrt{n}},\quad \varepsilon _2=-a \frac{\hat{S}_n}{\sqrt{n}}=t _{n-1,1-\frac{\alpha }{2}}\frac{\hat{S}_n}{\sqrt{n}}
  \end{align*}
  \begin{align*}
    \Rightarrow S(X)=\bigg[\bar{X}\mp \frac{\hat{S}_n}{\sqrt{n}}t _{n-1,1-\frac{\alpha }{2}}\bigg]
  \end{align*}
  (b)\\
  Konfidenzintervall für $\vartheta =\sigma ^2$. Ansatz: 
  \begin{align*}
    [c_1 \hat{S}_n^2,c_2 \hat{S}_n^2]
  \end{align*}
  \begin{align*}
    P _{\vartheta }(\sigma ^2 \in S(X))
    &=P _{\vartheta }(c_1 \hat{S}_n^2 \leq \sigma ^2 \leq c_2 \hat{S}_n^2)\\
    &=P _{\vartheta }\bigg(\frac{1}{c_1 \hat{S}_n^2}\geq \frac{1}{\sigma ^2}\geq \frac{1}{c_2 \hat{S}_n^2}\bigg)\\
    &=P _{\vartheta }\bigg(\frac{n-1}{c_2}\leq \underbrace{\frac{(n-1)\hat{S}_n^2}{\sigma ^2}}_{\sim \chi _{n-1}^2}\leq \frac{n-1}{c_1}\bigg)\overset{!}\geq 1-\alpha 
  \end{align*}
  Wähle z.B.
  \begin{align*}
    \frac{n-1}{c_1}=\chi _{n-1,1-\alpha /2}^2,\quad \frac{n-1}{c_2}=\chi _{n-1,\alpha /2}^2
  \end{align*}
  \begin{align*}
    \Rightarrow S(X)=\left[\frac{n-1 \hat{S}_n^2}{\chi _{n-1,1-\alpha /2}^2},\frac{(n-1)\hat{S}_n^2}{\chi _{n-1,\alpha /2}^2}\right]
  \end{align*}
  \underline{oder}
  \begin{align*}
    S(X)=\left[\frac{(n-1)\hat{S}_n^2}{a},\frac{(n-1)\hat{S}_n^2}{b}\right]
  \end{align*}
  mit $a,b  $ so gewählt, dass die intervallänge minimal ist und das Konfidenzniveau $1-\alpha  $.\\
  (c)\\
  $\vartheta =(\mu ,\sigma ^2)$ \\
  Man wählt im Allgemeinen Konfidenzellipsoide statt Quader $S_1(X)\times S_2(X)$ mit kleinerer Fläche.
\end{bei}
\begin{bem}[13.3]
  Betrachte $H_0:\vartheta =\vartheta _0$, $H_1:\vartheta \neq \vartheta _0$, $S(X)$ Konfidenzbereich für $\vartheta $ zum Niveau $1-\alpha $. \\
  Dann gilt 
  \begin{align*}
    \varphi (X)=\begin{cases}
      1 &\vartheta _0 \notin S(X)\\
      0&\vartheta _0 \in S(X)
    \end{cases}
  \end{align*}
  ist Niveau $\alpha $ Test, denn \\
  Fehler 1. Art:
  \begin{align*}
    P _{\vartheta _0}(\varphi (x)=1)
    &=1-\underbrace{P _{\vartheta _0}(\underbrace{\varphi (x)=0}_{\vartheta_0 \in S(X)})}_{\geq 1-\alpha }\leq 1-(1-\alpha )=\alpha 
  \end{align*}
  \underline{Bsp.} 13.2.a:
  \begin{align*}
    \mu _0 \notin S(X)&=\bigg(\bar{X}-\frac{\sqrt{\hat{S}_n^2}}{\sqrt{n}}t _{n-1,1-\alpha /2},\bar{X}+\frac{\sqrt{\hat{S}_n^2}}{\sqrt{n}}t _{n-1,1-\alpha /2}\bigg)\\
    \Leftrightarrow |\bar{X}-\mu _0|&\geq \frac{\sqrt{\hat{S}_n^2}}{\sqrt{n}}t _{n-1,1-\alpha /2}\text{ zweiseitiger t-Test}
  \end{align*}
\end{bem}
\begin{theo}{13.4}{}
  Sei $H_0:\vartheta =\vartheta _0$, $H_1:\vartheta \in \Uptheta_1(\vartheta _0)$ (z.B. $\Uptheta \backslash\{\vartheta _0\},(\vartheta _0,\infty ) $)  \\
  Für jedes $\vartheta _0 \in \Uptheta$ ($\Uptheta$ hier ganzer Bereich, nicht nur $\Uptheta_1(\vartheta _0)$) sei (mit $\mathcal{A}(\vartheta _0)$ Annahmebereich von $H_0$)
  \begin{align*}
    \varphi _0(X)=1-1\{X \in \mathcal{A}(\vartheta _0)\}=1\{X \notin \mathcal{A}_{\vartheta _0}\}
  \end{align*}
  \underline{UMP}-Test zum Niveau $\alpha \in (0,1)$. Dann gilt  
  \begin{align*}
    S(X)=\{\vartheta \in \Uptheta:X \in \mathcal{A}(\vartheta )\}
  \end{align*}
  ist Konfidenzbereich zum Niveau $1-\alpha $ mit minimaler Fehlerwahrscheinlichkeit 2. Art
  \begin{align*}
    P _{\vartheta }(\vartheta _0 \in S(X))\quad \forall\;\vartheta \in \Uptheta_1(\vartheta _0)
  \end{align*}
  unter allen Konfidenzbereichen zum Niveau $1-\alpha $. 
\end{theo}
\begin{bew}[]
  Sei $S^*$ Konfidenzbereich zum Niveau $1-\alpha $, $\mathcal{A}^*(\vartheta _0)=\{x \in \mathcal{X}:\vartheta _0 \in S^*(X)\}$   
  \begin{align*}
    \Rightarrow \varphi ^*(x)=1-1\{\underbrace{x \in \mathcal{A}^*(\vartheta _0)}_{\vartheta _0^* \in S^*(X)}\}
  \end{align*}
  ist Niveau $\alpha $ Test $H_0:\vartheta =\vartheta _0$ siehe 13.3. \\
  Da $\varphi _0$ UMP nach Voraussetzung folgt
  \begin{align*}
    \beta _{\varphi _0}(\vartheta )
    &\geq \beta _{\varphi ^*}(\vartheta )\quad \forall\;\vartheta \in \Uptheta_1(\vartheta _0) \\
    \Leftrightarrow P _{\vartheta }(X \in \mathcal{A}(\vartheta _0))&\leq P _{\vartheta }(X \in \mathcal{A}^*(\vartheta _0))\quad \forall\;\vartheta \in \Uptheta_1(\vartheta _0) \\
    \Leftrightarrow P _{\vartheta }(\vartheta _0 \in S(X))& \leq P _{\vartheta }(\vartheta _0 \in S^*(X))\quad \forall\;\vartheta \in \Uptheta_1(\vartheta _0) \;\square
  \end{align*}
\end{bew}
\begin{bei}[13.5 Exaktes Konfidenzintervall für Binomialverteilungen]
  Sei $X\sim$ Bin$(n,\vartheta )$ z.B. $X=\sum_{i=1}^{n}{X_i},\  X_i \overset{iid}\sim$ Bin$(1,\vartheta )$  \\
  \underline{Gesucht}: Konfidenzintervall $S(X)=(l(X),L(X))$ mit 
  \begin{align*}
    P _{\vartheta }(\vartheta \in S(X))\geq 1-\alpha \quad \forall\;\vartheta \in \Uptheta=[0,1]
  \end{align*}
  Bestimme zunächst 
  \begin{align*}
    \mathcal{A}(\vartheta )=\{x \in \{0,1,...,n\}:a(\vartheta )\leq x \leq A(\vartheta )\}
  \end{align*}
  Wähle z.B. 
  \begin{align*}
    a(\vartheta )&=\max \bigg\{k \in \{0,1,...,n\}:\sum_{j=0}^{k-1}{\binom{n}{j}\vartheta ^j(1-\vartheta )^{n-j}}\leq \alpha /2\bigg\}\\
    A(\vartheta )&=\min \bigg\{k \in \{0,1,...,n\}:\sum_{j=k+1}^{n}{\binom{n}{j}\vartheta ^j(1-\vartheta )^{n-j}}\leq \alpha /2\bigg\}
  \end{align*}
  \begin{center}
    \begin{tikzpicture}
  \begin{axis}[
    xtick = \empty,
    ytick = \empty,
    extra x ticks = {2,6},
    extra x tick labels = {$a$,$A$}
    %axis y line = none,
    %axis x line = middle
    ]
\addplot+ [black, mark = none,
  ycomb,
] coordinates {
  (0,0.3) (1,0.7) (2,1.6) (3,2.4) (4,3) (5,2.7) (6,1.8) (7,0.8) (8,0.4) 
} ;
\node (A) at (axis cs:0, 1.62) {};
\node (B) at (axis cs:2, 1.62) {};
\node (C) at (axis cs:6, 1.82) {};
\node (D) at (axis cs:8, 1.82) {};
\draw [decorate,decoration={brace,amplitude=5pt, raise = -1mm}]
(A.west) -- (B.east) node [black,midway, above] {$\sum(...)\leq \frac{\alpha }{2} $};

\draw [decorate,decoration={brace,amplitude=5pt, raise = -1mm}]
(C.west) -- (D.east) node [black,midway,above] {$\sum(...)\leq \frac{\alpha }{2} $};
\end{axis}
\end{tikzpicture}
  \end{center}
  $a(\vartheta ),A(\vartheta )$ monoton wachsend in $\vartheta $, $a(\vartheta )$ rechts-stetig, $A(\vartheta )$ links-stetig, also \\
  $a(\vartheta )\leq x \leq A(\vartheta ) \Leftrightarrow l(x)<\vartheta <L(x)$ mit \\
  $L(x)=\sup \{\vartheta :a(\vartheta )=x\}$, $L(x)$ löst
  \begin{align*}
    \sum_{j=0}^{x}{\binom{n}{j}\vartheta ^j(1-\vartheta )^{n-j}}=\frac{\alpha }{2}\text{ bzgl. }\vartheta 
  \end{align*}
  $l(x)=\inf \{\vartheta :A(\vartheta )=x\}$, $l(x)$ löst
  \begin{align*}
    \sum_{j=x}^{n}{\binom{n}{j}\vartheta ^j(1-\vartheta )^{n-j}}=\frac{\alpha }{2}\text{ bzgl. }\vartheta 
  \end{align*}
  Numerisch lösbar oder mit 'Pearson-Clopper' Schranken (Zusammenhang Bin- und F-Verteilung)
\end{bei}
\chapter{Stochastische Prozesse und Versicherungsmathematik}
\begin{defi}{14.1}{}
  Betrachte $(\Omega ,\mathcal{A},P)$ und $T \neq \emptyset $ Indexmenge.\\
  Eine Familie von Zufallsvariablen $\{X_t\}_{t \in T}$ auf $(\Omega ,\mathcal{A},P)$ heißt \underline{stochastischer Prozess}. \\
  Gilt $T \subseteq \mathbb{N}_0$, dann nennt man $\{X_t\}_{t \in T}$ \underline{Kette}.    
\end{defi}
\noindent \textbf{Motivation} (14.2 Versicherungsmathematisches Modell)\\
\underline{Annahme}: Versicherung bekommt von Kunden pro Zeiteinheit (z.B. Jahr) eine Prämie $\gamma $. \\
Sei $N(t)=$ \#\{Schadensfälle in $[0,t]$\} \\
$N(t)$ wird im Allgemeinen durch Poisson-Prozess modelliert.\\
Auch von Interesse:\\
\#\{Schadensfälle bis variablen Zeipunkt $t$\} %($t$ ZV)
(z.B. Zahlungsunfähigkeit) \\
$(Y_n)_{n \in \mathbb{N}}$ Höhe der Schadensfälle ($Y_1,Y_2,...,Y_n $ iid) \\
$(X_t)_{t \in T}$ Kapital der Versicherung zum Zeitpunkt $t$ (stochastischer Prozess)
\begin{align*}
  X(t)=a+\gamma t-\sum_{j=1}^{N(t)}{Y_j}\quad (t \geq 0)
\end{align*}
($a $ Startkapital)\\
\underline{Annahme}: Zahlungen an bzw. von Kunden erfolgen zu äquidistanten Zeitpunkten $t_k=\frac{k}{N}$, $k \in \mathbb{N}_0$, der Einfachheit halber sei $t_k=k$ (d.h. $N=1$) \\
\underline{Von Interesse/Ziel}: \\
Bestimmung von $P_a=P(\text{'rote Zahlen bei Startkapital $a$'})=P\bigg(\inf\limits _{k \in \mathbb{N}_0}X(k)<0\bigg)$ \\
Sei $X_k=X(k)$ $(=X(t_k))$, $\tau_a$ Zufallsvariable (zufälliger Zeitpunkt) mit $\tau_a=\inf\{k:X_k<0\}$ \\
Sei $\tau_a=\infty $ falls $X_k<0$ nie eintritt. \\
Dann gilt 
\begin{align*}
  P_a=P(\inf X(k)<0)=P(\tau_a< \infty )
\end{align*}
\begin{defi}{14.3}{}
  Ein stochastischer Prozess $N(.,t)$, $t \geq 0$ heißt \underline{Zählprozess}, falls \\
  \begin{align*}
    (i)&\text{ $N(w,t)\in \mathbb{N}_0$ $\forall\;w \in \Omega $ sowie $N(.,0)=0$ fast sicher}\\
    (ii)&\text{ Der Pfad $t\mapsto N(w,t)$ wächst monoton für jedes $w \in \Omega $}
  \end{align*}
  Ein Zählprozess heißt \underline{(homogener) Poisson-Prozess mit Intensität $\lambda >0$} wenn seine Zuwächse unabhängig und Poisson-verteilt sind, d.h. für beliebige $0 \leq t_1 <t_2 <...<t_n$ sind die Zufallsvariablen 
  \begin{align*}
    N(t _{j+1})-N(t_j), \quad j=1,...,n-1
  \end{align*}
  unabhängig und jeweils Poisson-verteilt mit Parameter $\lambda (t _{j+1}-t_j)$ 
\end{defi}
\begin{theo}{14.4}{}
  Betrachte $X_1,X_2,...,X_n \overset{iid}\sim$ Exp$(\lambda )$ mit Dichte $\lambda e^{-\lambda x},\lambda >0,x>0$ \\
  $S_n:=\sum_{i=1}^{n}{X_i}$ und den Zählprozess
  \begin{align*}
    N(t)=N(t,w)=\sup \{n \in \mathbb{N}_0:S_n(w)\leq t\}
  \end{align*} (mit rechts-seitig stetigen Pfaden). \\
  Sei $0 \leq t_1<t_2<...\leq t_n$ dann gilt:
  \begin{align*}
    N(t _{j+1})-N(t_j),\quad j=1,...,n-1
  \end{align*}
  sind unabhängig und Pois$(\lambda (t _{j+1}-t_j))$-verteilt.
\end{theo}
\begin{bew}[]
  Siehe Skript von Meister Satz 5.1 (Idee: Mit $S_n\sim \Gamma (\lambda ,n)$ und $P(X_1>t+h|X_1>h)=P(X_1>h)$ (Gedächtnislosigkeit der Exponentialverteilung) zeigt man 
  \begin{multline*}
    P(N(t_n)-N(t _{n-1})=k_n,N(t _{n-j})=k _{n-j}\forall\;j=1,...,n-1)\\=\frac{1}{k_n!}(\lambda (t _{n}-t _{n-1}))^{k_n}e^{-\lambda (t _n-t _{n-1})}\cdot P(N(t _{n-j})=k _{n-j}\forall\;j=1,...,n-1)\;\square
  \end{multline*}
\end{bew}
\noindent \underline{Heuristik zum Poisson-Prozess} 
\begin{center}
  \begin{tikzpicture}
  \begin{axis}[
    axis x line = middle,
    axis y line = none,
    xlabel = $t$,
    xmin = 0,
    xmax = 3.5,
    xtick = \empty,
    extra x ticks = {0,1,2,3,0.25,0.5,0.75,1.25,1.5,1.75,2.25,2.5,2.75},
    extra x tick labels = {0,1,2,3}
    ]
    \addplot[black]{0};
    \node (A) at (axis cs:1.05, 0.1) {};
    \node (B) at (axis cs:1.95, 0.1) {};
    \draw [decorate,decoration={brace,amplitude=5pt, raise = -1mm}]
    (A.west) -- (B.east) node [black,midway, above] {$n $ Teilintervalle};
    \node at (axis cs:1.5,0.32) {Zeitintervall,};
\end{axis}
\end{tikzpicture}
\end{center}
Betrachte unabhängige Bernoulli-Experimente, Ausgang $0/1$ in jedem Teilintervall.  \\
Angenommen wir erwarten $\lambda $ Erfolge pro Zeitintervall (z.B. $\lambda =2.2$ Tore pro Fußballspiel) \\
Dann gilt 
\begin{align*}
  p=P(\text{'$1$'})=\frac{\lambda }{n}
\end{align*}
sind die Teilintervalle sehr klein, dann gilt
\begin{align*}
  P(\text{'$2$ oder mehr Erfolge'})\approx 0
\end{align*}
Zeit bis zum 1. Erfolg $\approx \frac{1}{n} \cdot \underbrace{\text{\#\{Experimente bis zum 1. Erfolg\}}}_{=:G_n}$ mit $G_n\sim$ Geo$(p)$, $p=\frac{\lambda }{n}$ (diskrete Analogon zur Exponentialverteilung) und 
\begin{align*}
  \frac{G_n}{n}\overset{\text{D}}\to \text{Exponentialverteilung}
\end{align*}
d.h. Wartezeit ist Exponentialverteilt. \\
Betrachte $[0,t]$, $t$ fest, d.h. $\approx n \cdot t$ Experimente. \\
Dann gilt
\begin{align*}
  X_t=\text{\#\{Erfolge in $[0,t]$\}}\approx \text{ Bin}(nt,p)=\text{ Bin}\bigg(nt,\frac{\lambda }{n}\bigg)\overset{n \text{ groß}}\approx \text{Pois}(ntp)=\text{Pois}(t \lambda )
\end{align*}
$X_t$ ist der Poisson-Prozess. \\
Die Erfolge in disjunkten Intervallen $[0,t)$, $[t,t+s]$ sind unabhängig, da die Experimente unabhängig sind. 
\begin{defi}{14.5}{}
  Betrachte Kette $\{X_t\}_{t \in \mathbb{N}_0}$ auf $(\Omega ,\mathcal{A},P)$ \\
  (a)\\
  Eine Folge von $\{A_t\}_{t \in \mathbb{N}_0}$ von $\sigma $-Algebren über $\Omega $ heißt \underline{Filtration}, wenn 
  \begin{align*}
    \underset{}{\mathcal{A}_t \subseteq \mathcal{A}_s}_{} \subseteq \mathcal{A}\quad \forall\;t<s
  \end{align*}
  (b)\\
  $\{X_t\}_{t \in \mathbb{N}_0} $ heißt $\{\mathcal{A}_t\}_{t \in \mathbb{N}_0}$ \underline{adaptiert}, wenn 
  \begin{align*}
    X_t \text{ bzgl. } \mathcal{A}_t \text{ messbar ist für alle }t \in \mathbb{N}_0
  \end{align*}
  (c) \\
  $\{X_t\}_{t \in \mathbb{N}_0}$ heißt \underline{Martingal} bezüglich der Filtration $\{\mathcal{A}_t\}_{t \in \mathbb{N}_0}$ wenn (b) gilt und
  \begin{align*}
    (i)&\quad E|X_t|<\infty \quad \forall\;t \in \mathbb{N}_0 \\
    (ii)&\quad E(X_s|\mathcal{A}_t)=X_t\quad \forall\;s>t
  \end{align*}
  Gilt $\leq $ (bzw. $\geq $) in $(ii)$ spricht man von einem \underline{Supermartingal} (bzw. \underline{Submarginal})  
\end{defi}
\begin{defi}{14.6}{}
  Betrachte $(\Omega ,\mathcal{A},P)$ mit einer Filtration $\{\mathcal{A}_t\}_{t \in \mathbb{N}_0}$. \\
  Eine Zufallsvariable $\tau$ auf $(\Omega ,\mathcal{A},P)$ mit Werten in $\mathbb{N}_0 \cup \{\infty \} $ mit der Eigenschaft 
  \begin{align*}
    \{w \in \Omega :\tau(w)=t\}\in \mathcal{A}_t\quad \forall\;t \in \mathbb{N}_0
  \end{align*}
  heißt \underline{Stoppzeit} bzgl. $\{\mathcal{A}_t\}_{t \in \mathbb{N}_0}$. \\
  Ist $P(\tau = \infty )=0$ heißt $\tau $ \underline{endliche Stoppzeit}. 
\end{defi}
\begin{theo}{14.7 Version des Satzes vom optionalen Stoppen}{}
  Sei $(M_t)_{t \in \mathbb{N}_0}$ ein Martingal bzgl. der vom ihm erzeugten Filtration (d.h. $\mathcal{A}_t$ ist die von $M_0,M_1,...,M_t$ erzeugte $\sigma $-Algebra) und $\tau$ eine beschränkte Stoppzeit bzgl. $\{\mathcal{A}_t\}_{t \in \mathbb{N}_0}$ (d.h. $P(\tau>t_s)=0$ für ein $t_s \in \mathbb{N}_0$)\\
  Dann gilt 
  \begin{align*}
    E M _{\tau}=EM_0
  \end{align*}
\end{theo}
\begin{bew}[]
  O.B.d.A. gelte $\tau \leq t_s$ für alle $w$ (statt 'fast sicher'). \\
  \begin{align*}
    E M _{\tau}
    &=E \bigg(\sum_{t=0}^{t_s}{M_t 1_{\{t\}}}(\tau)\bigg)\\
    &=E \bigg(\sum_{t=0}^{t_s}{M_t [1_{\{t,t+1,...,t_s\}}(\tau)-1_{\{t+1,t+2,...,t_s\}}(\tau)]}\bigg)\\
    &=EM_0 1_{\{0,...,t_s\}}(\tau)+E \bigg(\sum_{t=1}^{t_s}{M_t 1_{\{t,...,t_s\}}(\tau)}\bigg)-E \bigg(\sum_{t=0}^{t_s-1}{M_t 1_{\{t+1,...,t_s\}}(\tau)}\bigg)-\underbrace{E \bigg(M _{t_s}1_{\underbrace{\{t_s+1,...,t_s\}}_{\emptyset }}(\tau)\bigg)}_{0}\\
    &=E M_0+0+\sum_{t=1}^{t_s}{E(M_t-M _{t-1})1_{\{t,...,t_s\}}(\tau)}
  \end{align*}
  mit $E(M_t-M _{t-1})=E[E(M_t|M _{t-1},...,M_0)-M _{t-1}]=M _{t-1}-M _{t-1}=0$
  folgt 
  \begin{align*}
    E M _{\tau}=E M_0\;\square
  \end{align*}
\end{bew}
\noindent\textbf{Herleitung der Lundberg'schen Ungleichung} (14.8)\\
Betrachte Modell (14.2) mit $X_k=a+\gamma k-\sum_{j=1}^{N(k)}{Y_j} $, setze
\begin{align*}
  &M_k:=\exp(-sX_k)\quad(k \in \mathbb{N}_0)\text{ für ein }s>0 
\end{align*}
Sei $\mathcal{A}_k$ die von $X_0,X_1,...,X_k$ erzeugte $\sigma $-Algebra (Filtration), dann ist $M_k$ $\{\mathcal{A}_k\}$-adaptierter Prozess.\\
Es gilt mit $g(s):=E(\exp(sY_1)) $
\begin{align*}
  E|M_k|=EM_k
  &=E\bigg\{\exp\bigg(-s\bigg[a+\gamma k-\sum_{j=1}^{N(k)}{Y_j}\bigg]\bigg)\bigg\}\\
  &=E\bigg\{\exp\bigg(-s[a+\gamma k]-\sum_{j=1}^{N(k)}{sY_j}\bigg)\bigg\}\\
  %&=\exp(-s[a+\gamma k])\underbrace{E\bigg(\prod_{j=1}^{N(k)}{sY_j}\bigg)}_{\prod_{}^{}{E\exp(sY_j)=g(s)^n}}\\
  &=\exp(-s[a+\gamma k]){E\bigg\{E\bigg(\prod_{j=1}^{N(k)}{\exp(sY_j)}\bigg|N(k)\bigg)\bigg\}}\\
  &=\exp(-s[a+\gamma k])\sum_{k=0}^{\infty }{}\underbrace{E\bigg(\prod_{j=1}^{N(k)}{\exp(sY_j)}\bigg)}_{\prod_{}^{}{E\exp(sY_j)}=g(s)^n}P(N(k)=n)\\
  &=\exp(-s[a+\gamma k])  E(g(s)^{N(k)})<\infty \text{ falls }g(s)=E(\exp(sY_1))<\infty \\
  &\!\!\!\!\!\!\!\!\overset{\sim \text{Pois}(\lambda k)}=\exp(-s[a+\gamma k])\sum_{j=0}^{\infty }{g^j(s)\frac{(\lambda k)^j}{j!}\exp(-\lambda k)}\\
  &=\exp(-s[a+\gamma k]-\lambda k)\exp(g(s)\lambda k)\\
  &=\exp(-s[a+\gamma k]+\lambda k[g(s)-1])<\infty \text{ für }g(s)<\infty 
\end{align*}
Außerdem gilt
\begin{align*}
  E(M _{k+1}|\mathcal{A}_k)
  &=E(\exp(-sX_k)\exp(-s[X _{k+1}-X_k]|\mathcal{A}_k)\\
  &=M_k \cdot E(\exp(-s[X _{k+1}-X_k])|\mathcal{A}_k)
\end{align*}
mit 
\begin{align*}
  X _{k+1}-X_k
  &=a+\gamma (k+1)-\sum_{j=1}^{N(k+1)}{Y_j-a-\gamma k}+\sum_{j=1}^{N(k)}{Y_j}\\
  &=\gamma -\sum_{j=N(k)+1}^{N(k+1)}{Y_j}=\gamma -\sum_{j=1}^{N(k+1)-N(k)}{Y _{N(k)+j}}
\end{align*}
Sei $\mathcal{A}_k'=\mathcal{A}_k \cup \sigma (N(k))$. 
Dann gilt fast sicher 
\begin{align*}
  E(\exp(-s[X _{k+1}-X_k])|\mathcal{A}_k)
  &=\exp(-s \gamma )E \bigg({E \bigg\{1 _{\mathbb{N}_0}(N(k))\exp \bigg[s \sum_{j=1}^{N(k+1)-N(k)}{Y _{N(k)+j}}\bigg]\bigg|\mathcal{A}_k'\bigg\}}\bigg|\mathcal{A}_k\bigg)\\
  &=\exp(-s \gamma )E \bigg({E \bigg\{\sum_{l=0}^{n}{1_{\{l\}}(N(k))\exp\bigg[s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg]\bigg|\mathcal{A}_k'}\bigg\}}\bigg|\mathcal{A}_k\bigg)\\
  &=\exp(-s \gamma )\sum_{l=0}^{\infty }{E \bigg(\underbrace{1 _{\{l\}}(N(k))E \bigg[\exp \bigg(s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg)\bigg|\mathcal{A}_k'\bigg]}_{(*)}\bigg|\mathcal{A}_k\bigg)}  
\end{align*}
Gilt $N(k)=l \Rightarrow \mathcal{A}_k'$ und die $\sigma $-Algebra die von den $N(k+1)-N(k)$ und $Y _{l+j}$, $j \geq 1$ erzegt werden, sind unabhängig. (Zukünftige Zuwächse und die Schadenshöhe von der Gegenwart $k$ aus gesehen)\\
Also folgt 
%\begin{align*}
%  {E \bigg\{\sum_{l=0}^{n}{1_{\{l\}}(N(k))\exp\bigg[s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg]\bigg|\mathcal{A}_k'}\bigg\}}
%  &=\sum_{l=0}^{\infty }{E \bigg(1_{\{l\}}(N(k))E \bigg[\exp \bigg(s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg)\bigg|\mathcal{A}_k'\bigg]\bigg)}\\
%  &=\sum_{l=0}^{\infty }{E \bigg(1_{\{l\}}(N(k))E \bigg[\exp \bigg(s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg)\bigg]\bigg)}\\
%  &=(...)
%\end{align*}
%Nebenrechnung  
%\begin{align*}
%  \exp \bigg(s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg)
%  &=E\prod_{}^{}{\exp(sY _{l+j})}\\
%  &=E(\exp(sY_1))^{N(k+1)-N(k)}\\
%  &=E\bigg(g(s)^{\overbrace{N(k+1)-N(k)}^{\sim \text{Pois}(\lambda (k+1-k))} }\bigg)
%\end{align*}
%Nebenrechnung vorbei. 
%\begin{align*}
%  (...)
%  &=\sum_{l=0}^{\infty }{E \bigg(1_{\{l\}}(N(k))\sum_{j=0}^{\infty }{g(s)^j}\frac{\lambda ^j}{j!}e^{-\lambda }\bigg)}\\
%  &=\sum_{l=0}^{\infty }{E 1_{\{l\}}(N(k))e^{-\lambda }e^{\lambda g(s)}}
%\end{align*}
\begin{align*}
  (*)
  &=1 _{\{l\}}(N(k))E \bigg[\exp \bigg(s \sum_{j=1}^{N(k+1)-N(k)}{Y _{l+j}}\bigg)\bigg]\\
  &=1 _{\{l\}}(N(k))E \bigg[\prod_{}^{}{}\exp (s {Y _{l+j}})\bigg]\quad (Y_1,Y_2,... \text{ iid})\\
  &=1 _{\{l\}}(N(k))E(g(s)^{N(k+1)-N(k)})\\
  &=1 _{\{l\}}(N(k))\sum_{j=0}^{\infty }{g(s)^j \frac{\lambda ^j}{j!}e^{-\lambda }}=1 _{\{l\}}(N(k))e^{-\lambda }e^{\lambda g(s)}
\end{align*}
Zusammengefasst gilt
\begin{align*}
  E(M _{k+1}|\mathcal{A}_k)
  &=M_k \cdot E(\exp(-s[X _{k+1}-X_k])|\mathcal{A}_k)\\
  &=M_k \cdot \exp(-s \gamma )\sum_{l=0}^{\infty }{E(1_{\{l\}}(N(k))e^{\lambda (g(s)-1)}|\mathcal{A}_k)}\\
  &=M_k \cdot \exp(\underbrace{\lambda g(s)-\lambda -s \gamma }_{=:G(s)})\cdot \underbrace{\sum_{l=0}^{\infty }{E(1_{\{l\}}(N(k))|\mathcal{A}_k)}}_{=1}\\
  &=M_k \cdot \exp(G(s))
\end{align*}
Setze $W_k:=\exp(-kG(s))M_k$. \\
$\{W_k\}_k$ ist eine $\{\mathcal{A}_k\}_k$-adaptierte Kette mit $E|W_k|<\infty $ (da $E|M_k|<\infty $) $\forall\;k \in \mathbb{N}_0$. Dann
\begin{align*}
  E(W _{k+1}|\mathcal{A}_k)=\exp(-(k+1)G(s))\underbrace{E(M _{k+1}|\mathcal{A}_k)}_{M_k\exp (G(s))}=\exp(-kG(s))M_k=W_k
\end{align*}
Also gilt 
\begin{align*}
  E(W _{k+m}|\mathcal{A}_k)
  &\!\!\overset{\text{eben}}=E(\underbrace{E(W _{k+m}|\mathcal{A}_{k+m-1})}_{W _{k+m-1}}|\mathcal{A}_k)\\
  &=E(W _{k+m-1}|\mathcal{A}_k)\text{ fast sicher}\\
  &=E(W _{k+m-2}|\mathcal{A}_k)=...\\
  &=E(W_k|\mathcal{A}_k)=W_k
\end{align*}
$\Rightarrow W_k$ Martingal bzgl. $\{\mathcal{A}_k\}_k$\\
Sei $t_s$ fest, $\tau_a=\inf\{k:X_k<0\}$, setze $\tau_a'=\min\{\tau_a,t_s\} $ (festgelegter Zeitpunkt $X_k<0$ oder $t_s $). Dies ist eine beschränkte Stoppzeit, denn
\begin{align*}
  \{w:\tau_a'>k\}=\begin{cases}
    \emptyset \in \mathcal{A}_k &k \geq t_s\\
    \bigcap_{j \leq k}^{}{\{X_j \geq 0\}}&k<t_s
  \end{cases}\in \mathcal{A}_k
\end{align*}
Damit gilt: 
\begin{align*}
  \{w \in \Omega :\tau_a'(w)=k\}=\underbrace{\{w:\tau_a'>k-1\}}_{\in \mathcal{A}_{k-1}\subseteq \mathcal{A}_k}\backslash \underbrace{\{w:\tau_a'>k\}}_{\in \mathcal{A}_k}
\end{align*}
Mit dem Satz von optionalen Stopping folgt 
\begin{align*}
  \exp(-sa)
  &=EW_0(\overset{\text{Def.}}=E[\exp(-0 \cdot G(s))M_0]=EM_0)\\
  &\!\!\overset{\text{Satz}}=EW _{\tau_a'}\geq 
  E(W _{\tau_a'}\cdot 1_{[0,t_s]}(\tau_a))=E(W _{\tau_a}\cdot 1_{[0,t_s]}(\tau_a))\geq  P(\tau_a \leq t_s)
\end{align*}
\underline{falls}: $W _{\tau_a}\geq 1$: mit 
\begin{align*}
  W _{\tau_a}=\underbrace{e^{-\tau_aG(s)}}_{\geq 1 \text{ für }G(s)<0}M _{\tau_a}\geq M _{\tau_a}=e^{-sX _{\tau_a}}\geq 1
\end{align*}
($X _{\tau_a}\leq 0 $ ab Zeitpunkt $\tau_a $) $\Rightarrow $ 1. Forderung: $G(s)<0$ (F1) \\
Wegen $\{\tau_a< \infty \}=\bigcup\limits_{t_s \in \mathbb{N}_0}^{}{\{\tau_a \leq t_s\}}$ gilt außerdem 
\begin{align*}
  P(\tau_a < \infty )=\lim\limits _{t_s\to \infty }P(\tau_a \leq t_s)\overset{\text{oben}}\leq \exp(-sa)
\end{align*} wobei $\exp(-sa)$ möglichst klein sein soll!
$\Rightarrow $ 2. Forderung: wähle $s=s^*$ möglichst groß (F2) \\
(F1) $+$ (F2) $\Rightarrow s^*=\sup\{s>0:G(s)\leq 0\} $

\begin{theo}{14.9 Lundberg'sche Ungleichung}{}
  Im klassischen Versicherungsmodell (14.2) mit $G(s):=\lambda Ee^{-sY_1}-\lambda -s \gamma $ ($N(k)\sim$ Pois$(\lambda k)$) ist die Wahrscheinlichkeit $P(\tau _a=\infty )$ dass eine Versicherung bei Startkapital $a $ \underline{nie} in die roten Zahlen kommt nach unten beschränkt durch 
  \begin{align*}
    1-\exp(-s^*a)\text{ mit }s^*=\sup \{s:G(s)\leq 0\}\text{ 'Lundberg Exponent'}
  \end{align*}
\end{theo}
\chapter{Markov-Ketten}
Betrachte Stochastischen Prozess $\{X_n\}_{n \in \mathbb{N}_0} $ der abzählbar viele Werte annimmt, im Allgemeinen $\mathbb{N}_0$. \\
'$X_n=i$' heißt, der Prozess ist zu Zeitpunkt $n$ im Zustand $i$
\begin{defi}{15.1}{}
  Ein Prozess $\{X_n\}_{n \in \mathbb{N}_0}$ heißt \underline{Markov-Kette}, falls er die \underline{Markov-Eigenschaft} erfüllt, d.h.
  \begin{align*}
    p _{ij}:=P(X _{n+1}=j|X_n=i,X _{n-1}=i _{n-1},...,X_0=i)=P(\underbrace{X _{n+1}=j}_{\text{Zukunft}}|\underbrace{X_n=i}_{\text{Gegenwart}})  \end{align*}
  für alle Zustände $j,i,i_0,i_1,...,i _{n-1}$ und $n \geq 0 $.
\end{defi}
\begin{kor}{15.2}{}
  Es muss gelten $p _{ij}\geq 0 \;\forall\;i,j$ (da Wahrscheinlichkeit $\geq  $ 0), $\sum_{j=0}^{\infty }{p _{ij}}=1$, $i \in \mathbb{N}_0$ (man muss vom Zustand $i $ irgendeinen Zustand erreichen)\\
  \underline{Übergangsmatrix}
  \begin{align*}
    P=\begin{pmatrix}
      p _{00}&p _{01}&...&...&...\\
     p _{10}&p _{11}&...&...&...\\
     \vdots&\vdots&&&\\
     p _{i0}&p _{i1}&&&\\
     \vdots&\vdots&&&\\
    \end{pmatrix}
  \end{align*}

\end{kor}
  \underline{Bsp}
  \begin{align*}
    \begin{pmatrix}
      \frac{1}{2}&\frac{1}{2}&0&0&0\\
     \frac{1}{3}&0&\frac{2}{3}&0&0\\
     0&\frac{1}{3}&0&\frac{2}{3}&0\\
     0&0&\frac{2}{3}&0&\frac{1}{3}\\
     0&0&0&\frac{1}{2}&\frac{1}{2}\\
    \end{pmatrix}
  \end{align*}
  \begin{center}
\begin{tikzpicture}[node distance = 15mm, semithick, main/.style = {draw, circle}]
  \node[main] (1) {$1$};
  \node[main] (2) [right of = 1]{$2$};
  \node[main] (3) [right of = 2]{$3$};
  \node[main] (4) [right of = 3]{$4$};
  \node[main] (5) [right of = 4]{$5$};
  \path (1) edge [ loop left ] node {$\frac{1}{2}$} (1) 
        (1) edge [bend left, ->] node [above] {$\frac{1}{2}$} (2) 
        (2) edge [bend left, -> ] node [below] {$\frac{1}{3}$} (1)
        (2) edge [bend left, ->] node [above] {$\frac{2}{3}$} (3) 
        (3) edge [bend left, -> ] node [below] {$\frac{1}{2}$} (2)
        (3) edge [bend left, ->] node [above] {$\frac{1}{3}$} (4) 
        (4) edge [bend left, -> ] node [below] {$\frac{2}{3}$} (3)
        (4) edge [bend left, ->] node [above] {$\frac{1}{3}$} (5) 
        (5) edge [bend left, -> ] node [below] {$\frac{1}{2}$} (4)
        (5) edge [ loop right ] node {$\frac{1}{2}$} (5); 
\end{tikzpicture}
\end{center}
\begin{bei}[15.3 Warteschlange]%embedded markov chain
  Ankunft von Kunden in Kundenzentrum \\
  Modellierung mit Poisson-Prozess mit Intensität $\lambda $. \\
  1 Mitarbeiter, 1. Kunde wird sofort bedient, der Rest kommt in die Warteschlange. \\
  \underline{Annahme}: Servicezeiten der Kunden sind iid $\sim G$\\
  Die Zeitdauern zwischen den Ankünften sei exponentialverteilt, da es sich um einen Poisson-Prozess handelt (vgl. 14.4). \\
  Sei $\tilde{N}(t)=$ \#\{Anzahl Kunden zum Zeitpunkt $t$\}\\
  $\tilde{N}(t)$ ist keine Markov-Kette, denn die bedingte Verteilung von $\tilde{N}(t+1)$ hängt nicht nur von $\tilde{N}(t)$, sondern auch von den Servicedauern ($\sim G$ unbekannt) ab.\\
  \underline{Ausweg}: Betrachte nur Zeitpunkte, an denen die Kunden fertig sind, d.h. \\
  $X_n=$ \#\{Kunden nachdem der $n$-te Kunde gegangen ist\} ($n \geq 1$) \\
  $X_n>0$: es gibt noch $X_n$ Kunden, einer wird bedient. $X _{n}-1$ in Warteschlange \\
    '$X_n=0$': keine Kunden mehr da nachdem $n$-ter Kunde gegangen ist \\
  d.h. wenn der nächste Kunde geht gibt es $X _{n}-1+Y_n$ Kunden ($Y_n$ Neuzugänge; Kunden die in der Zeit gekommen sind, in der Kunde $n+1$ bedient wurde)\\

  \begin{align*}
    \Rightarrow X _{n+1}=\begin{cases}
       X _{n}-1+Y_n&X_n>0\\
       Y_n&X_n=0
    \end{cases}\quad(*)
  \end{align*}
  $\{Y_n\}_{\mathbb{N}} $ ist Poisson-Prozess, nämlich \#\{ankommende Kunden in disjunkten Zeitintervallen\}, d.h. \\
  die $Y_n$ sind unabhängig und
  \begin{align*}
    P(Y_n=j)&=E(P(Y_n=j)|\text{Servicezeit})\\
            &=\int_{0}^{\infty }{e^{-\lambda x}\frac{(\lambda x)^j}{j!}dG(x)}\quad j=0,1,...
  \end{align*}
  \begin{center}
    \begin{tikzpicture}
  \begin{axis}[
    axis x line = middle,
    axis y line = none,
    xmin = 0,
    xmax = 1.2,
    xtick = \empty,
    extra x ticks = {0,1},
    extra x tick labels = {0,$x $ \\ (zufällig)},
    xticklabel style = {align = center}
    ]
    \addplot[black]{0};
    \node (source) at (axis cs:0.2,0.3) {Kunde $n $ geht};
    \node (destination) at (axis cs:0.00,-0.01){};
       \draw[thick,->](source)--(destination);
    \node (source2) at (axis cs:0.9,0.3) {Kunde $n+1 $ geht};
    \node (destination2) at (axis cs:1.03,-0.01){};
       \draw[thick,->](source2)--(destination2);
\end{axis}
\end{tikzpicture}
  \end{center}
  Damit und mit $(*)$ folgt $\{X_n\}_{n \in \mathbb{N}}$ ist eine Markov-Kette mit Übergangsverteilung \\
  Nebenrechnung
  \begin{align*}
    P(X _{n+1}=j|X_n=i)=P(X _{n}-1+Y_n=j|X_n=i)=P(Y_n=j-i+1)
  \end{align*}
  Nebenrechnung vorbei
  \begin{align*}
    p _{0j}&=\int_{0}^{\infty }{e^{-\lambda x}\frac{(\lambda x)^j}{j!}dG(x)}\quad j \in \mathbb{N}_0\\
    p _{ij}&=\int_{0}^{\infty }{e^{-\lambda x}\frac{(\lambda x)^{j-i+1}}{(j-i+1)!}dG(x)}\quad j-i+1 \geq 0 \Leftrightarrow j \geq i-1, i \geq 1 \\
    p _{ij}&=0 \text{ sonst}
  \end{align*}
\end{bei}
\begin{bei}[15.4 Der allgemeine Random Walk (Irrfahrt)]
  Seien $X_1,X_2,...,$ iid mit 
  \begin{align*}
    P(X_i=j)=a_j,\quad j=0,\pm 1, \pm 2,...
  \end{align*}
  Sei 
  \begin{align*}
    S_0=0\quad S_n=\sum_{i=1}^{n}{X_i}
  \end{align*}
  dann gilt $S_n$ ist eine Markov-Kette mit $P _{ij}=a _{j-i}$ ($S_n=i\rightarrow S _{n+j}=j$)\\
  %\begin{align*}
  %  p _{ij}&=P(S _{n+1}=j|S_n=i)=a _{j-i}\quad \forall\;n \geq 0
  %\end{align*}
  \underline{Spezialfall}: Einfacher Random Walk
  \begin{align*}
    S_n=\sum_{i=1}^{n}{X_n}\text{ mit }P(X_i=1)=p \text{ und }P(X_i=-1)=\underbrace{1-p}_{q}\quad 0<p<1
  \end{align*}
  \begin{center}
    \begin{tikzpicture}
  \begin{axis}[
    axis x line = middle,
    axis y line = none,
    xtick = \empty,
    extra x ticks = {0,1,2,3,4},
    xmin = 0,
    xmax = 4.5,
    ]
    \addplot[black, domain = 0:1]{x};
    \addplot[black, domain = 1:3]{-x+2};
    \addplot[black, domain = 3:4.5]{x-4};
    \addplot[black, domain = 0:2, dotted, thick]{x};
    \addplot[black, domain = 0:2, dotted, thick]{-x};
\end{axis}
\end{tikzpicture}
  \end{center}
\end{bei}
\chapter{Brownsche Bewegung ('Wiener Prozess')}
\noindent \textbf{Einführung} (16.1 Herleitung)\\
Betrachte einen symmetrischen Random Walk $X_1,X_2,...$ (hoch/ runter mit gleicher Länge),\\
$\Delta t$ Zeiteinheit \\
$\Delta x$ Schrittlänge (Sprunghöhe)
\begin{center}
  \begin{tikzpicture}
  \begin{axis}[
    axis x line = middle,
    axis y line = none,
    xtick = \empty,
    extra x ticks = {0,2,0.5,1,1.5},
    extra x tick labels = {0,2},
    xmin = 0,
    xmax = 2.5,
    ]
    \addplot[black, domain = 0:0.5]{-x};
    \addplot[black, domain = 0.5:2]{x-1};
    \addplot +[mark=none, black, dotted, thick] coordinates {(2, 0.5) (2, 1)};
    \addplot +[mark=none, black, dotted, thick] coordinates {(1.5, 0.5) (2, 0.5)};
\node (A) at (axis cs:0.05, 0) {};
\node (B) at (axis cs:0.45, 0) {};
\node (C) at (axis cs:2, 0.55) {};
\node (D) at (axis cs:2, 0.95) {};
\draw [decorate,decoration={brace,amplitude=5pt,raise = 1mm}]
(A.west) -- (B.east) node [black,midway, above, yshift = 2mm] {$\Delta t$};
\draw [decorate,decoration={brace,amplitude=5pt, mirror, raise = 1mm}]
(C.south) -- (D.north) node [black,midway, right, xshift = 2mm] {$\Delta x$};
\end{axis}
\end{tikzpicture}
\end{center}
$X(t)$ sei Position zum Zeitpunkt $t$, d.h. $X(t)=\Delta x \cdot (X_1+X_2+...+X _{\frac{t}{\Delta t}})$ mit 
\begin{align*}
  X_i=\begin{cases}
    +1 &\text{Schritt der Länge $x$ nach oben}\\
    -1 &\text{Schritt der Länge $x$ nach unten}
  \end{cases}
\end{align*}
$X_i$'s unabhängig mit $P(X_i=1)=P(X_i=-1)=\frac{1}{2}$, also $EX_i=0$, $VarX_i=EX_i^2=1 \cdot P(X_i^2=1)=1$
\begin{align*}
  \Rightarrow \begin{cases}
    E(X(t))=0 &\\
    Var(X(t))&=E((X(t))^2)=(\Delta x)^2 \sum_{i=1}^{\frac{t}{\Delta t}}{{Var(X_i)}}=(\Delta x)^2 \frac{t}{\Delta t}
  \end{cases}   
\end{align*}
\underline{Grenzübergang} $\Delta x\to 0$, $\Delta t\to 0$ derart sodass Grenzprozess nicht trivial (als z.B. \underline{nicht} beide gleich schnell gegen 0 gehen lassen wie $\Delta x:=\Delta t$, da sonst $X(t)=0$) \\
Betrachte $\Delta x:=c \sqrt{\Delta t}$ ($c>0$ Konstant)\\
Dann gilt mit $\Delta t\to 0$:
\begin{align*}
  E(X(t))&=0 \\
  Var(X(t))&=(\Delta x)^2 \frac{t}{\Delta t}=c^2\Delta t \frac{t}{\Delta t}=c^2t
\end{align*}
\underline{Eigenschaften} von $X(t)=\Delta x(X_1+X_2+...+X _{\frac{t}{\Delta t}})$ wenn $\Delta x=c \sqrt{\Delta t}\to0$\\
(i)\\
$X(t)\sim N(0,c^2t)$ (ZGW)\\
Begründung: Betrachte $t$ fest, $\frac{t}{\Delta t}=n$ Teilintervalle
\begin{align*}
  \Delta t&=\frac{t}{n}\overset{n\to \infty }\longrightarrow 0 \\
  X(t)&=c \sqrt{\Delta t}(X_1+X_2+...+X_n)\\
      &=c \sqrt{t}n^{-\frac{1}{2}}\underbrace{\sum_{i=1}^{n}{X_i}}_{\stackrel{EX_i=0,}{VarX_i=1}}\overset{\text{D}}\to c \sqrt{t}N(0,1)=N(0,c^2t)
\end{align*}
(ii) \\
$\{X(t),t \geq 0\} $ hat unabhängige Zuwächse (Änderungen des Random Walk in disjunkten Zeitintervallen sind unabhängig) \\
Die Änderung der Position des Random Walks in jedem Zeitintervall hängt nur von der Intervalllänge ab (\underline{nicht} der Position), also \\
(iii)\\
$\{X_t,t \geq 0\} $ hat stationäre Zuwächse, d.h. $X _{t+s}-X_t$ haben für jedes $t$ dieselbe Verteilung (nur vom Abstand $s$ abhängig) \\\\
\begin{defi}{16.2}{}
  Ein stochastischer Prozess $(X(t))_{t \geq 0} $ heißt 'Brownscher Bewegungs-Prozess' (oder 'Brownsche Bewegung oder 'Wiener Prozess') falls gilt \\
  (i) $X(0)=0 $\\
  (ii) $(X(t))_{t \geq 0} $ hat unabhängige stationäre Zuwächse \\
  (iii) Für jedes $t > 0 $ gilt $X(t)\sim N(0,c^2t)$ \\
  (Modell Partikelbewegung, entdeckt von Robert Brown, 1. Erklärung (physikalisch) durch Einstein 1905, mathematische Definition Norbert Wiener 1918)\\
  Im Folgenden sei $c=1 $ \underline{'standard Browninan motion'}
\end{defi}
\noindent \textbf{Eigenschaften} (16.3)\\
(a) \\
$X(t) $ ist $P $-fast sicher \underline{stetige} Funktion in $t $ ('stetige Pfade')\\
(b)\\
$X(t) $ ist $P $-fast sicher \underline{nirgends differenzierbar}\\
(c)\\
$X(t) $ ist ein \underline{Markov-Prozess} \\
Unabhängige Zuwächse $\Rightarrow  $ Positionswechsel $X(t+s)-X(s) $ zwischen Zeitpunkt $s $ und $t+s  $ ist unabhängig von allen Werten vor dem Zeitpunkt $s  $. Damit gilt
\begin{align*}
  &P(\underbrace{X(t+s)}_{\text{Zukunft}}\leq a|\underbrace{X(s)=x}_{\text{Gegenawart}},\underbrace{X(u), 0 \leq u}_{\text{Vergangenheit}} <s) \\
   =&P(X(t+s)-X(s)\leq a-{X(s)}|{X(s)=x},{X(u),0 \leq u <s})\\
   =&P(X(t+s)-X(s)\leq a-x)\\
   =&P(X(t+s)\leq a|X(s)=x)
\end{align*}
\noindent \textbf{Verteilung von $(X(t))_{t \geq 0} $} (16.4)\\
$X(t) $ hat unabhängig stationäre Zuwächse (nur vom Abstand abhängig) \\
Nebenbemerkung \\
Im diskreten Fall
\begin{align*}
  P(X_1=x_1,X_2=x_2,...,X_n=x_n)=P(X_1=x_1,X_2=x_2-x_1,...,X_n- X _{n-1}=x_n - x _{n-1})
\end{align*}
Nebenbemerkung vorbei. \\
Damit hat $X(t_1),..,X(t_n) $ die gemeinsame Dichte
\begin{align*}
  f(x_1,...,x_n)=f _{t_1}(x_1)f _{t_2-t_1}(x_2-x_1)\cdot ... \cdot f _{t_n-t _{n-1}}(x_n-x _{n-1}) 
\end{align*}
und die bedingte Verteilung von $X(s) $ gegeben $X(t)=B $ ist ($s<t $):
\begin{align*}
  f _{s|t}(x|B)=\frac{f_s(x)f _{t-s}(B-x)}{f_t(B)}
  &=K_1\exp \bigg(-\frac{x^2}{2s}-\frac{(B-x)^2}{2(t-s)}\bigg)\\
  &=K_1\exp \bigg(\frac{-x^2(t-s)-s(B-x)^2}{2s(t-s)}\bigg)\\
  &=K_1\exp \bigg(\frac{-t(x-\frac{s}{t}B)^2-B^2(\frac{s }{t}-\frac{s^2}{t^2})}{2s(t-s)}\bigg)\\
  &=K_2\exp \bigg(-\frac{(x-\frac{s }{t}B)^2}{2s(t-s)/t}\bigg)\text{ Normalverteilung}
\end{align*}
\begin{align*}
  \Rightarrow E(X(s)|X(t)=B)
  &=B \frac{s }{t},\quad (E(X(s)|X(t))=X(t)\frac{s }{t})\\
  Var(X(s)|X(t)=B)&=\frac{s(t-s)}{t}=\frac{s }{t}\frac{t-s}{t}t\text{ (nicht von $B  $ abhängig)}
\end{align*}
Gilt z.B. $\frac{s}{t}=\alpha \in (0,1)$ $\Rightarrow  $ $X(s)|X(t)\sim N(\alpha X(t),\alpha (1-\alpha )t) $ \\
Aus der Dichteformel für $X(t_1),...,X(t_n) $ foglt auch, dass die gemeinsame Verteilung eine multivariate Normalverteilung, d.h. der Prozess ist ein Gauß-Prozess.
\begin{defi}{16.5}{}
  Ein stochastischer Prozess heißt \underline{Gauß-Prozess}, wenn die Verteilung von $X(t_1),...,X(t_n) $ für alle $t_1,...,t_n $ eine multivariate Normalverteilung ist.
\end{defi}
\begin{bem}[16.6 Alternative Definition der Brownschen Bewegung]
  \underline{Vorbemerkung}: Eine multivariate Normalverteilung ist vollständig durch die Erwartungswerte der Randverteilungen und die Kovarianzen bestimmt.\\
  \underline{Alternative Definition}: Ein Brownscher Bewegungsprozess ist ein Gaußprozess mit Erwartungswert \\
  $E(X(t))=0$ und $Cov(X(s),X(t))=s \;\forall\;s <t$ \\
  \underline{Denn} 
  \begin{align*}
    Cov(X(s),X(t))&=Cov(X(s),X(s)+X(t)-X(s))\\
                  &=Cov(X(s),X(s))+\underbrace{Cov(X(s),\underbrace{X(t)-X(s)}_{\text{unab. Zuwächse}})}_{0}\\
                  &=Cov(X(s),X(s))=Var(X(s))=s \quad (c^2t \text{ mit }c=1,t=s)
  \end{align*}
\end{bem}
\noindent \textbf{Herleitung der Brownschen Brücke} (16.7)\\
Sei $X(t) $ Brownsche Bewegung, betrachte
\begin{align*}
  \{X(t),0 \leq t \leq 1|X(1)=0\}
\end{align*}
wie in 16.4 zeigt man: dies ist ein Gauß-Prozess. \\
Dort ebenfalls gezeigt: 
\begin{align*}
  E(X(s)|X(1)=0)
  &=0 \cdot \frac{s}{1}=0\;\forall\;s <1
\end{align*}
Für $s \leq t \leq 1 $ gilt: 
\begin{align*}
  Cov[(X(s),X(t))|X(1)=0]
  &=E[X(s)X(t)|X(1)=0]\\
  &=E[E\{X(s)X(t)|X(t),X(1)=0\}|X(1)=0]\\
  &=E[X(t)\underbrace{E\{X(s)|X(t)\}}_{X(t)\frac{s }{t}}|X(1)=0]\\
  &=\frac{s}{t}E (X^2(t)|X(1)=0)\\
  &=\frac{s}{t}Var(X(t)|X(1)=0)\\
  &=\frac{s}{t}t(1-t)=s(1-t)
\end{align*}
\begin{theo}{16.8}{}
  Sei $X(t)_{t \geq 0} $ die Brownsche Bewegung, $Z(t)=X(t)-t  X(1) $, dann ist $(Z(t))_{0 \leq t \leq 1} $ die Brownsche Brücke.
\end{theo}
\begin{bew}[]
  O.B.d.A. sei $s<t $. $(Z(t))_{0 \leq t \leq 1} $ ist Gauß-Prozess mit $EZ(t)=0 $. Zu zeigen
  \begin{align*}
    s(1-t)\overset{!}=Cov(Z(s),Z(t))
    &=Cov(X(s)-sX(1),X(t)-tX(1))\\
    &=\underbrace{Cov(X(s),X(t))}_{=s}+st \underbrace{Cov(X(1),X(1))}_{=1}-s \underbrace{Cov(X(1),X(t))}_{t}-t \underbrace{Cov(X(s),X(1))}_{s}\\
    &=s+st-st-st=s-st=s(1-t)\checkmark\;\square
  \end{align*}
\end{bew} 
\chapter{Asymptotische Statistik}
\begin{defi}{17.1}{}
  $X,X_1,X_2,...,X_n  $ seien iid Zufallsvariablen mit $EX=\mu  $, $VarX=\sigma ^2 \in (0,\infty ) $ und Verteilungsfunktion $F $.\\
  Die \underline{empirische Verteilungsfunktion} ist 
  \begin{align*}
    \hat{F}(t)=\frac{1}{n}\sum_{i=1}^{n}{1(X_i \leq t)}=\frac{\#\{X_i \leq t\}}{n},\quad t \in (-\infty ,\infty )
  \end{align*}
  Der \underline{empirische Schätzer} für $Eg(x) $ ist 
  \begin{align*}
    \int{g(x)d \hat{F}(x)}=\frac{1}{n}\sum_{i=1}^{n}{g(X_i)}
  \end{align*}
  (Spezialfall $g(x)=1 _{(-\infty ,t]}(x) $ empirische Verteilungsfunktion)
\end{defi}
\begin{bem}[17.2 Eigenschaften von empirischen Schätzern]
  (a)
  \begin{align*}
    \frac{1}{n}\sum_{i=1}^{n}{g(X_i)}\overset{n\to \infty }\longrightarrow Eg(X)\text{ fast sicher (SLLN)}
  \end{align*}
  (b)
  \begin{align*}
    \sqrt{n}\bigg(\frac{1}{n}\sum_{}^{}{g(X_i)-Eg(X_i)}\bigg)\overset{D}{\underset{n\to \infty }{\longrightarrow }}N(0,Var \;g(x)) \text{ (ZGW)}
  \end{align*}
\end{bem}
\begin{bem}[17.3 Eigenschaften von der empirischen Verteilungsfunktion]
  (a) \\
  $\hat{F}(t) $ ist Zufallsvariable (für $t  $ fest) \\
  (b)\\
  $\hat{F}(.) $ ist eine zufällige (Verteilungs-)Funktion, $(\hat{F}(t))_{t \in \mathbb{R}} $ also stochastischer Prozess
  \\
  (c)\\
  $\hat{F}(t) $ ist erwartungstreu für $F(t) $
  \begin{align*}
    E \hat{F}(t)=\frac{1}{n}\sum_{}^{}{\underbrace{E(1(X_i \leq t))}_{F(t)}}=F(t)
  \end{align*}
  (d)
  \begin{align*}
    n \hat{F}(t)=\sum_{i=1}^{n}{1(X_i \leq t)} \sim \text{ Bin}(n,F(t))
  \end{align*}
  (e)\\
  Vgl. 17.2(b): 
  \begin{align*}
    \hat{F}(t)=\frac{1}{n}\sum_{i=1}^{n}{1(X_i \leq t)} \approx N\bigg(F(t),\frac{F(t)(1-F(t))}{n}\bigg)
  \end{align*}
  \begin{align*}
    \sqrt{n}(\hat{F}(t)-F(t))\overset{\text{D}}\to N(0,F(t)(1-F(t)))
  \end{align*}
\end{bem}
\begin{theo}{17.4 Gliwenko-Cantelli}{}
  $\hat{F}(x)=\hat{F}_n(x) $ ist stark konsistent gleichmäßig in $x $, d.h.
  \begin{align*}
    D_n:=\sup _{t \in \mathbb{R}}|\hat{F}_n(t)-F(t)|\overset{n\to \infty }\longrightarrow 0 \text{ fast sicher}
  \end{align*}
  $D_n $ heißt 'Kolmogorov-Smirnov Abstand'.
\end{theo}
\begin{bew}[]
  Wir verwenden die Dvoretzky-Kiefer-Wolfowitz Ungleichung, d.h.
  \begin{align*}
    \exists\;c \in (0,\infty ):P(D_n>\varepsilon )\leq ce^{-2n \varepsilon ^2}\quad \forall\;\varepsilon >0
  \end{align*}
  (Beweis siehe Serfling, Approximation Theorems of Mathematical Statistics, 2.1.3)\\
  Damit gilt 
  \begin{align*}
    \sum_{n=1}^{\infty }{P(D_n>\varepsilon ) }\leq \sum_{n=1}^{\infty }{ce^{-2n \varepsilon ^2}}\quad\forall\;\varepsilon >0
  \end{align*}
  Die Summe ist endlich $(|a _{n+1}/a_n|\to e^{-2 \varepsilon ^2}<1) $. Mit dem folgenden Lemma 17.5 folgt $D_n\to 0 $ fast sicher. $\square $
\end{bew}
\begin{lem}{17.5}{}
  Gilt $X_n \overset{\text{P}}\to X $ hinreichend schnell (sufficiently fast), d.h.
  \begin{align*}
    \sum_{n=1}^{\infty }{P(|X_n-X|>\varepsilon )}<\infty \quad \forall\;\varepsilon >0
  \end{align*}
  dann folgt
  \begin{align*}
    X_n\to X \text{ fast sicher}
  \end{align*}
\end{lem}
\begin{bew}[]
  Statt fast sichere Konvergenz, also $P(\lim X_n=X)=1 $ zu beweisen, beweisen wir die äquivalente Bedingung (siehe Serfling 1.2.2)
  \begin{align*}
    \lim_{n\to \infty }{P(\underbrace{|X_m-X|<\varepsilon\quad \forall\;m \geq n }_{=:A})}=1
  \end{align*}
  Wir zeigen $P(A^c)\to 0 $. Sei $\varepsilon >0 $ fest
  \begin{align*}
    P(|X_m-X|>\varepsilon \text{ für ein }m \geq n) 
    &=P \bigg(\bigcup_{m \geq n}^{\infty }{\{|X_m-X|>\varepsilon \}}\bigg)\\
    &\leq \sum_{m \geq n}^{}{P(|X_n-X|>\varepsilon )}\overset{n\to \infty }\longrightarrow 0
  \end{align*}
  da die Summe nach Voraussetzung endlich ist. $\square $
\end{bew}
\begin{theo}{17.6}{}
  Betrachte $H_0:F=F_0 $, $H_1:F \neq F_0 $, $F,F_0 $ stetig \\
  Dann ist die Kolmogorov-Smirnov-Teststatistik
  \begin{align*}
    T=\sup _{x \in \mathbb{R}}|\hat{F}(x)-F_0(x)|
  \end{align*}
  unter $H_0 $ \underline{verteilungsfrei}, d.h. die Verteilung hängt nicht von $F_0 $ ab.
\end{theo}
\begin{bew}[]
  Betrachte 'Pseudo-Inverse' (klassische Definition eines Quantils) 
  \begin{align*}
    F_0 ^{-1}(y)=\inf _{x \in \mathbb{R}}\{F_0(x)\geq y\},\quad y \in (0,1)
  \end{align*}
  Es gilt 
  \begin{align*}
    T=\sup _{x \in \mathbb{R}}|\hat{F}(x)-F_0(x)|
    &=\sup _{y \in (0,1)}|\hat{F}(F_0 ^{-1}(y))-\underbrace{F_0(F_0 ^{-1}(y))}_{y}|
  \end{align*}
  und 
  \begin{align*}
    \hat{F}(F_0 ^{-1}(y)) 
    &=\frac{1}{n}\sum_{j=1}^{n}{1 _{(-\infty ,F_0 ^{-1}(y)]}}(X_j)\\
    &=\frac{1}{n}\sum_{j=1}^{n}{1 _{(-\infty ,y]}}\underbrace{(F_0(X_j))}_{=:Z_j}
  \end{align*}
  $Z_1,...,Z_n $ iid mit 
  \begin{align*}
    P(Z_j \leq z) &=P(F_0(y)\leq z)=P(X_j \leq F_0 ^{-1}(z))\overset{H_0}=F_0(F_0 ^{-1}(z))=z\quad \forall\;z \in [0,1]
  \end{align*}
  $\Rightarrow Z_j \overset{iid}\sim U([0,1]) $ und $T $ lässt sich ohne $F_0  $ darstellen:
  \begin{align*}
    T=\sup _{y \in (0,1)}\bigg|\frac{1}{n}\sum_{j=1}^{n}{1 _{(-\infty ,y]}(Z_j)-y}\bigg|\;\square
  \end{align*}
\end{bew}
\begin{bem}[17.7]
  Unter $H_0 :F=F_0$ hat $\sqrt{n}T $ für stetig $F $ dieselbe Verteilung wie 
  \begin{align*}
    S_n=\sup _{x \in [0,1]}\bigg|n ^{-\frac{1}{2}}\sum_{j=1}^{n}{1 _{[0,x]}(U_j)-x}\bigg|
  \end{align*}
  $U_1,...,U_n \overset{iid}\sim U([0,1])$. Man kann zeigen:
  \begin{align*}
    S_n \overset{\text{D}}\to S\sim F(x)=1-2 \sum_{k=1}^{\infty }{(-1)^{k-1}e^{-2k^2x^2}},\;x \geq 0
  \end{align*}
  ($\Rightarrow  $ kritische Werte berechenbar)
\end{bem}
\begin{bem}[17.8 $\hat{F} $ und die Brownsche Brücke]
  Betrachte $X_1,X_2,... $ iid \\
  \underline{1. Fall}: $X_i\sim U(0,1) $
  \begin{align*}
    \alpha _n(s):=\sqrt{n}(\hat{F}(s)-s)=\sqrt{n}\bigg(\frac{1}{n}\sum_{j=1}^{n}{1 _{(-\infty ,s]}(X_j)}-F _{U(0,1)}(s)\bigg)
  \end{align*}
  \underline{Ziel}: Asymptotische Eigenschaften von $\{\alpha _n(s)\}_{s \in [0,1]} $ 
  \begin{align*}
    N(t):=n \hat{F}(t)\sim \text{Bin}(n,t),\quad N(s)\sim \text{Bin}(n,s)
  \end{align*}
  Sei $s<t $. Die bedingte Wahrscheinlichkeit von $N(t)-N(s) $ gegeben $N(s)=n_s $ ist Bin$(n-n_s,\frac{t-s}{1-s}) $-verteilt (Ü).\\
  Man kann zeigen: \\
  - $(\alpha _n(s),\alpha _n(t)) $ ist asymptotisch normalverteilt \\
  - der Grenzprozess ist ein Gauß-Prozess \\
  \underline{Zu bestimmen}: $E(\alpha _n(s)),Cov(\alpha _n(s),\alpha _n(t)) $
  \begin{align*}
    E(\alpha _n(s))=0 \text{ (klar)}
  \end{align*}
  Sei $0 \leq s \leq t \leq 1 $
  \begin{align*}
    Cov(\alpha _n(s),\alpha _n(t))
    &=n(Cov (\hat{F}(s),\hat{F}(t))\\
    &=\frac{1}{n}Cov (N(s),N(t))\\
    &=\frac{E[E(N(s)N(t)|N(s))]-\overbrace{E(N(s))}^{ns} \overbrace{E(N(t))}^{nt} }{n}\\
    &=n ^{-1}\{E[N(s)E(N(t)|N(s))]-n^2st\}\\
    &=n ^{-1}\{E[N(s)E(N(t)-N(s)+N(s)|N(s))]-n^2st\}\\
    &=n ^{-1}\{E\bigg[N(s)(N(s)+(n-N(s))\frac{t-s}{1-s})\bigg]-n^2st\}\\
    &=[\text{mit }N(s)\sim \text{Bin}(n,s)]...\\
    &=s(1-t)
  \end{align*}
\end{bem}
Der Grenzprozess ist also ein Gauß-Prozess mit Erwartungswert $E\alpha _n(s)=0\;\forall s \in [0,1] $ und $Cov(\alpha _n(s),\alpha _n(t))=s(1-t)\;(0 \leq s \leq t \leq 1) $ also eine \underline{Brownsche-Brücke}. \\
\underline{2. Fall} $X_i\sim F $ beliebige stetige Verteilungsfunktion.\\
\underline{Gesucht}: Asymptotische Verteilung von $\sqrt{n}\sup _{x}|\hat{F}(x)-F(x)| $ \\
Es gilt 
\begin{align*}
  P(F(X_i)\leq x)=P(X_i \leq F ^{-1}(x))=F(F ^{-1}(x))=x
\end{align*}
d.h. $F(X_i)\sim U(0,1) $. \\
Betrachte $\alpha _n(s) $ aus Fall 1 mit $F(X_i)\sim U(0,1) $. \\
Auf Fall 1 folgt:
\begin{align*}
  \alpha _n(s)
  &=\sqrt{n}\bigg[\frac{1}{n}\#\{X_i,i=1,...,n:\underbrace{F(X_i)}_{\sim U(0,1)}\leq s\}-s\bigg]\\
  &=\sqrt{n}\bigg[\frac{1}{n}\sum_{i=1}^{n}{1\{X_i \leq F ^{-1}(s)\}}-s\bigg]\\
  &=\sqrt{n}[\hat{F}(F ^{-1}(s))-s]\\
  &=\sqrt{n}[\hat{F}(\underbrace{F ^{-1}(s)}_{=:y_s})-F(F ^{-1}(s))]\\
  &=\sqrt{n}(\hat{F}(y_s)-F(y_s))
\end{align*}
Der Prozess $\{\alpha _n(s)\}_{s \in [0,1]} $ konvergiert gegen eine Brownsche Brücke nach Fall 1, die asymptotische Verteilung von $\sqrt{n}\sup _x|\hat{F}(x)-F(x)| $ ist das Supremum (oder Maximum da stetig) der Brownschen Brücke, also
\begin{align*}
  \lim_{n\to \infty }{P\bigg(\sqrt{n}\sup _x|\hat{F}(x)-F(x)|<a \bigg)}=P\bigg(\max _{0 \leq t \leq 1}|Z(t)|<a\bigg)
\end{align*}
mit $\{Z(t)\}_{t \geq 0} $ der Brownsche Brücken Prozess.
\end{document}












